<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>S.Lott -- Software Architect - Python</title><link href="https://slott56.github.io/" rel="alternate"></link><link href="/feeds/python.atom.xml" rel="self"></link><id>https://slott56.github.io/</id><updated>2023-12-19T08:01:00-05:00</updated><entry><title>More Reasons to Stop Bash-ing</title><link href="https://slott56.github.io/2023_12_19-more_reasons_to_stop_bashing.html" rel="alternate"></link><published>2023-12-19T08:01:00-05:00</published><updated>2023-12-19T08:01:00-05:00</updated><author><name>S.Lott</name></author><id>tag:slott56.github.io,2023-12-19:/2023_12_19-more_reasons_to_stop_bashing.html</id><summary type="html">&lt;p&gt;There are many good reasons to use shell scripts.
Mostly, a script can be useful when it's an alias that launches an application.
Beyond that, I have doubts.&lt;/p&gt;
&lt;div class="section" id="bluf"&gt;
&lt;h2&gt;BLUF&lt;/h2&gt;
&lt;p&gt;Incumbency is a popular argument for bash.&lt;/p&gt;
&lt;p&gt;It's not a good argument, however.&lt;/p&gt;
&lt;p&gt;Use &lt;a class="reference external" href="https://pypi.org/project/invoke/"&gt;invoke&lt;/a&gt; and you'll be much happier.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="background"&gt;
&lt;h2&gt;Background …&lt;/h2&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;There are many good reasons to use shell scripts.
Mostly, a script can be useful when it's an alias that launches an application.
Beyond that, I have doubts.&lt;/p&gt;
&lt;div class="section" id="bluf"&gt;
&lt;h2&gt;BLUF&lt;/h2&gt;
&lt;p&gt;Incumbency is a popular argument for bash.&lt;/p&gt;
&lt;p&gt;It's not a good argument, however.&lt;/p&gt;
&lt;p&gt;Use &lt;a class="reference external" href="https://pypi.org/project/invoke/"&gt;invoke&lt;/a&gt; and you'll be much happier.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="background"&gt;
&lt;h2&gt;Background&lt;/h2&gt;
&lt;p&gt;See &lt;a class="reference external" href="https://dnastacio.medium.com/bash-over-python-39e0eba502f9"&gt;When You Should Use Bash Over Python&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I'll start with the three &amp;quot;expressiveness&amp;quot; points.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Syntax&lt;/strong&gt;: Python code is longer. While true, this isn't a reason to use bash. I have to reject this for two reasons.&lt;ul&gt;
&lt;li&gt;No one wins at code golf. Shorter code isn't better by any metric other than size. Bash syntax hides important details.&lt;/li&gt;
&lt;li&gt;The argument starts from the notion that there's a &amp;quot;better&amp;quot; way to express complicated structures, and the bash reflects better.
Python, by being more explicit, is less good.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Runtime&lt;/strong&gt;: Shell script interpreters are ubiquitous. True. Not a compelling argument, when we consider that bash scripts are untestable.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Semantics&lt;/strong&gt;: There is a cognitive cost in converteing bash to Python. Correct. Easy to avoid by avoiding the confusing and opaque bash abstractions.&lt;ul&gt;
&lt;li&gt;The argument (again) starts from the notion that the bash abstraction is a standard against which other languages -- by virtue of being different -- aren't as good.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The argument &lt;strong&gt;for&lt;/strong&gt; bash is incumbency. Bash is installed, and because it's installed, it's better.&lt;/p&gt;
&lt;p&gt;&amp;quot;Bash’s longevity is rooted in core strengths that still resonate in the technology industry&amp;quot;.
I suggest the longevity is due entirely to it's incumbency.
It's not the &lt;strong&gt;best&lt;/strong&gt; choice for anything.
It's a handy default choice because it's already installed.&lt;/p&gt;
&lt;p&gt;And.  There's no easy way to unit test.&lt;/p&gt;
&lt;p&gt;Let's move on to the other six reasons.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="some-reasons-for-using-bash"&gt;
&lt;h2&gt;Some reasons for using bash&lt;/h2&gt;
&lt;p&gt;Here are the the detailed reasons for rejecting Python. Most of this isn't persuasive.
It's mostly about the incumbency of bash.&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;Mastery Matters. Parts of this argument are true. Bash scripts seem to be uniformly bad because bad is a permitted style.
They could be better, making use of clever things like functions and their obscure semantics.&lt;/p&gt;
&lt;p&gt;This doesn't make bash better. It only says that a lot of people write bad scripts.
A lot of bash-bashing stems from seeing so many bad scripts.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Bash is Everywhere. True. Incumbency may be helpful under certain situations.
It's like learning how to compute logarithms so you can then add them to avoid multiplication.
Yes. It does work. However. Calculators exist on this timeline; it's no longer 1617.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&amp;quot;Sidestepping the discussions about the Python version to pick&amp;quot;? What discussion? Is this a &amp;quot;Python 2 v. Python 3&amp;quot; question? That's been answered.&lt;/li&gt;
&lt;li&gt;&amp;quot;the best way to install Python on a given environment&amp;quot;? Most linux distros have Python ready-to-go. That's best.&lt;/li&gt;
&lt;li&gt;&amp;quot;gymnastics to keep dependencies and environments in check&amp;quot;? This isn't hard, actually. Almost anything bash-related is in the standard library plus a few add-ons line &lt;a class="reference external" href="https://pypi.org/project/psutil/"&gt;psutil&lt;/a&gt;.
For a very complicated application with a tall stack of poorly-chosen dependencies, there's work involved.
That application with a complicated set of installs isn't doing bash-like things, though.&lt;/li&gt;
&lt;li&gt;&amp;quot;fragmentation of Python runtime versions&amp;quot;? What fragmentation? Python is popular, and evolves quickly. Is evolution to new versions some kind of problem?&lt;/li&gt;
&lt;li&gt;&amp;quot;mutually exclusive dependency matrix&amp;quot;? Callback to gymnastics. A tall stack of poorly-chosen dependencies is an edge case. It's not the sweet spot for admin tasks often written as bad, untestable bash scripts.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Secured Production Environments. This is hard. None of these difficulties are Python-related, however. It applies to every single application in the environment.
Java requires installs for develolpers, too. So go Go and Rust. Air-gapped systems are hard to build.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&amp;quot;whatever Python runtime environment you lock into a production environment&amp;quot;? Um. This is true for &lt;em&gt;all&lt;/em&gt; applications.
It has nothing to do with Python. This is configuration management. It's hard.&lt;/li&gt;
&lt;li&gt;&amp;quot;Running package managers safely inside a production environment is possible, but everything’s got a price&amp;quot;. And the price is actually quite low.
Further, this means building secured systems for software development. That's quite hard in all languages.
The only language that wouldn't require extra downloads of new and useful packages would be Pascal, I think.&lt;/li&gt;
&lt;li&gt;&amp;quot;You could do [here documents] with a Python script, too, as long as it does not import any package not already installed in the system.&amp;quot;
Right. Most bash-related Python features are part of the standard library. This isn't daunting or even particularly difficult or complicated.
And. With Python you can unit test.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Container Runtimes. See #3. This is bash incumbency and configuration management from point 3, repeated. It's still challenging.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;The Universal Language of Platforms. The bash CLI is ubiquitous, it's ideal for bash. But it's not actually &lt;strong&gt;ideal&lt;/strong&gt; in general.
A Python library that offers access an application's API may be much easier to work with and involve far fewer weird
leaps to make the CLI amendable to the relatively weak set of abstractions bash has available.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;&amp;quot;It would take a couple of days in syntactical and semantical translations to get a result with more lines of code that were less readable than its Bash counterpart&amp;quot;.
Again, the argument presumes the bash language is the gold standard. Starting with bash and enduring translating into Python involves a cost.
It also had benefits, like the ability to test.
Why not start with Python?
&amp;quot;Less readable&amp;quot; is offered without further evidence. Again, this repeats the bash incumbency argument where smaller and older is inherently better.&lt;/p&gt;
&lt;p&gt;Further, the time spent writing Python is often time &lt;strong&gt;well&lt;/strong&gt; spent getting the abstractions right,
and understading use cases.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;&amp;quot;All original samples in the docs were written using the command-line interface.&amp;quot;  Incumbency. And maybe lazy documentation writers in the vendor organization.
&amp;quot;All Internet forums reference the command-line interface&amp;quot;. Sigh. The &amp;quot;All&amp;quot; is disputable, but the point remains that using Python takes some effort.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;The End of the Line Is Not Scripted. (Not sure what this means.)
There are two obstacles here, both of which seem specious at best.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;Mega CLI's. Just because a bash CLI is available does not make it &amp;quot;best.&amp;quot;&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&amp;quot;every bit of function be wrapped with command-line interfaces.&amp;quot;  While true, it ignores the fact
that some packages are actually written in Python, and the bash interface is -- at best -- a hack
for those folks who won't learn Python.&lt;/li&gt;
&lt;li&gt;Bash is everywhere. Incumbency does not make it better. It only makes it incumbent.&lt;/li&gt;
&lt;li&gt;Writing shell scripts is more accessible than writing a new application. A good straw-man.
It throws Python scripting away as if we can't write a short, pithy, testable, reusable Python script.&lt;/li&gt;
&lt;li&gt;&amp;quot;open-source juggernauts...&amp;quot; like &lt;tt class="docutils literal"&gt;awk&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;curl&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;openssl&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;jq&lt;/tt&gt;, and &lt;tt class="docutils literal"&gt;yq&lt;/tt&gt; involves two issues.
First, some programs like &lt;tt class="docutils literal"&gt;openssl&lt;/tt&gt; are better left as stand-alone binaries used by a Python script.
Second, programs like  &lt;tt class="docutils literal"&gt;awk&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;jq&lt;/tt&gt;, and &lt;tt class="docutils literal"&gt;yq&lt;/tt&gt; are the primary symptom of how unsuitable bash is for working with anything other
than a trivial string of characters. Reliance on these add-on programs is one of the reasons why bash is so confusingly horrible.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Operations Frameworks like Ansible, Terraform, and (not mentioned) Puppet. These require some scripting
for integration. Having done it in Python, I can safely say Python works.&lt;/p&gt;
&lt;p&gt;And I could unit test it.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Unrelated to the two obstacles is this nugget: &amp;quot;tuned for five decades of minimum resource utilization&amp;quot;.
I don't think this is true at all.&lt;/p&gt;
&lt;p&gt;The original Bourne &lt;tt class="docutils literal"&gt;sh&lt;/tt&gt; wasn't very thrifty to begin with. It was constrained by the tiny size of early
machines. And. The Linux technique of sharing the read-only code pages meant the costs could stay low.
State management was environment variables and some OS settings (like the current working directory.)
The bash program is bloatware by comparison to the Bourne shell.
The use of the OS &lt;tt class="docutils literal"&gt;|&lt;/tt&gt; operator forks subprocess after subprocess leading to crazy OS overheads
for a &amp;quot;simple&amp;quot; &lt;tt class="docutils literal"&gt;app | awk | grep | sed &amp;gt; file&lt;/tt&gt; operation.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;&amp;quot;In objective terms, regarding task automation for Cloud operations, it is hard to argue against Bash&amp;quot;.&lt;/p&gt;
&lt;p&gt;No. Actually. It's really easy.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;The bash scripting language is opaque. Objectively, the syntax rules are quite obscure with complicated line-ending and quoting rules.
Objectively, it's really difficult to understand the semantics of the operators like &lt;tt class="docutils literal"&gt;;&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;|&lt;/tt&gt;, and &lt;tt class="docutils literal"&gt;&amp;amp;&lt;/tt&gt;.
Why is &lt;tt class="docutils literal"&gt;;&lt;/tt&gt; optional? Why can a line end with &lt;tt class="docutils literal"&gt;&amp;amp;&lt;/tt&gt;  or &lt;tt class="docutils literal"&gt;;&lt;/tt&gt; but not end with &lt;tt class="docutils literal"&gt;|&lt;/tt&gt;?&lt;/li&gt;
&lt;li&gt;Error-handling in bash is an unholy mess. Objectively, what does &lt;tt class="docutils literal"&gt;set &lt;span class="pre"&gt;-e&lt;/span&gt;&lt;/tt&gt; do?
Objectively, why are there so many return codes?&lt;/li&gt;
&lt;li&gt;Unit testing is almost impossible. Objectively, no one should run a shell script without a test case.&lt;/li&gt;
&lt;li&gt;Bash has almost no useful data structures beyond the string.
Objectively, we can argue that there's a way to break strings on spaces to treat the string as an array.
This is essentially Python &lt;tt class="docutils literal"&gt;.split()&lt;/tt&gt; as the alternative data structure to the string.&lt;/li&gt;
&lt;li&gt;Programs like &lt;tt class="docutils literal"&gt;expr&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;[&lt;/tt&gt; are used widely and very difficult to understand.
Objectively, the man pages for these programs are quite complicated.
What looks like an expression isn't really. It's input to a separate binary that produces a result used by the shell's &lt;tt class="docutils literal"&gt;if&lt;/tt&gt; construct.
Objectively, this is confusing and unpleasant.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Programs like &lt;tt class="docutils literal"&gt;awk&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;jq&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;yq&lt;/tt&gt; are used widely and can be difficult to understand.
They're -- technically -- separate binaries, part of the overall bash ecosystem of internal bash features and external binaries.
They do permit a kind of functional style on bash programming which is nice.
Objectively, this isn't all bad. Python, also, has functional programming features.&lt;/p&gt;
&lt;p&gt;The ubiquity of the bash programming is undeniable. It's also terrible. Bash should be used cautiously.&lt;/p&gt;
&lt;p&gt;When to use bash?&lt;/p&gt;
&lt;p&gt;Use bash you need to launch a Python script. A bash script should be little more than an alias for a program written in a language that offers unit testing.&lt;/p&gt;
&lt;/div&gt;
</content><category term="Python"></category><category term="shell"></category><category term="bash"></category><category term="unit-testing"></category></entry><entry><title>Understanding the Abstraction -- matplotlib Edition</title><link href="https://slott56.github.io/2023-12-12-understanding_the_abstraction.html" rel="alternate"></link><published>2023-12-12T08:01:00-05:00</published><updated>2023-12-12T08:01:00-05:00</updated><author><name>S.Lott</name></author><id>tag:slott56.github.io,2023-12-12:/2023-12-12-understanding_the_abstraction.html</id><summary type="html">&lt;p&gt;I wasted three days because I refused to get a grip on how &lt;a class="reference external" href="https://matplotlib.org"&gt;matplotlib&lt;/a&gt; &lt;strong&gt;really&lt;/strong&gt; works.&lt;/p&gt;
&lt;p&gt;Most of the time, folks like me are happy and successful using the &lt;a class="reference external" href="https://matplotlib.org/stable/api/pyplot_summary.html"&gt;pyplot&lt;/a&gt; module.
The &lt;a class="reference external" href="https://matplotlib.org/stable/users/explain/quick_start.html"&gt;Quickstart&lt;/a&gt; provides brilliant, working
examples.&lt;/p&gt;
&lt;p&gt;As my partner's grandfather used to say, &amp;quot;We're off to the races in …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I wasted three days because I refused to get a grip on how &lt;a class="reference external" href="https://matplotlib.org"&gt;matplotlib&lt;/a&gt; &lt;strong&gt;really&lt;/strong&gt; works.&lt;/p&gt;
&lt;p&gt;Most of the time, folks like me are happy and successful using the &lt;a class="reference external" href="https://matplotlib.org/stable/api/pyplot_summary.html"&gt;pyplot&lt;/a&gt; module.
The &lt;a class="reference external" href="https://matplotlib.org/stable/users/explain/quick_start.html"&gt;Quickstart&lt;/a&gt; provides brilliant, working
examples.&lt;/p&gt;
&lt;p&gt;As my partner's grandfather used to say, &amp;quot;We're off to the races in a cloud of heifer dust.&amp;quot;&lt;/p&gt;
&lt;p&gt;The examples are easily rewritten for the data at hand. They work in Jupyter Lab. Boom. Done.&lt;/p&gt;
&lt;p&gt;There's a little bit of technical detail in &lt;a class="reference external" href="https://matplotlib.org/stable/users/explain/figure/interactive.html#jupyter-notebooks-jupyterlab"&gt;https://matplotlib.org/stable/users/explain/figure/interactive.html#jupyter-notebooks-jupyterlab&lt;/a&gt;.
When I realized things weren't working. I followed each piece of advice, scruplously. They were not the cause of my problems.
The root cause was failure to understand the abstraction.&lt;/p&gt;
&lt;div class="section" id="digging-a-little-deeper"&gt;
&lt;h2&gt;Digging a Little Deeper&lt;/h2&gt;
&lt;p&gt;What is not &lt;strong&gt;painfully&lt;/strong&gt; obvious is how the &lt;strong&gt;matplotlib&lt;/strong&gt; architecture works.
(It's not written in flaming letters 100 feet high.)&lt;/p&gt;
&lt;p&gt;The &lt;tt class="docutils literal"&gt;pyplot&lt;/tt&gt; module is pure genius. It works to shield us from a tech stack that's non-trivial.&lt;/p&gt;
&lt;p&gt;Which means, when someone like me wants to do something that's not copy-and-paste from one of the hundreds of examples,
I have to &lt;strong&gt;actually&lt;/strong&gt; read the documentation. Carefully.&lt;/p&gt;
&lt;p&gt;It took me three days to understand what the documentation said.
Here's my timeline.&lt;/p&gt;
&lt;p&gt;Day 1. Fuss around with my incorrect understanding of how graphics are created.&lt;/p&gt;
&lt;p&gt;Day 2. Write the entire thing as a stand-alone command-line app, where the extemely robust, clever &lt;strong&gt;matplotlib&lt;/strong&gt; architecture works.
It works in spite of me using it utterly incorrectly.&lt;/p&gt;
&lt;p&gt;Day 3. Blinding realization that for the last two days, I've been &lt;strong&gt;doing it wrong.&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="the-big-reveal"&gt;
&lt;h2&gt;The Big Reveal&lt;/h2&gt;
&lt;p&gt;Just about everything that happens in &lt;strong&gt;matplotlib&lt;/strong&gt; depends on an abstraction called an &lt;tt class="docutils literal"&gt;Artist&lt;/tt&gt; being out of date from the canvas.&lt;/p&gt;
&lt;p&gt;This is not obvious, and no one needs to know it except in the rare cases of an animation.&lt;/p&gt;
&lt;p&gt;The rest of the time, we observe that changes to scale or axes or whatever lead to changes to the diagram
that are just what were expected. The &amp;quot;out-of-date&amp;quot; business doesn't enter into our experience
when we're making changes that update the static diagram we want.&lt;/p&gt;
&lt;p&gt;Anyone (even me) can get things to work by simply creating axes, creating a &amp;quot;fill&amp;quot; (a Polygon, actually), and being happy.
The &lt;tt class="docutils literal"&gt;plt.show()&lt;/tt&gt; works.&lt;/p&gt;
&lt;p&gt;But that's actually &lt;strong&gt;not&lt;/strong&gt; right for the kinds of things I was trying to do.&lt;/p&gt;
&lt;p&gt;Here's what I was working on.&lt;/p&gt;
&lt;a class="reference external image-reference" href="https://slott56.github.io/media/Empire_1337.png"&gt;&lt;img alt="Hexagonal map showing 5 interlocking regions" src="https://slott56.github.io/media/Empire_1337.png" style="width: 400px; height: 400px;" /&gt;&lt;/a&gt;
&lt;p&gt;This map is actually &amp;quot;grown&amp;quot; using some simple rules from a few seed points.
The animation of that growth process is what I want.&lt;/p&gt;
&lt;p&gt;This isn't as clever as &lt;a class="reference external" href="https://conwaylife.com"&gt;Conway's Game of Life&lt;/a&gt;, but it is similar in a few respects.
Mine, for example, involves random numbers. Is that desirable? Can the dependency be reduced
and still lead to complicated structures?&lt;/p&gt;
&lt;p&gt;I want to tinker with the rules.&lt;/p&gt;
&lt;p&gt;(I have a version running in the Pythonista environment on my iPad. I want a version
in JupyterLab that I can expand on more easily.)&lt;/p&gt;
&lt;p&gt;Let's compare and contrast the two approaches&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="seductive-and-wrong"&gt;
&lt;h2&gt;Seductive and Wrong&lt;/h2&gt;
&lt;p&gt;This is seductive and simple. It fits (to an extent) with previous examples.
It seems so right. And it sometimes works. But it's so wrong.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Create 324 polygon outlines to paint the background grid.&lt;/li&gt;
&lt;li&gt;Create 324 text labels to label the hexes.&lt;/li&gt;
&lt;li&gt;As the generative algorithm runs, create colored polygon fill patches, showing
how the 5 seed positions evolve into the 5 interlocking shapes.
This starts with 5 filled polygons and grows to 200+ polygons through 48 generations.
So that's &lt;span class="formula"&gt;35 + ... + 235 = 6, 650&lt;/span&gt; filled polygons.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Wave after wave of increasing number of polygons.
Sure, it's a lot of objects. I have a big laptop. We're good.&lt;/p&gt;
&lt;p&gt;This has two problems.&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;It's slow.&lt;/li&gt;
&lt;li&gt;If I save the animation as an HTML or JSHTML object, I get a cycling animation with the right number of images, but  no content in any image.&lt;/li&gt;
&lt;li&gt;In spite of the animation being empty, the final image looks good.&lt;/li&gt;
&lt;li&gt;A few off-by-one errors.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;What's wrong?&lt;/p&gt;
&lt;p&gt;I'm patient and thorough. I tried a &lt;strong&gt;lot&lt;/strong&gt; of things.  I added Qt. I added ipympl. I restructured the animation
as functions and callable objects. I used &lt;tt class="docutils literal"&gt;FuncAnimation&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;ArtistAnimation&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;Nothing Worked.  Nothing.&lt;/p&gt;
&lt;blockquote&gt;
&lt;strong&gt;Spoiler Alert&lt;/strong&gt;.  That's how you know you're doing something fundamentally wrong.
The thing works in general. But specific features are missing.&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class="section" id="how-can-that-be-wrong"&gt;
&lt;h2&gt;How Can That Be Wrong?&lt;/h2&gt;
&lt;p&gt;The foundational mis-understanding was trying to animate the appearance of various &lt;strong&gt;matplotlib&lt;/strong&gt; &lt;tt class="docutils literal"&gt;Artist&lt;/tt&gt; objects
on the map.&lt;/p&gt;
&lt;p&gt;I drew the grid. I drew the labels.&lt;/p&gt;
&lt;p&gt;Then the colored hexes are supposed to appear, one at at time. I figured (wrongly) I would just draw the filled polygons.&lt;/p&gt;
&lt;p&gt;See above. &amp;quot;Just about everything that happens in &lt;strong&gt;matplotlib&lt;/strong&gt; depends on an abstraction called an &lt;tt class="docutils literal"&gt;Artist&lt;/tt&gt; being out of date from the canvas.&amp;quot;&lt;/p&gt;
&lt;p&gt;Out-of-date?&lt;/p&gt;
&lt;p&gt;Out-of-date!&lt;/p&gt;
&lt;p&gt;State Change.&lt;/p&gt;
&lt;p&gt;The &lt;tt class="docutils literal"&gt;Artist&lt;/tt&gt; won't paint unless there's something &lt;strong&gt;new&lt;/strong&gt; to paint.&lt;/p&gt;
&lt;p&gt;On day three, I realized the truth.&lt;/p&gt;
&lt;p&gt;It works like this:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Create 324 polygon outlines to paint the background grid.&lt;/li&gt;
&lt;li&gt;Create 324 text labels to label the hexes.&lt;/li&gt;
&lt;li&gt;Create 324 polygons filled with white.&lt;/li&gt;
&lt;li&gt;As the generative algorithm runs, change the color in the polygon.
&lt;strong&gt;Change&lt;/strong&gt; the color. Change.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Change. The &lt;tt class="docutils literal"&gt;Artist&lt;/tt&gt; is waiting for a change.&lt;/p&gt;
&lt;p&gt;Don't create a wave of new polygons. Change the color of the polygons.
It's simpler. It's faster. It works.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
def paint(self, col: int, row: int, fill: str) -&amp;gt; None:
    &amp;quot;&amp;quot;&amp;quot;
    Update a hex's fill color.
    &amp;quot;&amp;quot;&amp;quot;
    for a in self.cells[col, row]:
        a.set(
            fill=True,
            color=fill
        )
&lt;/pre&gt;
&lt;p&gt;Don't create a new polygon.  Change the color of the polygon you have.&lt;/p&gt;
&lt;p&gt;I still have no idea how the scale factors work when creating the JSHTML.
I have eight mypy complaints because I'm not using &lt;strong&gt;matplotlib&lt;/strong&gt; correctly.
I have more work to do.&lt;/p&gt;
&lt;p&gt;But. I have pictures that work. For the right reason.&lt;/p&gt;
&lt;/div&gt;
</content><category term="Python"></category><category term="language"></category><category term="semantics"></category></entry><entry><title>It's Not THE Ternary Operator -- there are many</title><link href="https://slott56.github.io/2023_12_05-not_the_ternary_operator.html" rel="alternate"></link><published>2023-12-05T08:01:00-05:00</published><updated>2023-12-05T08:01:00-05:00</updated><author><name>S.Lott</name></author><id>tag:slott56.github.io,2023-12-05:/2023_12_05-not_the_ternary_operator.html</id><summary type="html">&lt;p&gt;I'm sick of reading about &lt;strong&gt;THE&lt;/strong&gt; Ternary Operator.&lt;/p&gt;
&lt;p&gt;There is not merely &lt;strong&gt;a&lt;/strong&gt; single operator that is ternary.
There are many operators that are ternary.&lt;/p&gt;
&lt;p&gt;Here's one example:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;&amp;gt;&amp;gt; 6+1 &amp;gt;= 6 &amp;gt;= 6-1
&lt;/pre&gt;
&lt;p&gt;The &lt;tt class="docutils literal"&gt;&amp;gt;= &amp;gt;=&lt;/tt&gt; operator is ternary. It has 3 operands.  Count them.&lt;/p&gt;
&lt;p&gt;There are a 36 of these ternary operators …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I'm sick of reading about &lt;strong&gt;THE&lt;/strong&gt; Ternary Operator.&lt;/p&gt;
&lt;p&gt;There is not merely &lt;strong&gt;a&lt;/strong&gt; single operator that is ternary.
There are many operators that are ternary.&lt;/p&gt;
&lt;p&gt;Here's one example:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;&amp;gt;&amp;gt; 6+1 &amp;gt;= 6 &amp;gt;= 6-1
&lt;/pre&gt;
&lt;p&gt;The &lt;tt class="docutils literal"&gt;&amp;gt;= &amp;gt;=&lt;/tt&gt; operator is ternary. It has 3 operands.  Count them.&lt;/p&gt;
&lt;p&gt;There are a 36 of these ternary operators.&lt;/p&gt;
&lt;p&gt;&amp;quot;Oh, pish-tosh,&amp;quot; you say. &amp;quot;It's an example of two binary operators.&amp;quot;&lt;/p&gt;
&lt;p&gt;Really?&lt;/p&gt;
&lt;p&gt;In a sense, you're almost right, it's equivalent to &lt;tt class="docutils literal"&gt;6+1 &amp;gt;= 6 and 6 &amp;gt;= &lt;span class="pre"&gt;6-1&lt;/span&gt;&lt;/tt&gt;. Which is three binary operators.&lt;/p&gt;
&lt;p&gt;But it's &lt;strong&gt;not&lt;/strong&gt; three binary operators. It's one ternary operator.&lt;/p&gt;
&lt;p&gt;&amp;quot;Whoa. What about &lt;tt class="docutils literal"&gt;5 &amp;lt; 6 &amp;lt; 7 &amp;lt; 8&lt;/tt&gt;?&amp;quot; you reply triumphantly. &amp;quot;That has four operands!&amp;quot;&lt;/p&gt;
&lt;p&gt;Right. It's quaternary. There a lot of ways to create quaternary (and higher) operators in Python.
There are 216 of quaternary operators.  1296 quinary.&lt;/p&gt;
&lt;p&gt;There is not &lt;strong&gt;A Ternary Operator&lt;/strong&gt;.  The phrase is meaningless.  You can stop using it.&lt;/p&gt;
&lt;div class="section" id="there-s-more"&gt;
&lt;h2&gt;There's more&lt;/h2&gt;
&lt;p&gt;We're not done.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;&amp;gt;&amp;gt; (2*a + 1
...    for a in range(5)
...    if a % 2 == 0
... )
&lt;/pre&gt;
&lt;p&gt;Is ternary.&lt;/p&gt;
&lt;p&gt;I'll clarify:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;2*a + 1&lt;/tt&gt; -- expression #1&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;range(5)&lt;/tt&gt; -- expression #2&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;a % 2 == 0&lt;/tt&gt; -- expression #3&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Admittedly, the two pieces of interstitial syntax are complicated.&lt;/p&gt;
&lt;ol class="loweralpha simple"&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;for a in&lt;/tt&gt;  -- kind of big; and it names a bind variable.&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;if&lt;/tt&gt; -- more typical for ternary operators.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;But. There are three operands separated by punctuation.&lt;/p&gt;
&lt;p&gt;It is, therefore, ternary.&lt;/p&gt;
&lt;p&gt;And yes. When we have multiple &lt;tt class="docutils literal"&gt;for&lt;/tt&gt; clauses or multiple &lt;tt class="docutils literal"&gt;if&lt;/tt&gt; clauses, we clearly have quaternary and quinary operators.
That's part of my point: there are a number of &lt;em&gt;arities&lt;/em&gt; and a number of operators of each arity.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="i-could-go-on"&gt;
&lt;h2&gt;I could go on&lt;/h2&gt;
&lt;p&gt;A Big Pointless Beef (BPB™) is often this.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The ternary operator&lt;/strong&gt; (by which I presume they mean the conditional expression) &lt;strong&gt;evaluates the middle first.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Which is kind of a &amp;quot;so what?&amp;quot;&lt;/p&gt;
&lt;p&gt;Many things in Python are left-to-right.&lt;/p&gt;
&lt;p&gt;But not everything is trivially left-to-right.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;&amp;gt;&amp;gt; noisy = lambda x: print(x) or x
&amp;gt;&amp;gt;&amp;gt; list(noisy(2*a + 1)
...   for a in noisy(range(5))
...   if noisy(a % 2 == 0)
... )
range(0, 5)  # expression 2, the range(...)
True  # expression 3, the if.
1  # expression 1, the 2*a+1.
False
True
5
False
True
9
[1, 5, 9]
&lt;/pre&gt;
&lt;p&gt;The &lt;tt class="docutils literal"&gt;range(5)&lt;/tt&gt; -- in the middle of this particular ternay operator -- is evaluated first.
And only evaluated once, where the outer expressions are evaluated on right-to-left order over and over again.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="we-re-not-done"&gt;
&lt;h2&gt;We're not done&lt;/h2&gt;
&lt;p&gt;Consider, if you will,&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;&amp;gt;&amp;gt; a = list(range(5))
&amp;gt;&amp;gt;&amp;gt; a[1:-1]
[1, 2, 3]
&lt;/pre&gt;
&lt;p&gt;The &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;a[1:-1]&lt;/span&gt;&lt;/tt&gt; is ternary. It has three expressions. Count them yourself.&lt;/p&gt;
&lt;p&gt;Also, &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;a[:-1:2]&lt;/span&gt;&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;a[-1::-1]&lt;/span&gt;&lt;/tt&gt;.  All ternary subsets of a more general quaternary operator.&lt;/p&gt;
&lt;p&gt;&amp;quot;That'a wrong! You can't call a slice part of an operator,&amp;quot; you claim.&lt;/p&gt;
&lt;p&gt;Perhaps I am pushing it. But it sure looks like &lt;tt class="docutils literal"&gt;a&lt;/tt&gt; is one expressions, &lt;tt class="docutils literal"&gt;1&lt;/tt&gt; is another and &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;-1&lt;/span&gt;&lt;/tt&gt; is the third.
And it sure looks like &lt;tt class="docutils literal"&gt;[&lt;/tt&gt; is one separator, &lt;tt class="docutils literal"&gt;:&lt;/tt&gt; is another, and there's an extra closing
punctuation mark of &lt;tt class="docutils literal"&gt;]&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;&amp;quot;You've jumbled up indexing and slicing!&amp;quot; you claim. &amp;quot;They're clearly separate syntactic categories!&amp;quot;&lt;/p&gt;
&lt;p&gt;Clearly? If I can only using slicing in the context of indexing, I'm not completely sold that these two concepts
are separate and foreign.  They seem pretty tightly coupled.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="summary"&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;p&gt;Stop writing (and saying) &amp;quot;The Ternary Operator&amp;quot;. Please.&lt;/p&gt;
&lt;p&gt;There are a lot of ternary operators.&lt;/p&gt;
&lt;p&gt;If you don't like the &lt;strong&gt;Conditional Expression&lt;/strong&gt; because it's too much like a list comprehension with that &amp;quot;evaluate something not on the left first&amp;quot; semantics,
please say that you don't like &lt;strong&gt;The Section 6.13 Conditional Expression&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Please.  Please try to be precise.&lt;/p&gt;
&lt;p&gt;Otherwise, the rest of your rant on evaluation order looks like you haven't really taken the time to think things through.
Maybe you have, but the use of &amp;quot;The Ternary Operator&amp;quot; dilutes your message.&lt;/p&gt;
&lt;p&gt;Other languages use phrases like &amp;quot;the ternary operator.&amp;quot; That doesn't really mean much.
We're talking about Python, where there's more than one.&lt;/p&gt;
&lt;/div&gt;
</content><category term="Python"></category><category term="language"></category><category term="semantics"></category></entry><entry><title>This is Awful</title><link href="https://slott56.github.io/2023-11-14-this_is_awful.html" rel="alternate"></link><published>2023-11-14T08:01:00-05:00</published><updated>2023-11-14T08:01:00-05:00</updated><author><name>S.Lott</name></author><id>tag:slott56.github.io,2023-11-14:/2023-11-14-this_is_awful.html</id><summary type="html">&lt;p&gt;This is a disheartening thing to read&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;As someone who doesn't do a ton of JSON parsing on the command line, I tend to forget &lt;a class="reference external" href="https://jqlang.github.io/jq/manual/"&gt;jq&lt;/a&gt; syntax.&lt;/p&gt;
&lt;p&gt;Two tools I really like are &lt;a class="reference external" href="github.com/tomnomnom/gron"&gt;gron&lt;/a&gt; (make JSON greppable) from &amp;#64;tomnomnom and &lt;a class="reference external" href="github.com/noahgorstein/jqp"&gt;jqp&lt;/a&gt; ..., which provides a &amp;quot;tui playground for exploring jq.&amp;quot;&lt;/p&gt;
&lt;p&gt;98 …&lt;/p&gt;&lt;/blockquote&gt;</summary><content type="html">&lt;p&gt;This is a disheartening thing to read&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;As someone who doesn't do a ton of JSON parsing on the command line, I tend to forget &lt;a class="reference external" href="https://jqlang.github.io/jq/manual/"&gt;jq&lt;/a&gt; syntax.&lt;/p&gt;
&lt;p&gt;Two tools I really like are &lt;a class="reference external" href="github.com/tomnomnom/gron"&gt;gron&lt;/a&gt; (make JSON greppable) from &amp;#64;tomnomnom and &lt;a class="reference external" href="github.com/noahgorstein/jqp"&gt;jqp&lt;/a&gt; ..., which provides a &amp;quot;tui playground for exploring jq.&amp;quot;&lt;/p&gt;
&lt;p&gt;98% of the time I end up being able to get what I need with gron + grep, then jqp is awesome for when I actually need jq :)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;What's so bad?&lt;/p&gt;
&lt;p&gt;With Python, all of this &amp;quot;syntax&amp;quot; and &amp;quot;greppable&amp;quot; and &amp;quot;interactive&amp;quot; goes away.&lt;/p&gt;
&lt;p&gt;Stop using bash. Start using Python. Life is so much simpler. (And faster. And unit-testable.)&lt;/p&gt;
</content><category term="Python"></category><category term="bash"></category><category term="json"></category></entry><entry><title>The Debugger</title><link href="https://slott56.github.io/2023_10_10-the_debugger.html" rel="alternate"></link><published>2023-10-10T18:21:00-04:00</published><updated>2023-10-10T18:21:00-04:00</updated><author><name>S.Lott</name></author><id>tag:slott56.github.io,2023-10-10:/2023_10_10-the_debugger.html</id><summary type="html">&lt;p&gt;See &lt;a class="reference external" href="https://www.bitecode.dev/p/python-312-what-didnt-make-the-headlines"&gt;Python 3.12: what didn't make the headlines&lt;/a&gt;. This is &lt;strong&gt;very&lt;/strong&gt; helpful.&lt;/p&gt;
&lt;p&gt;It is a great list of 7 key features of Python 3.12.&lt;/p&gt;
&lt;p&gt;With one tiny point I need to object to.&lt;/p&gt;
&lt;div class="section" id="i-don-t-like-debuggers"&gt;
&lt;h2&gt;I don't like debuggers&lt;/h2&gt;
&lt;p&gt;This is a strongly-held position.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Debuggers are harmful.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I say this …&lt;/p&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;See &lt;a class="reference external" href="https://www.bitecode.dev/p/python-312-what-didnt-make-the-headlines"&gt;Python 3.12: what didn't make the headlines&lt;/a&gt;. This is &lt;strong&gt;very&lt;/strong&gt; helpful.&lt;/p&gt;
&lt;p&gt;It is a great list of 7 key features of Python 3.12.&lt;/p&gt;
&lt;p&gt;With one tiny point I need to object to.&lt;/p&gt;
&lt;div class="section" id="i-don-t-like-debuggers"&gt;
&lt;h2&gt;I don't like debuggers&lt;/h2&gt;
&lt;p&gt;This is a strongly-held position.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Debuggers are harmful.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I say this because I have had the misfortune to help more than one programmer
who could not actually describe the semantics of the code.&lt;/p&gt;
&lt;p&gt;They couldn't draw a picture. Write a sentence. Nothing.&lt;/p&gt;
&lt;p&gt;They could only point at the interactive debugger session with hapless flailing, and &amp;quot;see, it should work&amp;quot;
kind of noises.&lt;/p&gt;
&lt;p&gt;This is emphatically &lt;strong&gt;bad&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Every time I would ask them to step away from the debugger and describe -- maybe on a whiteboard --
what the heck they thought was going on.&lt;/p&gt;
&lt;p&gt;I could go on with horror stories of bad debugging.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="i-use-debuggers"&gt;
&lt;h2&gt;I use debuggers&lt;/h2&gt;
&lt;p&gt;Back when C++ was my &amp;quot;stock-in-trade&amp;quot;, I used the debugger.&lt;/p&gt;
&lt;p&gt;Rarely.&lt;/p&gt;
&lt;p&gt;And then, mostly, on core dump files to figure out where the program failed.&lt;/p&gt;
&lt;p&gt;And to look at a few key variables to confirm the state of the computation.&lt;/p&gt;
&lt;p&gt;Then.&lt;/p&gt;
&lt;p&gt;I went back to the source, and looked for a logic path that lead to the wrong state.
It wasn't often hard to find.
And it didn't involve using the debugger for much more than finding the
call frame, stack contents, and local variables.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="what-set-me-off"&gt;
&lt;h2&gt;What set me off&lt;/h2&gt;
&lt;p&gt;This:&lt;/p&gt;
&lt;blockquote&gt;
...it's also removing a big &amp;quot;WTF&amp;quot; that all beginners will experience using the Python debugger with nobody in sight to explain to them what's going on.&lt;/blockquote&gt;
&lt;p&gt;I think there are no circumstances under which beginners should be using the debugger.&lt;/p&gt;
&lt;p&gt;I think there are no circumstances under which anyone should use a debugger before they already know
what's supposed to be going on.&lt;/p&gt;
&lt;p&gt;The idea of &amp;quot;beginners&amp;quot; being surprised at the structure of stackframes is an oxymoron.&lt;/p&gt;
&lt;blockquote&gt;
Beginners don't know about stack frames.&lt;/blockquote&gt;
&lt;p&gt;More-or-less, this is one definition of &amp;quot;beginner&amp;quot;.&lt;/p&gt;
&lt;p&gt;People who know about stack frames aren't beginners and can be trusted to understand the debugger.&lt;/p&gt;
&lt;p&gt;The points in the blog posts are sound: better debugging, additional support for evaluating expressions.&lt;/p&gt;
&lt;p&gt;The &amp;quot;audience of beginners&amp;quot; is my only quibble.&lt;/p&gt;
&lt;/div&gt;
</content><category term="Python"></category><category term="games"></category><category term="tutorial"></category></entry><entry><title>Analyzing a Dice Mechanic</title><link href="https://slott56.github.io/2023_09_14-analyzing_a_dice_mechanic.html" rel="alternate"></link><published>2023-09-14T14:57:00-04:00</published><updated>2023-09-14T14:57:00-04:00</updated><author><name>S.Lott</name></author><id>tag:slott56.github.io,2023-09-14:/2023_09_14-analyzing_a_dice_mechanic.html</id><summary type="html">&lt;p&gt;A &amp;quot;Dice Mechanic&amp;quot;? Yes. The thing you do with the dice to determine an outcome.
We'll use Python to see how the dice shake out.&lt;/p&gt;
&lt;div class="section" id="a-little-backstory"&gt;
&lt;h2&gt;A little backstory&lt;/h2&gt;
&lt;p&gt;For a casino game of craps, the roll of the dice can be 7 or 11 for an immediate win,
2, 3 …&lt;/p&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;A &amp;quot;Dice Mechanic&amp;quot;? Yes. The thing you do with the dice to determine an outcome.
We'll use Python to see how the dice shake out.&lt;/p&gt;
&lt;div class="section" id="a-little-backstory"&gt;
&lt;h2&gt;A little backstory&lt;/h2&gt;
&lt;p&gt;For a casino game of craps, the roll of the dice can be 7 or 11 for an immediate win,
2, 3, or 12 for an immediate loss, and the other numbers establish a point.
You continue to roll until you get your point or a 7. That's a mechanic.
Kind of complicated -- by design.&lt;/p&gt;
&lt;p&gt;Many Table-Top Role-Playing Games (TTRPG) include game mechanics that involve dice.
The original D&amp;amp;D used the Platonic regular polyhedra. They were summarized as &amp;quot;d6&amp;quot;
for the 6-sided die folks often think of. The term &amp;quot;3d8&amp;quot; was interpreted as &amp;quot;3 eight-sided dice.&amp;quot;&lt;/p&gt;
&lt;p&gt;It, of course, gets more complicated &amp;quot;3d6+1&amp;quot; is add one to three six-sided dice.&lt;/p&gt;
&lt;p&gt;And, there are things like &amp;quot;4d6-low&amp;quot; to discard the lowest of 4 dice.
Or maybe &amp;quot;ll4d6&amp;quot; for &amp;quot;lose lowest&amp;quot;. Clever people have worked out a lot of mechanics,
and a lot of ways to describe them.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="the-mechanics-in-question"&gt;
&lt;h2&gt;The mechanics in question&lt;/h2&gt;
&lt;p&gt;We want to compare two mechanics:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Worst of 2d6. This tends to have a lot of low numbers.&lt;/li&gt;
&lt;li&gt;Middle of 3d6. This -- well -- does it tend to favor low numbers, also?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We could -- if we had a big brain -- work out the odds.  But we don't have a big brain.&lt;/p&gt;
&lt;p&gt;Another really good alternative is to exhaustively enumerate the possible outcomes.
With 3d6 there are only &lt;span class="formula"&gt;6&lt;sup&gt;3&lt;/sup&gt; = 216&lt;/span&gt; ways the dice can fall. This doesn't seem
pleasant. We'll set it aside.&lt;/p&gt;
&lt;p&gt;Instead, we'll simulate.&lt;/p&gt;
&lt;div class="sidebar"&gt;
&lt;p class="first"&gt;This isn't as dumb as it might sound.&lt;/p&gt;
&lt;p&gt;Some of the foundational statistical tests are designed to discern of outcomes
are random or not. The &amp;quot;Null Hypothesis&amp;quot; is that the data's random.
The various tests for the null hypothesis are often difficult to understand,
and involve tables of magical numbers. The &lt;span class="formula"&gt;&lt;i&gt;χ&lt;/i&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/span&gt; test involves a
complicated computation to compare actual and expected and then you have to look
up a number in a table.&lt;/p&gt;
&lt;p class="last"&gt;In some cases, it's easier to create random data and compute the correlation between
actual and random. High correlation? Accept the Null Hypothesis.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;We'll start by building a simulation of each mechanic.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="worst-of-2d6"&gt;
&lt;h2&gt;Worst of 2d6&lt;/h2&gt;
&lt;p&gt;Here's the code to roll a handful of dice.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
from random import randint

def nd6(n: int) -&amp;gt; list[int]:
    return [randint(1, 6) for _ in range(n)]
&lt;/pre&gt;
&lt;p&gt;The &lt;tt class="docutils literal"&gt;nd6(2)&lt;/tt&gt; expression gives us a pair of dice as a tiny little list.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
def worst(dice: list[int]) -&amp;gt; int:
    return min(dice)
&lt;/pre&gt;
&lt;p&gt;The &lt;tt class="docutils literal"&gt;worst(some_dice)&lt;/tt&gt; expression returns the worst of the two values.
If we were more clever, we might write something like.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
def worst(dice: list[int]) -&amp;gt; int:
    d_1, d_2 = dice
    return d_1 if d_1 &amp;lt;= d_2 else d_2
&lt;/pre&gt;
&lt;p&gt;Which would be faster when it runs.
But this is a lot more coding.
Efficiency isn't the goal.
We're comparing two dice mechanics.&lt;/p&gt;
&lt;p&gt;Finally, this will apply the &lt;tt class="docutils literal"&gt;worst()&lt;/tt&gt; decision to &lt;tt class="docutils literal"&gt;nd6(2)&lt;/tt&gt; to
capture the worst numbers.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
from collections.abc import Iterator

def worst_2d6(samples=1000) -&amp;gt; Iterator[int]:
    yield from (
        worst(nd6(2)) for _ in range(samples)
    )
&lt;/pre&gt;
&lt;p&gt;This function is a kind of generator. It doesn't simply compute a value the way
the &lt;tt class="docutils literal"&gt;nd6()&lt;/tt&gt; or &lt;tt class="docutils literal"&gt;worst()&lt;/tt&gt; functions did. This will yield a result
each time it's asked for something. It iterates over a sequence of &lt;tt class="docutils literal"&gt;worst(nd6(2))&lt;/tt&gt; values.&lt;/p&gt;
&lt;p&gt;(The &lt;tt class="docutils literal"&gt;range(samples)&lt;/tt&gt; defines how long the sequence will be.)&lt;/p&gt;
&lt;p&gt;The point of the generator is to avoid producing a giant list with a thousand values
when all we're going to do is summarize the list into a small result.&lt;/p&gt;
&lt;p&gt;Here's the summary.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
from collections import Counter

distro_worst_2d6 = Counter(worst_2d6())
&lt;/pre&gt;
&lt;p&gt;We'll create a &lt;tt class="docutils literal"&gt;Counter&lt;/tt&gt; object from the values generated when evaluating the &lt;tt class="docutils literal"&gt;worst(nd6(2))&lt;/tt&gt; expression 1,000 times.&lt;/p&gt;
&lt;p&gt;Here's the result:&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="50%" /&gt;
&lt;col width="50%" /&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;n&lt;/th&gt;
&lt;th class="head"&gt;count&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;304&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;242&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;202&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;132&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;84&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;36&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;That fits our expectation, more-or-less.&lt;/p&gt;
&lt;p&gt;And it wasn't too hard to create.&lt;/p&gt;
&lt;p&gt;Let's look at the other mechanic.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="middle-of-3d6"&gt;
&lt;h2&gt;Middle of 3d6&lt;/h2&gt;
&lt;p&gt;We're going to reuse the &lt;tt class="docutils literal"&gt;nd6()&lt;/tt&gt; function. It works delightfully well for 3 dice as well as 2 dice.&lt;/p&gt;
&lt;p&gt;Here's an approach to picking the middle value.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
def mid(dice: list[int]) -&amp;gt; int:
    return sorted(dice)[1]
&lt;/pre&gt;
&lt;p&gt;We've sorted the three dice, and taken the one in position 1.
Position 0 has the least, and position 2 has the most.
In the middle is the target value.&lt;/p&gt;
&lt;p&gt;We can optimize this, of course.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
d_0, d_1, d_2 = dice
return (
    d_0 if d_1 &amp;lt;= d_0 &amp;lt;= d_2 else
    d_1 if d_0 &amp;lt;= d_1 &amp;lt;= d_2 else
    d_2
)
&lt;/pre&gt;
&lt;p&gt;Who needs that kind of optimization? Not me.&lt;/p&gt;
&lt;p&gt;Here's a generator to provide the needed 1,000 samples.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
def mid_3d6(samples=1000):
    yield from (
        mid(nd6(3)) for _ in range(samples)
    )
&lt;/pre&gt;
&lt;p&gt;It's really similar to the &lt;tt class="docutils literal"&gt;worst_2d6()&lt;/tt&gt; function. And, yes, the two could be refactored to eliminate a tiny blot of redundant code. And, no, I won't spend a lot of time on that optimization.
(I wrote a whole book on Functional Python Programming.)&lt;/p&gt;
&lt;p&gt;Here's the distribution:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
distro_mid_3d6 = Counter(mid_3d6())
&lt;/pre&gt;
&lt;p&gt;What's it look like? This.&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="50%" /&gt;
&lt;col width="50%" /&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;n&lt;/th&gt;
&lt;th class="head"&gt;count&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;72&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;192&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;245&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;226&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;185&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;80&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Seriously? It's weighted toward 3's and 4's?&lt;/p&gt;
&lt;p&gt;That shouldn't be too surprising. Maybe it is.&lt;/p&gt;
&lt;p&gt;I had no idea.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="so-far-so-good"&gt;
&lt;h2&gt;So Far, So Good&lt;/h2&gt;
&lt;p&gt;The point is to compare dice mechanics.&lt;/p&gt;
&lt;p&gt;The strategy is to simulate them.&lt;/p&gt;
&lt;p&gt;We wrote some functions to apply the mechanic.&lt;/p&gt;
&lt;p&gt;We sampled it 1,000 times to create a &lt;tt class="docutils literal"&gt;Counter&lt;/tt&gt; with the distribution of the 1,000 samples.&lt;/p&gt;
&lt;p&gt;And now, you can decide if that's acceptable for the game you're designing.&lt;/p&gt;
&lt;p&gt;Or, you can press on and do a little more math.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="but-wait-there-s-more"&gt;
&lt;h2&gt;But wait, there's more&lt;/h2&gt;
&lt;p&gt;The worst-of-2d6 isn't too difficult to compute on paper.&lt;/p&gt;
&lt;p&gt;When will the lowest value be 6? This requires a (6, 6) tie, &lt;span class="formula"&gt;&lt;i&gt;P&lt;/i&gt;(6) = &lt;span class="fraction"&gt;&lt;span class="ignored"&gt;(&lt;/span&gt;&lt;span class="numerator"&gt;1&lt;/span&gt;&lt;span class="ignored"&gt;)/(&lt;/span&gt;&lt;span class="denominator"&gt;36&lt;/span&gt;&lt;span class="ignored"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;It's a 5 when there's a (5, 5), (5, 6), or (6, 5)) pair. &lt;span class="formula"&gt;&lt;i&gt;P&lt;/i&gt;(5) = &lt;span class="fraction"&gt;&lt;span class="ignored"&gt;(&lt;/span&gt;&lt;span class="numerator"&gt;3&lt;/span&gt;&lt;span class="ignored"&gt;)/(&lt;/span&gt;&lt;span class="denominator"&gt;36&lt;/span&gt;&lt;span class="ignored"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;It's a 4 when there's any of (4, 4), (4, 5), (4, 6), (5, 4), or (6, 4). &lt;span class="formula"&gt;&lt;i&gt;P&lt;/i&gt;(4) = &lt;span class="fraction"&gt;&lt;span class="ignored"&gt;(&lt;/span&gt;&lt;span class="numerator"&gt;5&lt;/span&gt;&lt;span class="ignored"&gt;)/(&lt;/span&gt;&lt;span class="denominator"&gt;36&lt;/span&gt;&lt;span class="ignored"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;And so on for 3, 2, and 1.  &lt;span class="formula"&gt;&lt;i&gt;P&lt;/i&gt;(&lt;i&gt;n&lt;/i&gt;) = &lt;span class="fraction"&gt;&lt;span class="ignored"&gt;(&lt;/span&gt;&lt;span class="numerator"&gt;2(6 − &lt;i&gt;n&lt;/i&gt;) + 1&lt;/span&gt;&lt;span class="ignored"&gt;)/(&lt;/span&gt;&lt;span class="denominator"&gt;36&lt;/span&gt;&lt;span class="ignored"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;We can create prediction from this essential probability theory.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
for n in range(6):
    print(n+1, int(1000 * (2*(5-n)+1) / 36))
&lt;/pre&gt;
&lt;p&gt;The predicted distribution is this.&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="50%" /&gt;
&lt;col width="50%" /&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;n&lt;/th&gt;
&lt;th class="head"&gt;count&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;305&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;250&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;194&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;138&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;83&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;27&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;That looks pretty close to the random simulation. It was more work to do the theory
than to simulate. That's why I started with the simulation.&lt;/p&gt;
&lt;p&gt;This part is to convince any doubters that simulation gives useful results.&lt;/p&gt;
&lt;p&gt;We'll continue to flog that point.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="middle-of-3d6-theory"&gt;
&lt;h2&gt;Middle of 3d6 Theory&lt;/h2&gt;
&lt;p&gt;This exceeds my skills.&lt;/p&gt;
&lt;p&gt;When will the median value be 6? This requires a (6, 6, 6) tie. Actually, it's a lot more than that. Anything with a pair of 6's means 6 will be the mid value. There are &lt;span class="formula"&gt;&lt;span class="fraction"&gt;&lt;span class="ignored"&gt;(&lt;/span&gt;&lt;span class="numerator"&gt;15&lt;/span&gt;&lt;span class="ignored"&gt;)/(&lt;/span&gt;&lt;span class="denominator"&gt;216&lt;/span&gt;&lt;span class="ignored"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ways to have a pair of sixes and another number. Think of (1, 6, 6) to (5, 6, 6), and (6, 1, 6) to (6, 5, 6), and (6, 6, 1) to (6, 6, 5). So, total, is &lt;span class="formula"&gt;&lt;i&gt;P&lt;/i&gt;(6) = &lt;span class="fraction"&gt;&lt;span class="ignored"&gt;(&lt;/span&gt;&lt;span class="numerator"&gt;16&lt;/span&gt;&lt;span class="ignored"&gt;)/(&lt;/span&gt;&lt;span class="denominator"&gt;6&lt;sup&gt;3&lt;/sup&gt;&lt;/span&gt;&lt;span class="ignored"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;For 5's? Ugh. I can't enumerate them manually. So. I'll use &lt;tt class="docutils literal"&gt;itertools&lt;/tt&gt; to emit all &lt;span class="formula"&gt;6&lt;sup&gt;3&lt;/sup&gt; = 216&lt;/span&gt; combinations.&lt;/p&gt;
&lt;p&gt;This isn't quite the same as simulation. The simulation &lt;em&gt;probably&lt;/em&gt; hit all the combinations.
The &lt;tt class="docutils literal"&gt;itertools&lt;/tt&gt; approach will absolutely create all of the combinations.&lt;/p&gt;
&lt;p&gt;Here's the central part of enumerating all combinations:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
import itertools

d6 = [n+1 for n in range(6)]
for c in itertools.product(d6, d6, d6):
    # do something with c
&lt;/pre&gt;
&lt;p&gt;The &lt;tt class="docutils literal"&gt;itertools.product()&lt;/tt&gt; will enumerate all 3-item combinations of the values in the &lt;tt class="docutils literal"&gt;d6&lt;/tt&gt; sequence.&lt;/p&gt;
&lt;p&gt;Here it is in context.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
import itertools
from collections import defaultdict

d6 = [n+1 for n in range(6)]
mid_3d6 = defaultdict(list)
for c in itertools.product(d6, d6, d6):
    mid_3d6[mid(c)].append(c)
for k in sorted(mid_3d6):
    print(k, len(mid_3d6[k]), [''.join(map(str, v)) for v in mid_3d6[k]])
&lt;/pre&gt;
&lt;p&gt;We created a &lt;tt class="docutils literal"&gt;defaultdict&lt;/tt&gt; object, a dictionary that will -- if a key is not found -- jam in a an empty &lt;tt class="docutils literal"&gt;list&lt;/tt&gt;. When we evaluate  &lt;tt class="docutils literal"&gt;mid_3d6[mid(c)]&lt;/tt&gt; it will either&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;find a list in the dictionary, because this value of &lt;tt class="docutils literal"&gt;mid(c)&lt;/tt&gt; has been seen before, OR&lt;/li&gt;
&lt;li&gt;jam a new empty list into the dictionary, because the value has not been seen before.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Either way, &lt;tt class="docutils literal"&gt;mid_3d6[mid(c)]&lt;/tt&gt; is a list, and we can &lt;tt class="docutils literal"&gt;append(c)&lt;/tt&gt; to put another combination into that list. Why save them?&lt;/p&gt;
&lt;p&gt;So we can display the count and all the patterns.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
6 16 ['166', '266', '366', '466', '566', '616', '626', '636', '646', '656', '661', '662', '663', '664', '665', '666']
&lt;/pre&gt;
&lt;p&gt;A 6 is the middle value &lt;span class="formula"&gt;&lt;span class="textfraction"&gt;&lt;span class="ignored"&gt;(&lt;/span&gt;&lt;span class="numerator"&gt;16&lt;/span&gt;&lt;span class="ignored"&gt;)/(&lt;/span&gt;&lt;span class="denominator"&gt;216&lt;/span&gt;&lt;span class="ignored"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; times. And there are the 16 patterns, to make it perfectly clear what's going on.&lt;/p&gt;
&lt;p&gt;The sequence of 16-40-52-52-40-16 looks a lot like it is part of the binomial function.
Looking at the text patterns, I can work out the following.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;span class="formula"&gt;&lt;i&gt;P&lt;/i&gt;(6) = &lt;i&gt;P&lt;/i&gt;(1) = &lt;span class="fraction"&gt;&lt;span class="ignored"&gt;(&lt;/span&gt;&lt;span class="numerator"&gt;1 + 3×5&lt;/span&gt;&lt;span class="ignored"&gt;)/(&lt;/span&gt;&lt;span class="denominator"&gt;6&lt;sup&gt;3&lt;/sup&gt;&lt;/span&gt;&lt;span class="ignored"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class="formula"&gt;&lt;i&gt;P&lt;/i&gt;(5) = &lt;i&gt;P&lt;/i&gt;(2) = &lt;span class="fraction"&gt;&lt;span class="ignored"&gt;(&lt;/span&gt;&lt;span class="numerator"&gt;1 + 3×5 + 6×4&lt;/span&gt;&lt;span class="ignored"&gt;)/(&lt;/span&gt;&lt;span class="denominator"&gt;6&lt;sup&gt;3&lt;/sup&gt;&lt;/span&gt;&lt;span class="ignored"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class="formula"&gt;&lt;i&gt;P&lt;/i&gt;(4) = &lt;i&gt;P&lt;/i&gt;(3) = &lt;span class="fraction"&gt;&lt;span class="ignored"&gt;(&lt;/span&gt;&lt;span class="numerator"&gt;1 + 3×5 + 6×4 + 4×3&lt;/span&gt;&lt;span class="ignored"&gt;)/(&lt;/span&gt;&lt;span class="denominator"&gt;6&lt;sup&gt;3&lt;/sup&gt;&lt;/span&gt;&lt;span class="ignored"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Beyond this, I'm lost.&lt;/p&gt;
&lt;p&gt;But.&lt;/p&gt;
&lt;p&gt;Simulation showed me the way forward, and it wasn't much code.&lt;/p&gt;
&lt;/div&gt;
</content><category term="Python"></category><category term="games"></category><category term="tutorial"></category></entry><entry><title>The Echo-Pipe Trap [Updated]</title><link href="https://slott56.github.io/2023-08-30-the_echo_pipe_trap.html" rel="alternate"></link><published>2023-08-30T09:00:00-04:00</published><updated>2023-08-30T09:00:00-04:00</updated><author><name>S.Lott</name></author><id>tag:slott56.github.io,2023-08-30:/2023-08-30-the_echo_pipe_trap.html</id><summary type="html">&lt;p&gt;This is a &lt;strong&gt;great&lt;/strong&gt; question.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://fosstodon.org/&amp;#64;JustineSmithies/110979871574705636"&gt;https://fosstodon.org/&amp;#64;JustineSmithies/110979871574705636&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This works, they said.&lt;/p&gt;
&lt;blockquote&gt;
echo -en &amp;quot;Firefox\0icon\x1fweechat&amp;quot; | fuzzel -d -w 100 -l 10&lt;/blockquote&gt;
&lt;p&gt;But. The superficial switch to &lt;tt class="docutils literal"&gt;subprocess.Popen()&lt;/tt&gt; doesn't work.&lt;/p&gt;
&lt;p&gt;Why?&lt;/p&gt;
&lt;p&gt;The way &lt;tt class="docutils literal"&gt;echo&lt;/tt&gt; works varies from shell to shell. When MacOSX changes to zsh, things …&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is a &lt;strong&gt;great&lt;/strong&gt; question.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://fosstodon.org/&amp;#64;JustineSmithies/110979871574705636"&gt;https://fosstodon.org/&amp;#64;JustineSmithies/110979871574705636&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This works, they said.&lt;/p&gt;
&lt;blockquote&gt;
echo -en &amp;quot;Firefox\0icon\x1fweechat&amp;quot; | fuzzel -d -w 100 -l 10&lt;/blockquote&gt;
&lt;p&gt;But. The superficial switch to &lt;tt class="docutils literal"&gt;subprocess.Popen()&lt;/tt&gt; doesn't work.&lt;/p&gt;
&lt;p&gt;Why?&lt;/p&gt;
&lt;p&gt;The way &lt;tt class="docutils literal"&gt;echo&lt;/tt&gt; works varies from shell to shell. When MacOSX changes to zsh, things can break.
Or when you share it with someone else, who uses YetAnotherShell, things break.&lt;/p&gt;
&lt;p&gt;Two choices:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Specify which shell.&lt;/li&gt;
&lt;li&gt;Stop using the &lt;tt class="docutils literal"&gt;echo ... |&lt;/tt&gt; (echo-pipe) construct.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="section" id="what-s-better"&gt;
&lt;h2&gt;What's Better?&lt;/h2&gt;
&lt;p&gt;The &lt;tt class="docutils literal"&gt;stdin&lt;/tt&gt; parameter to &lt;tt class="docutils literal"&gt;Popen()&lt;/tt&gt; can be used to provide the required stream of bytes.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
from pathlib import Path
import subprocess

temp = Path.cwd() / &amp;quot;temp.tmp&amp;quot;
temp.write_text(&amp;quot;Firefox\0icon\0x1fweechat&amp;quot;)  # I think.

with temp.open() as echo_file:
    subprocess.Popen(['fuzzel', '-d', '-w', '100', '-l', '10'], stdin=echo_file)
&lt;/pre&gt;
&lt;p&gt;Something like the above will avoid the echo-pipe construct.&lt;/p&gt;
&lt;p&gt;But. It leaves a temporary file lying around. What to do?&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="slightly-better"&gt;
&lt;h2&gt;Slightly Better&lt;/h2&gt;
&lt;p&gt;This will cleanup the file. And. You don't have to pick a name.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
import tempfile
import subprocess

temp = tempfile.TemporaryFile(mode='w+')
with temp:
    temp.write(&amp;quot;Firefox\0icon\0x1fweechat&amp;quot;)  # I think.
    temp.seek(0)
    subprocess.Popen(['fuzzel', '-d', '-w', '100', '-l', '10'], stdin=temp)
&lt;/pre&gt;
&lt;p&gt;Seems kind of long. And it involves an additional problem. A file.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="but-there-s-a-file"&gt;
&lt;h2&gt;But. There's a FILE!&lt;/h2&gt;
&lt;p&gt;Yes. We &lt;strong&gt;can&lt;/strong&gt; create a pipe.  I think it's kind of hideous, though.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
import os
import subprocess

r, w = os.pipe()
readable = os.fdopen(r, 'r')
writeable = os.fdopen(w, 'w')
writeable.write(&amp;quot;Firefox\0icon\0x1fweechat&amp;quot;)  # I think.
writeable.close()
subprocess.Popen(['fuzzel', '-d', '-w', '100', '-l', '10'], stdin=readable)
readable.close()
&lt;/pre&gt;
&lt;p&gt;However. It's not too long.&lt;/p&gt;
&lt;p&gt;We can create a pleasant wrapper in the form
of a context manager.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="how-s-this"&gt;
&lt;h2&gt;How's This?&lt;/h2&gt;
&lt;p&gt;This seems pleasant, if you do a lot of this sort of thing.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
import os
import subprocess

class EchoPipe:
    def __init__(self, content):
        self.content = content

    def __enter__(self):
        r, w = os.pipe()
        self.readable = os.fdopen(r, 'r')
        writeable = os.fdopen(w, 'w')
        writeable.write(self.content)
        writeable.close()
        return self.readable

    def __exit__(self, exc_type, exc_value, traceback):
        self.readable.close()
&lt;/pre&gt;
&lt;p&gt;Once you have the &lt;tt class="docutils literal"&gt;EchoPipe&lt;/tt&gt; context, you can now write this.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
with EchoPipe(&amp;quot;Firefox\0icon\0x1fweechat&amp;quot;) as echo_pipe:
    subprocess.Popen(['fuzzel', '-d', '-w', '100', '-l', '10'], stdin=echo_pipe)
&lt;/pre&gt;
&lt;p&gt;Which is pretty close to the original terse shell stuff.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="and-this-update"&gt;
&lt;h2&gt;And this [Update]&lt;/h2&gt;
&lt;p&gt;Consider this...&lt;/p&gt;
&lt;pre class="literal-block"&gt;
subprocess.run(
    ['fuzzel', '-d', '-w', '100', '-l', '10'],
    input=&amp;quot;Firefox\0icon\0x1fweechat&amp;quot;,
    text=True
)
&lt;/pre&gt;
&lt;p&gt;It a very useful variant. This is -- perhaps -- the best of them all.&lt;/p&gt;
&lt;p&gt;I found the documentation is a bit hard to follow around this topic, so I was
completely taken by surprise when I was shown this.&lt;/p&gt;
&lt;/div&gt;
</content><category term="Python"></category><category term="python"></category><category term="shell"></category><category term="bash"></category></entry><entry><title>More Python Quirks Debunking</title><link href="https://slott56.github.io/2023-08-15-more_python_quirk_debunking.html" rel="alternate"></link><published>2023-08-15T09:00:00-04:00</published><updated>2023-08-15T09:00:00-04:00</updated><author><name>S.Lott</name></author><id>tag:slott56.github.io,2023-08-15:/2023-08-15-more_python_quirk_debunking.html</id><summary type="html">&lt;p&gt;Stuff I found on the internet that I have to disagree with.&lt;/p&gt;
&lt;p&gt;(And no, I didn't ask for clarification.
If the author posts things without supporting details it suggests they might lack the supporting
details. I can be charitable and assume they don't really care about providing useful information,
but …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Stuff I found on the internet that I have to disagree with.&lt;/p&gt;
&lt;p&gt;(And no, I didn't ask for clarification.
If the author posts things without supporting details it suggests they might lack the supporting
details. I can be charitable and assume they don't really care about providing useful information,
but are merely trolling for engagement. Yes. That's cruel.
I can't see how you take the time to have an opinion and not provide support for it.)&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A few of #Python 3 #quirks and #kludges&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Global Interpreter Lock&lt;/li&gt;
&lt;li&gt;Strong, dynamic typing&lt;/li&gt;
&lt;li&gt;Massive &lt;tt class="docutils literal"&gt;Any&lt;/tt&gt; hole in the type system&lt;/li&gt;
&lt;li&gt;Verbose class definition&lt;/li&gt;
&lt;li&gt;Declaration of instance attributes is their definitions in &lt;tt class="docutils literal"&gt;__init__()&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;Repetitious &lt;tt class="docutils literal"&gt;self&lt;/tt&gt; and kludgy &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;super().__init__()&lt;/span&gt;&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;Kludgy string-quotes to reference the class from within its definition&lt;/li&gt;
&lt;li&gt;Kludgy &lt;tt class="docutils literal"&gt;TypeVar&lt;/tt&gt; definition&lt;/li&gt;
&lt;li&gt;Absence of structural typing&lt;/li&gt;
&lt;li&gt;Need explicitly to convert iterator to list using &lt;tt class="docutils literal"&gt;list()&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;Usurping the &lt;tt class="docutils literal"&gt;id()&lt;/tt&gt; name&lt;/li&gt;
&lt;li&gt;Inner method may mutate referenced objects in the closure but may not mutate primitive values therein&lt;/li&gt;
&lt;li&gt;Kludgy &lt;tt class="docutils literal"&gt;main()&lt;/tt&gt; invocation&lt;/li&gt;
&lt;li&gt;Disconcerting lack of type information in the holdover documentation from the P2 days&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;Some of these might be good points. Some of these seem to be nonsense.
A bunch can't be interpreted, which I find madding.&lt;/p&gt;
&lt;div class="section" id="global-interpreter-lock"&gt;
&lt;h2&gt;1. Global Interpreter Lock&lt;/h2&gt;
&lt;p&gt;I'm not sure what this means. It's a solution to a specific problem.
It's -- I suppose -- a candidate &amp;quot;quirk&amp;quot; because it's an unusual solution to
the problem of assuring that data structure updates are atomic.&lt;/p&gt;
&lt;p&gt;It saves us from having to use explicit locks all over the place when updating
objects with complex state.&lt;/p&gt;
&lt;p&gt;The GIL-less Python proposals will require a bit more care in defining structures
useful in multithreaded environments. Is this a gain? It's disputable.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="strong-dynamic-typing"&gt;
&lt;h2&gt;2. Strong, dynamic typing&lt;/h2&gt;
&lt;p&gt;Yep. There it is. Quirk? Kluge? Dunno. It seems like a brilliant solution to a long-standing problem.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="massive-any-hole-in-the-type-system"&gt;
&lt;h2&gt;3. Massive &lt;tt class="docutils literal"&gt;Any&lt;/tt&gt; hole in the type system&lt;/h2&gt;
&lt;p&gt;Does this mean it's bad that &lt;strong&gt;mypy&lt;/strong&gt; assumes &lt;tt class="docutils literal"&gt;Any&lt;/tt&gt; for missing types?
If you don't like the &lt;strong&gt;mypy&lt;/strong&gt; assumptions, write type hints.&lt;/p&gt;
&lt;p&gt;Does this mean it's bad that you can use &lt;tt class="docutils literal"&gt;Any&lt;/tt&gt; to provide uninformative type hints?
If you don't like &lt;tt class="docutils literal"&gt;Any&lt;/tt&gt;, consider not using it as a type hint.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="verbose-class-definition"&gt;
&lt;h2&gt;4. Verbose class definition&lt;/h2&gt;
&lt;p&gt;Quirk?  I guess they've never seen Java.&lt;/p&gt;
&lt;p&gt;Kluge?  What would they prefer?&lt;/p&gt;
&lt;p&gt;What would they omit is the real question. From the item 6, below, I'm guessing
they don't like to have &lt;tt class="docutils literal"&gt;self&lt;/tt&gt; listed explicitly.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="declaration-of-instance-attributes-is-their-definitions-in-init"&gt;
&lt;h2&gt;5. Declaration of instance attributes is their definitions in &lt;tt class="docutils literal"&gt;__init__()&lt;/tt&gt;&lt;/h2&gt;
&lt;p&gt;First -- and most important -- there aren't any C- or Java- style declarations.
The instances are dynamic in every sense of the word.
The &lt;tt class="docutils literal"&gt;__new__()&lt;/tt&gt; method does almost nothing.&lt;/p&gt;
&lt;p&gt;I'll buy this as a legit quirk. It's a consequence of the way attributes
work, and logic is compelling and consistent.&lt;/p&gt;
&lt;p&gt;It's trivial to include type hints in the class definition, separate
from initialization in the &lt;tt class="docutils literal"&gt;__init__()&lt;/tt&gt; method. I find this helpful.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
class X:
    a: int
    b: float

    def __init__(self, a: str, b: str) -&amp;gt; None:
        self.a = int(a)
        self.b = float(b)
&lt;/pre&gt;
&lt;p&gt;It's potentially misleading: the &lt;tt class="docutils literal"&gt;a&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;b&lt;/tt&gt; appear to be class variables.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="repetitious-self-and-kludgy-super-init"&gt;
&lt;h2&gt;6. Repetitious &lt;tt class="docutils literal"&gt;self&lt;/tt&gt; and kludgy &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;super().__init__()&lt;/span&gt;&lt;/tt&gt;&lt;/h2&gt;
&lt;p&gt;The use of &lt;tt class="docutils literal"&gt;self&lt;/tt&gt; is not repetitious. It's explicit.&lt;/p&gt;
&lt;p&gt;Not sure what's klugy about &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;super().__init__()&lt;/span&gt;&lt;/tt&gt;. I guess they don't like writing &lt;tt class="docutils literal"&gt;__init__()&lt;/tt&gt; and
prefer having this assumed, also.&lt;/p&gt;
&lt;p&gt;This is -- to me -- flat our wrong.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="kludgy-string-quotes-to-reference-the-class-from-within-its-definition"&gt;
&lt;h2&gt;7. Kludgy string-quotes to reference the class from within its definition&lt;/h2&gt;
&lt;p&gt;I guess they'd prefer to have an explicitly complicated-looking forward reference
for a name. We could have a lot of &lt;tt class="docutils literal"&gt;class XYZ: defined_later()&lt;/tt&gt; constructs
to sort out circular references among classes.&lt;/p&gt;
&lt;p&gt;I guess they don't like this.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
class X:
    &amp;#64;classmethod
    def makes_X(cls: type[&amp;quot;X&amp;quot;], *args, **kwargs) -&amp;gt; &amp;quot;X&amp;quot;:
        ...
&lt;/pre&gt;
&lt;p&gt;It seems like a tedious &lt;tt class="docutils literal"&gt;X = &lt;span class="pre"&gt;ForwardRef('X')&lt;/span&gt;&lt;/tt&gt; would be required
to define the name &lt;tt class="docutils literal"&gt;X&lt;/tt&gt; before the actual class is defined.
See #8, below, they don't like that syntax. Does this mean they want a new statement for
forward references?&lt;/p&gt;
&lt;p&gt;Or. It would require &lt;strong&gt;mypy&lt;/strong&gt; to gaze more deeply at the parse tree to resolve
circular references. I'm not sure what they think would be better.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="kludgy-typevar-definition"&gt;
&lt;h2&gt;8. Kludgy &lt;tt class="docutils literal"&gt;TypeVar&lt;/tt&gt; definition&lt;/h2&gt;
&lt;p&gt;I'm guessing they want a new statement in the language instead of a function
in the &lt;tt class="docutils literal"&gt;typing&lt;/tt&gt; module.&lt;/p&gt;
&lt;p&gt;Since types are explicitly optional, new statements to handle types seems wrong to me.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="absence-of-structural-typing"&gt;
&lt;h2&gt;9. Absence of structural typing&lt;/h2&gt;
&lt;p&gt;This is confusing. The &lt;tt class="docutils literal"&gt;NamedTuple&lt;/tt&gt; provides structural types.&lt;/p&gt;
&lt;p&gt;I'm guessing they were hoping for some other classes to &lt;strong&gt;also&lt;/strong&gt; behave like
types in a structural system. It seems simplest to use &lt;tt class="docutils literal"&gt;NamedTuple&lt;/tt&gt;
and a functional style of programming.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="need-explicitly-to-convert-iterator-to-list-using-list"&gt;
&lt;h2&gt;10. Need explicitly to convert iterator to list using &lt;tt class="docutils literal"&gt;list()&lt;/tt&gt;&lt;/h2&gt;
&lt;p&gt;This is nonsense. What if the iterator is a sequence of pairs that
should be converted to a mapping with &lt;tt class="docutils literal"&gt;dict()&lt;/tt&gt;?&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="usurping-the-id-name"&gt;
&lt;h2&gt;11. Usurping the &lt;tt class="docutils literal"&gt;id()&lt;/tt&gt; name&lt;/h2&gt;
&lt;p&gt;Don't get this. The &lt;tt class="docutils literal"&gt;print()&lt;/tt&gt; name is also usurped by built-ins.
There are a dozen built-in function names that usurp other names one might want to use.
And all those keywords!  The name &lt;tt class="docutils literal"&gt;class&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;def&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;return&lt;/tt&gt; are all usurped
by keywords.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="inner-method-may-mutate-referenced-objects-in-the-closure-but-may-not-mutate-primitive-values-therein"&gt;
&lt;h2&gt;12. Inner method may mutate referenced objects in the closure but may not mutate primitive values therein&lt;/h2&gt;
&lt;p&gt;Primitives can't be mutated.&lt;/p&gt;
&lt;p&gt;Referenced objects can &lt;strong&gt;always&lt;/strong&gt; be mutated.&lt;/p&gt;
&lt;p&gt;It doesn't require an &amp;quot;inner&amp;quot; method. It's true for every function and method at all levels.&lt;/p&gt;
&lt;p&gt;I'm guessing the idea of mutable vs. immutable objects could be a quirk.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="kludgy-main-invocation"&gt;
&lt;h2&gt;13. Kludgy &lt;tt class="docutils literal"&gt;main()&lt;/tt&gt; invocation&lt;/h2&gt;
&lt;p&gt;Kludge? Really?  I guess they've never seen Java.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="disconcerting-lack-of-type-information-in-the-holdover-documentation-from-the-p2-days"&gt;
&lt;h2&gt;14. Disconcerting lack of type information in the holdover documentation from the P2 days&lt;/h2&gt;
&lt;p&gt;It's often helpful to provide an example of a documentation gap where
type information is totally missing (or is only present in a stubs file where it's not
automatically included by Sphinx). While I haven't seen any examples of missing type information in
Python or standard library documentation, that doesn't mean much. I only write books
about Python, I don't actually help maintain it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="summary"&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;p&gt;There's a good point:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Declaration of instance attributes is their definitions in &lt;tt class="docutils literal"&gt;__init__()&lt;/tt&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The reset is a mixture of&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;too vague to comment on,&lt;/li&gt;
&lt;li&gt;it's not clear what would be better, and&lt;/li&gt;
&lt;li&gt;wrong.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Mostly the former. Few of the latter. (#10 seems to be the stand-out for wrong.)&lt;/p&gt;
&lt;p&gt;It's important to think about these things when learning a language.
Some discussion of alterantives from other languages would make these points a lot
easier to interpret and understand.&lt;/p&gt;
&lt;p&gt;However, it's also important to understand why soem things are present in a language.
It's important to look a little more deeply at the language rules -- perhaps read the
relevant PEP's -- to see what alternatives have been proposed and discarded.&lt;/p&gt;
&lt;p&gt;In most cases, decisions aren't arbitrary, but reflect deeper considerations on the underlying
semantics of the language and the implementation details of the compiler and/or run-time.&lt;/p&gt;
&lt;/div&gt;
</content><category term="Python"></category><category term="python"></category><category term="community"></category></entry><entry><title>Python Quirks that aren't very quirky</title><link href="https://slott56.github.io/2023-08-01-python_quirks_that_arent_very_quirky.html" rel="alternate"></link><published>2023-08-01T09:00:00-04:00</published><updated>2023-08-01T09:00:00-04:00</updated><author><name>S.Lott</name></author><id>tag:slott56.github.io,2023-08-01:/2023-08-01-python_quirks_that_arent_very_quirky.html</id><summary type="html">&lt;p&gt;See &lt;a class="reference external" href="https://writing.peercy.net/p/python-quirks"&gt;https://writing.peercy.net/p/python-quirks&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Superficially, most of these are true.&lt;/p&gt;
&lt;p&gt;Looking a little more deeply, most of them are also presented in a somewhat misleading way.
A few set up a good punch-line. The &lt;strong&gt;Inheritance&lt;/strong&gt; one, for example, is funny.&lt;/p&gt;
&lt;p&gt;If the point is to force a …&lt;/p&gt;</summary><content type="html">&lt;p&gt;See &lt;a class="reference external" href="https://writing.peercy.net/p/python-quirks"&gt;https://writing.peercy.net/p/python-quirks&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Superficially, most of these are true.&lt;/p&gt;
&lt;p&gt;Looking a little more deeply, most of them are also presented in a somewhat misleading way.
A few set up a good punch-line. The &lt;strong&gt;Inheritance&lt;/strong&gt; one, for example, is funny.&lt;/p&gt;
&lt;p&gt;If the point is to force a deeper investigation, I think the piece might not be helpful.
I know too many people who would look at this list and say &amp;quot;See, Python is as bad as JavaScript.&amp;quot;
Or &amp;quot;That's why I only use perl.&amp;quot;
These are the sort of folks won't actually refer to the Python language reference manual to see what's going on.&lt;/p&gt;
&lt;p&gt;One of these &lt;strong&gt;is&lt;/strong&gt; a legitimate quirk.
The rest involve a little bit of &amp;quot;don't look at the man behind the curtain&amp;quot; mixed with &amp;quot;don't read the documentation.&amp;quot;&lt;/p&gt;
&lt;p&gt;To ease my own mental anguish, I'll include a slightly deeper dive into these language feaures.&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;Generators.&lt;/p&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;sorted()&lt;/tt&gt; creates a new list from the argument value. It's not a generator.
Comparing the resulting list to the argument is unsurprising.&lt;/p&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;reversed()&lt;/tt&gt; doesn't create a list. It is a generator. Since it can only
be used once, one use of the generator &lt;tt class="docutils literal"&gt;y&lt;/tt&gt; has a sequence of values.
The other use of the generator &lt;tt class="docutils literal"&gt;y&lt;/tt&gt; has no values.&lt;/p&gt;
&lt;p&gt;I suppose the single-use-of-a-generator featrure could be called a quirk.
Except it's well-documented, so, I'd argue that this simply exposes a language feature.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;References.&lt;/p&gt;
&lt;p&gt;The example fails to show how &lt;tt class="docutils literal"&gt;a&lt;/tt&gt; was created. It's not obvious
how the reused reference to a sublist was propogated throughout
the list.&lt;/p&gt;
&lt;p&gt;Missing:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
a = [[0]] * 5
&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Assignment.&lt;/p&gt;
&lt;p&gt;Not sure what the point of this is.
It doesn't even seem quirky.&lt;/p&gt;
&lt;p&gt;I guess they're astonished they can use something other than a trivial
variable in a &lt;tt class="docutils literal"&gt;for&lt;/tt&gt; statement.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Closures.&lt;/p&gt;
&lt;p&gt;My guess on this is they were hoping the &lt;tt class="docutils literal"&gt;i&lt;/tt&gt; variable would not be a single variable;
instead, a fresh, new variable would be created by the generator expression.
Perhaps other languages do this, and manufacture fresh, new variable bindings.&lt;/p&gt;
&lt;p&gt;Python has a (relatively) simple rule for variables: Local, Enclosing, Global, and Built-in.
There's no closure rule to create new variables. There are many good tutorials on the LEGB rule.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Inheritance.  This one is kind of funny.&lt;/p&gt;
&lt;p&gt;It's also, on reflection, unsurprising.
The &lt;tt class="docutils literal"&gt;type&lt;/tt&gt; type -- like all types -- is an &lt;tt class="docutils literal"&gt;object&lt;/tt&gt;. Mostly because almost everything is an object.
The &lt;tt class="docutils literal"&gt;object&lt;/tt&gt; type -- like all types -- is a &lt;tt class="docutils literal"&gt;type&lt;/tt&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Operator Chaining.&lt;/p&gt;
&lt;p&gt;This isn't a quirk at all.
This seems to be an exploration of precedence rules among operators.
It seems to be a matter of definition among &lt;tt class="docutils literal"&gt;==&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;and&lt;/tt&gt;, and &lt;tt class="docutils literal"&gt;in&lt;/tt&gt; operators.&lt;/p&gt;
&lt;p&gt;Also, it's not clear what &amp;quot;chaining&amp;quot; means here.
If &lt;tt class="docutils literal"&gt;1 + 2 + 3&lt;/tt&gt; is what they mean by &amp;quot;operator chaining&amp;quot;, then I think that may be the root
cause of the confusion. These are all binary operators with intermediate results.
Perhaps it can help to think of implicit ()'s around each binary operation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Identity.&lt;/p&gt;
&lt;p&gt;This is an optimization in the CPython interpreter to pre-allocate some integers.
This is a proper quirk. I'm glad it's on this list.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;NFKC Normalization.&lt;/p&gt;
&lt;p&gt;See &lt;a class="reference external" href="https://unicode.org/reports/tr15/"&gt;https://unicode.org/reports/tr15/&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This isn't Python. This is Unicode.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Default Arguments.&lt;/p&gt;
&lt;p&gt;This is pretty well-known. Some newbies discover it, and then
re-read the documentation that describes why this happens, and say &amp;quot;makes sense.&amp;quot;
Here's the rule: &lt;strong&gt;The mutable object is only created once; it's shared.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Most linters warn that this feature may not be doing what folks think it's doing.&lt;/p&gt;
&lt;p&gt;This appears in many other places. For example, default values for fields of
dataclasses cannot be mutable objects, because they'd be shared.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Whatever This Is.&lt;/p&gt;
&lt;p&gt;This isn't a quirk, it's a bug. It was fixed in Python 3.11, though. So it's much less interesting.
It remains a known bug until Python 3.10 end-of-life, 04 Oct 2026.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Python 2.&lt;/p&gt;
&lt;p&gt;Python 2 has been at end-of-life since 01 Jan 2020.
These kinds of things ceased to be interesting on that date.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In summary, and in conclusion, the identity of small integers is a legitimate quirk.
I like it. The inheritance is funny. I like that, too.&lt;/p&gt;
</content><category term="Python"></category><category term="python"></category><category term="community"></category></entry><entry><title>Two Problems with Python</title><link href="https://slott56.github.io/2023-07-25-two_problems_with_python.html" rel="alternate"></link><published>2023-07-25T09:00:00-04:00</published><updated>2023-07-25T09:00:00-04:00</updated><author><name>S.Lott</name></author><id>tag:slott56.github.io,2023-07-25:/2023-07-25-two_problems_with_python.html</id><summary type="html">&lt;p&gt;I want to call out two huge problems with Python.
I'm not the first to point these out, but they've been bothering me for a while.&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#surprising-changes"&gt;Surprising Changes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#dependency-hell"&gt;Dependency Hell&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I've provided them here to save folks from repeating these.
They're now officially &amp;quot;known&amp;quot; and there's no point in repeating …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I want to call out two huge problems with Python.
I'm not the first to point these out, but they've been bothering me for a while.&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#surprising-changes"&gt;Surprising Changes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#dependency-hell"&gt;Dependency Hell&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I've provided them here to save folks from repeating these.
They're now officially &amp;quot;known&amp;quot; and there's no point in repeating this again.
Write your blog posts about something else, please.&lt;/p&gt;
&lt;div class="section" id="surprising-changes"&gt;
&lt;h2&gt;Surprising Changes&lt;/h2&gt;
&lt;p&gt;Every language and library has changes. That's part of normal innovation and
evolution of the language.&lt;/p&gt;
&lt;p&gt;Some changes, however, were not communicated to me, personnally, and are therefore
suprising, which makes them bad. Really bad.&lt;/p&gt;
&lt;p&gt;Let's focus on linter tools as an example. Here's the scenario.&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;I have a code base. It's good. 100% compliant.&lt;/li&gt;
&lt;li&gt;I ugprade the linter.&lt;/li&gt;
&lt;li&gt;A new error is flagged. This was not an error before but &lt;strong&gt;somehow&lt;/strong&gt; (big eyeroll) it's an error now.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This is a surprising change. No one told me.&lt;/p&gt;
&lt;p&gt;The code &lt;em&gt;is&lt;/em&gt; sketchy. It could be seen as ambiguous. &lt;strong&gt;Even though it passes all the unit tests.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Someone else may have learned a lesson about sketchy code, and embodied that lesson in the linter.
But they didn't tell me.&lt;/p&gt;
&lt;p&gt;Python had a surprise change, and the mere presence of a surprise means one thing:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Python is useless&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="dependency-hell"&gt;
&lt;h2&gt;Dependency Hell&lt;/h2&gt;
&lt;p&gt;Every application has dependencies. That's part of building a language
in a rich ecosystem with a lot of useful packages.&lt;/p&gt;
&lt;p&gt;Some changes to these packages, while well-intentioned, can break a dependency with another package.
Packages have inter-dependencies, which I find &lt;strong&gt;impossible&lt;/strong&gt; to manage.&lt;/p&gt;
&lt;p&gt;Here's the scenario.&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;I have a code base. It's good. 100% tests pass. Installs perfectly on all supported platforms.&lt;/li&gt;
&lt;li&gt;Two packages, &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;p==3.14&lt;/span&gt;&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;q==2.78&lt;/span&gt;&lt;/tt&gt; both depend on &lt;tt class="docutils literal"&gt;x&lt;/tt&gt; version 1.1&lt;/li&gt;
&lt;li&gt;The authors of &lt;tt class="docutils literal"&gt;p&lt;/tt&gt; updated to &lt;tt class="docutils literal"&gt;4.0&lt;/tt&gt; and switched their dependency to to &lt;tt class="docutils literal"&gt;x&lt;/tt&gt; version 2.0. The authors of &lt;tt class="docutils literal"&gt;q&lt;/tt&gt; did not switch.&lt;/li&gt;
&lt;li&gt;If I include &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;p==4.0&lt;/span&gt;&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;x==2.0&lt;/span&gt;&lt;/tt&gt; the &lt;tt class="docutils literal"&gt;q&lt;/tt&gt; package breaks. I can't upgrade &lt;tt class="docutils literal"&gt;p&lt;/tt&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Dependency Hell.  Unresolvable Conflicts.&lt;/p&gt;
&lt;p&gt;Any combination of packages will have numerous internal dependencies.
The mere presence of these dependencies means one thing:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Python is useless&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="summary"&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Python is useless&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;I cannot tolerate innovation.&lt;/p&gt;
&lt;p&gt;If someone learns something and changes a linter, that's innovation: it breaks my code; I don't want it.&lt;/p&gt;
&lt;p&gt;If someone creates a new version of an open-source package, that's innovation: it breaks my code; I don't want it.&lt;/p&gt;
&lt;p&gt;This isn't to say that innovation is &lt;strong&gt;bad&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Innovation is &lt;strong&gt;good&lt;/strong&gt;. When it occurs very slowly, and I'm able to personally vet each individual change for impact on my project(s).&lt;/p&gt;
&lt;p&gt;The idea that every single open source package is innovating and learning at their own unique tempo
is insanity. It makes Python &lt;strong&gt;useless&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
</content><category term="Python"></category><category term="python"></category><category term="community"></category></entry><entry><title>Literate Programming with PyWebLP</title><link href="https://slott56.github.io/2023-07-18-literate_programming_with_pyweblp.html" rel="alternate"></link><published>2023-07-18T09:00:00-04:00</published><updated>2023-07-18T09:00:00-04:00</updated><author><name>S.Lott</name></author><id>tag:slott56.github.io,2023-07-18:/2023-07-18-literate_programming_with_pyweblp.html</id><summary type="html">&lt;p&gt;See &lt;a class="reference external" href="https://github.com/slott56/py-web-tool"&gt;https://github.com/slott56/py-web-tool&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;And &lt;a class="reference external" href="https://pypi.org/project/py-web-lp/"&gt;https://pypi.org/project/py-web-lp/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I finally made the PyWeb LP tool installable from PyPI.&lt;/p&gt;
&lt;p&gt;I need to fix the name of the GitHub repo (some day) to make it also say &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;py-web-lp&lt;/span&gt;&lt;/tt&gt;.
I should also fixup my tag cloud to say pyweblp …&lt;/p&gt;</summary><content type="html">&lt;p&gt;See &lt;a class="reference external" href="https://github.com/slott56/py-web-tool"&gt;https://github.com/slott56/py-web-tool&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;And &lt;a class="reference external" href="https://pypi.org/project/py-web-lp/"&gt;https://pypi.org/project/py-web-lp/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I finally made the PyWeb LP tool installable from PyPI.&lt;/p&gt;
&lt;p&gt;I need to fix the name of the GitHub repo (some day) to make it also say &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;py-web-lp&lt;/span&gt;&lt;/tt&gt;.
I should also fixup my tag cloud to say pyweblp instead of &lt;a class="reference external" href="https://slott56.github.io/tag/pyweb.html"&gt;pyweb&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I cleaned up a few small things in the project.&lt;/p&gt;
&lt;p&gt;This whole thing started a loooong time ago. See &lt;a class="reference external" href="https://slott56.github.io/2007_02_02-editing_docbook_xml.html"&gt;Editing DocBook XML&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Click the &lt;a class="reference external" href="https://slott56.github.io/tag/literate-programming.html"&gt;literate programming tag&lt;/a&gt; for a lot more on this topic.&lt;/p&gt;
&lt;p&gt;Background:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://slott56.github.io/2010_03_14-literate_programming.html"&gt;Literate Programming&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://slott56.github.io/2010_04_07-fancy_literate_programming.html"&gt;Fancy Literate Programming&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Also, I found &lt;cite&gt;pyLit&lt;/cite&gt;. See &lt;a class="reference external" href="https://slott56.github.io/2013_10_03-literate_programming_and_pylit.html"&gt;Literate Programming and PyLit&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;But, back to the PyWeb LP thread and more recent changes:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://slott56.github.io/2017_05_13-literate_programming_life_cycle.html"&gt;Literate Programming Life Cycle&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://slott56.github.io/2022_06_21-my_shifting_understanding_and_a_terrible_design_mistake.html"&gt;My Shifting Understanding and A Terrible Design Mistake&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://slott56.github.io/2022_06_28-massive_rework_of_data_structures.html"&gt;Massive Rework of Data Structures&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://slott56.github.io/2022_07_05-revised_understanding_revised_data_structures_revised_type_hints.html"&gt;Revised Understanding --&amp;gt; Revised Data Structures --&amp;gt; Revised Type Hints&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://slott56.github.io/2022_08_09-tragedy_averted.html"&gt;Tragedy Averted&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now, it's installable.&lt;/p&gt;
</content><category term="Python"></category><category term="python"></category><category term="literate programming"></category><category term="pyweb"></category></entry><entry><title>An Implementation of Annotated Types</title><link href="https://slott56.github.io/2023-07-11-an_implementation_of_annotated_types.html" rel="alternate"></link><published>2023-07-11T09:00:00-04:00</published><updated>2023-07-11T09:00:00-04:00</updated><author><name>S.Lott</name></author><id>tag:slott56.github.io,2023-07-11:/2023-07-11-an_implementation_of_annotated_types.html</id><summary type="html">&lt;p&gt;The &lt;tt class="docutils literal"&gt;typing&lt;/tt&gt; module includes the mysterious-looking &lt;tt class="docutils literal"&gt;Annotated&lt;/tt&gt; type hint.
See &lt;a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Annotated"&gt;https://docs.python.org/3/library/typing.html#typing.Annotated&lt;/a&gt; for details.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference internal" href="#what-does-this-do"&gt;What does this do?&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class="reference internal" href="#why-do-i-need-it"&gt;Why do I need it?&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class="reference internal" href="#where-can-i-see-examples"&gt;Where can I see examples?&lt;/a&gt;&lt;/p&gt;
&lt;div class="section" id="what-does-this-do"&gt;
&lt;h2&gt;What does this do?&lt;/h2&gt;
&lt;p&gt;The &lt;tt class="docutils literal"&gt;Annotated&lt;/tt&gt; type hint lets us append &amp;quot;details&amp;quot; to a …&lt;/p&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;The &lt;tt class="docutils literal"&gt;typing&lt;/tt&gt; module includes the mysterious-looking &lt;tt class="docutils literal"&gt;Annotated&lt;/tt&gt; type hint.
See &lt;a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Annotated"&gt;https://docs.python.org/3/library/typing.html#typing.Annotated&lt;/a&gt; for details.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference internal" href="#what-does-this-do"&gt;What does this do?&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class="reference internal" href="#why-do-i-need-it"&gt;Why do I need it?&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class="reference internal" href="#where-can-i-see-examples"&gt;Where can I see examples?&lt;/a&gt;&lt;/p&gt;
&lt;div class="section" id="what-does-this-do"&gt;
&lt;h2&gt;What does this do?&lt;/h2&gt;
&lt;p&gt;The &lt;tt class="docutils literal"&gt;Annotated&lt;/tt&gt; type hint lets us append &amp;quot;details&amp;quot; to a type.&lt;/p&gt;
&lt;p&gt;It might look like this&lt;/p&gt;
&lt;pre class="literal-block"&gt;
x: Annotated[int, MustBePrime()]
&lt;/pre&gt;
&lt;p&gt;The annotated type has one origin type (which must be first) and a sequence of objects. Presumably, they are &amp;quot;annotations&amp;quot; of some kind.
They can be anything. We can do a lot with them; we'll start with using them to narrow the domain of values.&lt;/p&gt;
&lt;p&gt;The core &lt;tt class="docutils literal"&gt;x: int&lt;/tt&gt; provides a large domain of possible values. Python's ints can be immense numbers, easily filling memory with digits.&lt;/p&gt;
&lt;p&gt;The &lt;tt class="docutils literal"&gt;MustBePrime&lt;/tt&gt; class is the kind of thing that might be used to narrow the domain of allowed
values to prime numbers.&lt;/p&gt;
&lt;div class="section" id="when-does-this-value-checking-happen"&gt;
&lt;h3&gt;When does this value checking happen?&lt;/h3&gt;
&lt;p&gt;I'm glad you asked.&lt;/p&gt;
&lt;p&gt;Use of annotated types is &lt;strong&gt;not&lt;/strong&gt; part of the Python run-time. Annotated type arguments are essentially ignored.
The origin type is used by tools like &lt;strong&gt;mypy&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Any further use of annotations is a thing your application or tool-chain will need to do.&lt;/p&gt;
&lt;p&gt;An application can see the annotations for an object using the &lt;tt class="docutils literal"&gt;__annotations__&lt;/tt&gt; special attribute number,
or use the &lt;tt class="docutils literal"&gt;typing.get_type_hints()&lt;/tt&gt; function.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;&amp;gt;&amp;gt; from typing import Annotated, get_type_hints
&amp;gt;&amp;gt;&amp;gt; class MustBePrime:
...     pass
...

&amp;gt;&amp;gt;&amp;gt; class SomeApp:
...     x: Annotated[int, MustBePrime()]
...

&amp;gt;&amp;gt;&amp;gt; get_type_hints(SomeApp)
{'x': &amp;lt;class 'int'&amp;gt;}
&amp;gt;&amp;gt;&amp;gt; get_type_hints(SomeApp, include_extras=True)
{'x': typing.Annotated[int, &amp;lt;__main__.MustBePrime object at 0x7fde259a7be0&amp;gt;]}
&amp;gt;&amp;gt;&amp;gt; get_type_hints(SomeApp, include_extras=True)['x']
typing.Annotated[int, &amp;lt;__main__.MustBePrime object at 0x7fde259a7be0&amp;gt;]
&lt;/pre&gt;
&lt;p&gt;We can see the annotated type hint for &lt;tt class="docutils literal"&gt;x&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;This means, our application is free to &amp;quot;apply&amp;quot; the annotation in some way.&lt;/p&gt;
&lt;p&gt;&amp;quot;&lt;strong&gt;Whoa!  That's vague&lt;/strong&gt;,&amp;quot; you say. &amp;quot;There are no specific rules for annotated types?&amp;quot;&lt;/p&gt;
&lt;p&gt;I agree.&lt;/p&gt;
&lt;p&gt;The details are up to your app.  Seriously.  Define them in a way that makes sense.&lt;/p&gt;
&lt;p&gt;Maybe you want your app looks like this:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;&amp;gt;&amp;gt; class SomeApp:
....    x: Annotated[int, MustBePrime()]
...     def __init__(self, arg_value: int) -&amp;gt; None:
...         self.x = arg_value
...
&lt;/pre&gt;
&lt;p&gt;And you've got a use case in mind...&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;&amp;gt;&amp;gt; sa = SomeApp(42)
Traceback (most recent call last):
   ...
ValueError: value 42 is not prime
&lt;/pre&gt;
&lt;p&gt;The idea is that this specific app has an associated collection of annotations that are used
during &lt;tt class="docutils literal"&gt;__init__()&lt;/tt&gt; processing to further validate the supplied values.&lt;/p&gt;
&lt;p&gt;The code to this is &lt;em&gt;clearly&lt;/em&gt; part of &lt;tt class="docutils literal"&gt;SomeApp&lt;/tt&gt; -- maybe a metaclass, maybe a superclass -- but
clearly part of the app.&lt;/p&gt;
&lt;p&gt;And the app will use the annotation as a kind of &amp;quot;plug-in&amp;quot; or &amp;quot;extension&amp;quot; or &lt;strong&gt;Strategy&lt;/strong&gt; design pattern to do some additional processing at some point.&lt;/p&gt;
&lt;p&gt;Our use case was part of &lt;tt class="docutils literal"&gt;__init__()&lt;/tt&gt; processing.  What does this look like?&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="an-example-app"&gt;
&lt;h3&gt;An example app&lt;/h3&gt;
&lt;p&gt;We'll avoid metaclasses, and pretend that Annotated types are checked by an
explict call to a method of the class.
Let's say a superclass, named &lt;tt class="docutils literal"&gt;RuleCheck&lt;/tt&gt; has a method that must be
called at the end of &lt;tt class="docutils literal"&gt;__init__()&lt;/tt&gt; to check compliance with annotations.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
class SomeApp(RuleCheck):
    x: Annotated[int, MustBePrime()]

    def __init__(self, arg_value: int) -&amp;gt; None:
        self.x = arg_value
        self.check()
&lt;/pre&gt;
&lt;p&gt;The idea here is that the class-level hints are carefully defined.&lt;/p&gt;
&lt;p&gt;The &lt;tt class="docutils literal"&gt;__init__()&lt;/tt&gt; merely slaps any old value in there.&lt;/p&gt;
&lt;p&gt;And the &lt;tt class="docutils literal"&gt;self.check()&lt;/tt&gt; then assures that all hints are actually true for the supplied
values.&lt;/p&gt;
&lt;p&gt;This means it will &amp;quot;apply&amp;quot; the annotation to the given value. In this case,
it will either allow the value silently or raise an exception if there's a problem.&lt;/p&gt;
&lt;p&gt;Here's the &lt;tt class="docutils literal"&gt;RuleCheck&lt;/tt&gt; class.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
from typing import Annotated, get_type_hints, get_args

class RuleCheck:
    def check(self) -&amp;gt; None:
        vars = get_type_hints(self.__class__, include_extras=True)
        for name in vars:
            match vars[name]:
                case Annotated:
                   base, *rules = get_args(vars[name])
                   for rule in rules:
                       rule(getattr(self, name))
&lt;/pre&gt;
&lt;p&gt;Each annotated variable has the arguments to the annotation
retrieved with &lt;tt class="docutils literal"&gt;typing.get_args()&lt;/tt&gt;.
Each of these annotations must be a callable object of some kind
that can be applied to the attribute's value.&lt;/p&gt;
&lt;p&gt;We leave the implementation of &lt;tt class="docutils literal"&gt;MustBePrime&lt;/tt&gt; as an exercise for the reader.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="why-do-i-need-it"&gt;
&lt;h2&gt;Why do I need it?&lt;/h2&gt;
&lt;p&gt;You need it in a bunch of cases. Here are some ideas.&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Type domain narrowing. We used &amp;quot;prime&amp;quot; as an example. You might want to use positive values, or
values in a range. Or other properties that you'd like to make part of a type.&lt;/li&gt;
&lt;li&gt;Documentation. You can imagine &lt;tt class="docutils literal"&gt;x: Annotated[str, &lt;span class="pre"&gt;title(&amp;quot;Some&lt;/span&gt; Descriptive &lt;span class="pre"&gt;Information&amp;quot;),&lt;/span&gt; &lt;span class="pre"&gt;Positive()]&lt;/span&gt;&lt;/tt&gt;.
Since the documentation is not a comment or other ephermeral source text, you can use this
to create a formal Schema for a class. Thing JSONSchema. (Or XSD if you're old.)
You could use the title to beef up the exception messages, for example.&lt;/li&gt;
&lt;li&gt;Other Processing. Let's not get crazy, but the following is possible.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class="literal-block"&gt;
x: Annotated[float, Title(&amp;quot;Independent&amp;quot;), Range(0, 10)]
y: Annotated[float, DerivedFrom(&amp;quot;x&amp;quot;), Function(lambda x: 2*x-1)]
&lt;/pre&gt;
&lt;p&gt;The idea is that we might build a class where any change to &lt;tt class="docutils literal"&gt;x&lt;/tt&gt; computes a value
for &lt;tt class="docutils literal"&gt;y&lt;/tt&gt; based on the annotation; and the value is cached as an attribute
value, not a &lt;tt class="docutils literal"&gt;&amp;#64;property&lt;/tt&gt; which is always recompued.&lt;/p&gt;
&lt;p&gt;(Yes, &lt;tt class="docutils literal"&gt;&amp;#64;cache&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;&amp;#64;property&lt;/tt&gt; can do this. This isn't necessarily a &lt;strong&gt;great&lt;/strong&gt; idea.
But it's possible.)&lt;/p&gt;
&lt;div class="section" id="building-a-type-definition"&gt;
&lt;h3&gt;Building a type definition&lt;/h3&gt;
&lt;p&gt;Maybe we want this.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
PosInt: TypeAlias = Annotated[int, MustBePositive()]
PrimePosInt: TypeAlias = Annotated[PosInt, MustBePrime()]
&lt;/pre&gt;
&lt;p&gt;We've built a complicated type on top of another complicated type.&lt;/p&gt;
&lt;p&gt;This permits us to -- for example -- improve the performance of &lt;tt class="docutils literal"&gt;MustBePositive&lt;/tt&gt; with an attendant speedup of other, related objects.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="file-parsing"&gt;
&lt;h3&gt;File Parsing&lt;/h3&gt;
&lt;p&gt;This is an edge case. But. It applies to the vast number of files processed by COBOL programs.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
x: Annotated[str, Start(0), Length(5)]
y: Annotated[str, Start(5), Length(10)]
z: Annotated[Decimal, Start(15), Length(10), Scale(2)]
&lt;/pre&gt;
&lt;p&gt;We've provided the metadata for positions of the source data in a text document.
A file with a line like &lt;tt class="docutils literal"&gt;&amp;quot;ABCDEZYXWVUTSRQ0000001299&amp;quot;&lt;/tt&gt; could be parsed by a class
that leveraged the annotations to pluck values out of the source string.
It could apply conversion from mainframe encodings (&amp;quot;EBCDIC&amp;quot;) and do &lt;tt class="docutils literal"&gt;decimal&lt;/tt&gt; conversion.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="where-can-i-see-examples"&gt;
&lt;h2&gt;Where can I see examples?&lt;/h2&gt;
&lt;p&gt;I have two examples, right now.&lt;/p&gt;
&lt;p&gt;Pydantic v2 Annotated Validators: &lt;a class="reference external" href="https://docs.pydantic.dev/latest/usage/validators/#annotated-validators"&gt;https://docs.pydantic.dev/latest/usage/validators/#annotated-validators&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Wow is this cool.&lt;/p&gt;
&lt;p&gt;Also.&lt;/p&gt;
&lt;p&gt;TigerShark. &lt;a class="reference external" href="https://github.com/slott56/TigerShark"&gt;https://github.com/slott56/TigerShark&lt;/a&gt;  This is a pretty narrow problem domain.
But, the Annotated type hints were a &lt;em&gt;perfect&lt;/em&gt; solution to an ages-old problem.
The X12 messages have complex more-or-less hierarchical structure. Messages have Loops (that can repeat), Segments, and individual Data Elements.&lt;/p&gt;
&lt;p&gt;The definitions of the messages have complicated meta-data on size, encoding, data types,
optionality, etc., and etc.&lt;/p&gt;
&lt;p&gt;What we want is a top-level definition of a message that looks like this:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
class MSG270(Message):
    &amp;quot;&amp;quot;&amp;quot;HIPAA Health Care Eligibility Inquiry X092A1-270&amp;quot;&amp;quot;&amp;quot;
    ItemIsa_Loop: TypeAlias = Annotated[ISA_LOOP, Title('Interchange Control Header'), Usage('R'), Position(1), Required(True)]
    isa_loop: Annotated[list[ItemIsa_Loop], MinItems(1)]
&lt;/pre&gt;
&lt;p&gt;The TypeAlias and Annotated type provide all the metadata for this message.&lt;/p&gt;
&lt;p&gt;Looking elsewhere in the message module, we find this...&lt;/p&gt;
&lt;pre class="literal-block"&gt;
class ISA_LOOP_ISA(Segment):
    &amp;quot;&amp;quot;&amp;quot;Interchange Control Header&amp;quot;&amp;quot;&amp;quot;
    _segment_name = 'ISA'

    isa01: Annotated[I01, Title('Authorization Information Qualifier'), Usage('R'), Position(1), Enumerated(*['00', '03'])]

    isa02: Annotated[I02, Title('Authorization Information'), Usage('R'), Position(2)]

    isa03: Annotated[I03, Title('Security Information Qualifier'), Usage('R'), Position(3), Enumerated(*['00', '01'])]
&lt;/pre&gt;
&lt;p&gt;Again, the elements are defined (entirely) by annotations.&lt;/p&gt;
&lt;p&gt;The base type? &lt;tt class="docutils literal"&gt;I01&lt;/tt&gt;?  A pool of common definitions.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
I01: TypeAlias = Annotated[ID, MinLen(2), MaxLen(2)]
&lt;/pre&gt;
&lt;p&gt;But wait! That still depends on a more foundational definition, &lt;tt class="docutils literal"&gt;ID&lt;/tt&gt;.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ID: TypeAlias = str
&lt;/pre&gt;
&lt;p&gt;The idea of this is to map the type information to type aliases, so anyone
can follow the message definitions completely. The annotations are defined
formally by the X12/EDI standards; the mapping to Python is through these
foundational type aliases for Python types.&lt;/p&gt;
&lt;p&gt;Also see &lt;a class="reference external" href="https://pypi.org/project/TigerShark3/"&gt;https://pypi.org/project/TigerShark3/&lt;/a&gt; if you have the urge to install it.&lt;/p&gt;
&lt;/div&gt;
</content><category term="Python"></category><category term="patterns"></category><category term="python"></category><category term="type-hints"></category></entry><entry><title>Behave Tests and Fixtures</title><link href="https://slott56.github.io/2023_01_27-behave_tests_and_fixtures.html" rel="alternate"></link><published>2023-01-27T08:00:00-05:00</published><updated>2023-01-27T08:00:00-05:00</updated><author><name>S.Lott</name></author><id>tag:slott56.github.io,2023-01-27:/2023_01_27-behave_tests_and_fixtures.html</id><summary type="html">&lt;div class="section" id="bluf"&gt;
&lt;h2&gt;BLUF&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Behave&lt;/strong&gt; fixtures totally rock for testing
complex applications.&lt;/p&gt;
&lt;p&gt;I had been doing them wrong. Doing them right is simpler.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="history"&gt;
&lt;h2&gt;History&lt;/h2&gt;
&lt;p&gt;I'm a fan of the Gherkin language for specifying
the behavior of software.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Scenario: Works for Me

Given a configuration
When a request is made
Then the response can …&lt;/pre&gt;&lt;/div&gt;</summary><content type="html">&lt;div class="section" id="bluf"&gt;
&lt;h2&gt;BLUF&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Behave&lt;/strong&gt; fixtures totally rock for testing
complex applications.&lt;/p&gt;
&lt;p&gt;I had been doing them wrong. Doing them right is simpler.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="history"&gt;
&lt;h2&gt;History&lt;/h2&gt;
&lt;p&gt;I'm a fan of the Gherkin language for specifying
the behavior of software.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Scenario: Works for Me

Given a configuration
When a request is made
Then the response can be evaluated.
&lt;/pre&gt;
&lt;p&gt;I love this.&lt;/p&gt;
&lt;p&gt;What I particularly love is the way &lt;strong&gt;Behave's&lt;/strong&gt; &lt;tt class="docutils literal"&gt;steps&lt;/tt&gt; package
provide implementations for the individual steps of the scenario.&lt;/p&gt;
&lt;p&gt;The steps can be organized around technical needs,
where the features are organized around the user's experience
when operating the software.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="the-non-fixture-approach"&gt;
&lt;h2&gt;The Non-Fixture Approach&lt;/h2&gt;
&lt;p&gt;For a long time, I used the &lt;tt class="docutils literal"&gt;Given&lt;/tt&gt; step and an &lt;tt class="docutils literal"&gt;after_scenario()&lt;/tt&gt;
function in &lt;strong&gt;Behave's&lt;/strong&gt; environment module to create and destroy fixtures.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Scenario: Test with Mock API

Given a server running on http://127.0.0.1:8000
And the server has the resource requested
When a client makes some random request or other
Then the response is a tidy bit of data the user just loves
&lt;/pre&gt;
&lt;p&gt;The &lt;tt class="docutils literal"&gt;Given&lt;/tt&gt; step would seed the context with details used
to configure a tiny, specialized service built with
Python's &lt;tt class="docutils literal"&gt;http.server&lt;/tt&gt; module. This separate subprocess would provide
an appropriate response for this scenario.&lt;/p&gt;
&lt;p&gt;The mock server srequired creating a request handling class hierarchy
with reusable and extensible choices for the
various scenarios and features.
Often only one or two paths would be handled, since that's all
a scenario needed.&lt;/p&gt;
&lt;p&gt;The context parameters were turned into command-line options.
The mini server was started by the &lt;tt class="docutils literal"&gt;When&lt;/tt&gt; step and stopped
(eventually) after the scenario.&lt;/p&gt;
&lt;p&gt;This was workable. But. Ultimately. Dumb.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="fixtures"&gt;
&lt;h2&gt;Fixtures&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Behave&lt;/strong&gt; has a much, much better way to configure
and manage fixtures. This is great for tests that
databases or RESTful API servers or other, separate processes
to collaborate with.&lt;/p&gt;
&lt;p&gt;Fixtures.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;#64;fixture.the_mock_server
Scenario: Test with Mock API

Given a server running on http://127.0.0.1:8000
And the server has the resource requested
When a client makes some random request or other
Then the response is a tidy bit of data the user just loves
&lt;/pre&gt;
&lt;p&gt;There's one change to the scenario -- a tag with &lt;tt class="docutils literal"&gt;&amp;#64;fixture.&lt;/tt&gt; to positively identify
a fixture required for this scenario to make sense.&lt;/p&gt;
&lt;p&gt;When reviewing the Gherkin with users, the &lt;tt class="docutils literal"&gt;&amp;#64;fixture&lt;/tt&gt; tag
is easy to explain. There are often other tags throughout
the scenarios. A &lt;tt class="docutils literal"&gt;&amp;#64;slow&lt;/tt&gt; tag, for example, might be used for those
scenarios that involve throttling or timeouts. A &lt;tt class="docutils literal"&gt;&amp;#64;future&lt;/tt&gt; tag
for those options that aren't required but can be tested
to observe development progress. For one project I had a &lt;tt class="docutils literal"&gt;&amp;#64;core&lt;/tt&gt; tag
that recapitulated the examples in the documentation --- these &lt;strong&gt;had&lt;/strong&gt; to work
exactly as shown.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="infrastructure"&gt;
&lt;h2&gt;Infrastructure&lt;/h2&gt;
&lt;p&gt;The fixture infrastructure has three parts.&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Our specific fixture-managing generator function. This will create the fixture, yield something, and then destroy the fixture. This precisely parallels the way &lt;strong&gt;pytest&lt;/strong&gt; fixtures work.&lt;/li&gt;
&lt;li&gt;A &lt;tt class="docutils literal"&gt;before_tag()&lt;/tt&gt; function in the environment to look for the tags and do any setup or logging required.&lt;/li&gt;
&lt;li&gt;The fixture itself. This is our specialized test-case server based on &lt;tt class="docutils literal"&gt;http.server&lt;/tt&gt;. It still uses a configuration file or command-line options -- or both -- to define some behavior required for the scenario.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;What happens, then, is this.&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;The &lt;tt class="docutils literal"&gt;before_tag()&lt;/tt&gt; function is evaluated for every tag on every step.
If a tag starts with &lt;tt class="docutils literal"&gt;&amp;quot;fixture.&amp;quot;&lt;/tt&gt; then, something special needs to be done.&lt;/li&gt;
&lt;li&gt;The &lt;tt class="docutils literal"&gt;before_tag()&lt;/tt&gt; function will evaluate the &lt;tt class="docutils literal"&gt;behave.use_fixture()&lt;/tt&gt; function to inject
our specific fixture-managing generator function into the step processing.&lt;/li&gt;
&lt;li&gt;The fixture will be created (and destroyed) as part of the scenario's execution.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;(If you need details, see &lt;a class="reference external" href="https://behave.readthedocs.io/en/stable/fixtures.html#fixture-cleanup-points"&gt;https://behave.readthedocs.io/en/stable/fixtures.html#fixture-cleanup-points&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;The mapping from &lt;tt class="docutils literal"&gt;&amp;quot;fixture.this_special_api&amp;quot;&lt;/tt&gt; to
a generator function named &lt;tt class="docutils literal"&gt;this_special_api()&lt;/tt&gt; is kind
of trivial. So trivial that the examples in the &lt;strong&gt;Behave&lt;/strong&gt;
documentation suggest you look these up in a map in
the simplest possible way.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
TAG_IMPLEMENTATIONS = {
    &amp;quot;the_mock_server&amp;quot;: server_fixture_generator,
    &amp;quot;the_other_server&amp;quot;: another_fixture_generator,
    &amp;quot;the_timeout_server&amp;quot;: the_timeout_server
}

def before_tag(context, tag):
    if tag.startswith(&amp;quot;fixture.&amp;quot;):
        _, name = tag.split('.')
        use_fixture(TAG_IMPLEMENTATIONS[name], context)
&lt;/pre&gt;
&lt;p&gt;There's a &lt;tt class="docutils literal"&gt;use_fixture_by_tag()&lt;/tt&gt; function that may be considered to be simpler
than my example.&lt;/p&gt;
&lt;p&gt;Now, we can add fixtures by writing a generator
function to create (and destroy) the fixture
and adding the new function to the &lt;tt class="docutils literal"&gt;TAG_IMPLEMENTATIONS&lt;/tt&gt; mapping.&lt;/p&gt;
&lt;p&gt;The fixture names are for users who might want to review
the scenarios. They're subject to the same kind of negotiation
the rest of the Gherkin terminology is. Sometimes, you'll
tweak the wording as the user's understanding (and needs)
evolve.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="cleanup"&gt;
&lt;h2&gt;Cleanup&lt;/h2&gt;
&lt;p&gt;When you have serious problems in your test implementation,
you'll have tiny cleanup issues.&lt;/p&gt;
&lt;p&gt;For example, if your step implementation code is broken,
the test can crash without having executed all
the steps you anticipated.&lt;/p&gt;
&lt;p&gt;This can mean a fixture isn't properly torn down.
It's a rare, but annoying thing to happen.&lt;/p&gt;
&lt;p&gt;See &lt;a class="reference external" href="https://behave.readthedocs.io/en/stable/fixtures.html#ensure-fixture-cleanups-with-fixture-setup-errors"&gt;https://behave.readthedocs.io/en/stable/fixtures.html#ensure-fixture-cleanups-with-fixture-setup-errors&lt;/a&gt; for
some solutions.&lt;/p&gt;
&lt;p&gt;I'm a fan of leaving information about the fixture in the context,
and using &lt;tt class="docutils literal"&gt;after_scenario()&lt;/tt&gt; or &lt;tt class="docutils literal"&gt;after_feature()&lt;/tt&gt; functions
to kill long-running process in the rare case that a step failed.&lt;/p&gt;
&lt;p&gt;The alternative, using &lt;tt class="docutils literal"&gt;add_cleanup()&lt;/tt&gt;, is -- perhaps -- nicer,
because it relies on a closure that doesn't clutter the
context with these little, technical overheads. (I find closures
a little awkward to debug, but, debugging is rarely needed
for this.)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="books"&gt;
&lt;h2&gt;Books&lt;/h2&gt;
&lt;p&gt;Yes, this is for a book.
Stay tuned. Later this year.&lt;/p&gt;
&lt;/div&gt;
</content><category term="Python"></category><category term="books"></category><category term="software design"></category><category term="test driven development"></category></entry><entry><title>Testing RESTful web services in Django -- Tantalizingly Close.</title><link href="https://slott56.github.io/2008_08_13-testing_restful_web_services_in_django_tantalizingly_close.html" rel="alternate"></link><published>2008-08-13T10:10:00-04:00</published><updated>2008-08-13T10:10:00-04:00</updated><author><name>S.Lott</name></author><id>tag:slott56.github.io,2008-08-13:/2008_08_13-testing_restful_web_services_in_django_tantalizingly_close.html</id><summary type="html">&lt;p&gt;Here's what's great about &lt;a class="reference external" href="http://www.djangoproject.com"&gt;Django&lt;/a&gt;  coupled with the &lt;a class="reference external" href="http://code.google.com/p/django-rest-interface/"&gt;Django-REST Interface&lt;/a&gt; :  It's almost all model.  You define the model, write some tests.  Add the URL mappings, write some tests using the built-in Django client.&lt;/p&gt;
&lt;p&gt;We're almost there, but this doesn't work out perfectly.  To do complete tests, we have to either …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Here's what's great about &lt;a class="reference external" href="http://www.djangoproject.com"&gt;Django&lt;/a&gt;  coupled with the &lt;a class="reference external" href="http://code.google.com/p/django-rest-interface/"&gt;Django-REST Interface&lt;/a&gt; :  It's almost all model.  You define the model, write some tests.  Add the URL mappings, write some tests using the built-in Django client.&lt;/p&gt;
&lt;p&gt;We're almost there, but this doesn't work out perfectly.  To do complete tests, we have to either subclass the Django Client to add &amp;quot;put&amp;quot; and &amp;quot;delete&amp;quot; or curry in methods for &amp;quot;put&amp;quot; and &amp;quot;delete&amp;quot;.  Then we can almost test our complete set of web services functions.&lt;/p&gt;
&lt;p&gt;At this point, the core of the application is -- well -- done.  It works, it handles the web services requests.  We can then start folding in HTML pages for the endlessly negotiated human interface.&lt;/p&gt;
&lt;p&gt;However, we're still not ready for deployment.&lt;/p&gt;
&lt;div class="section" id="authorization-differences"&gt;
&lt;h2&gt;Authorization Differences&lt;/h2&gt;
&lt;p&gt;First, we haven't really got a solid security model in place.  Sure, we can add &amp;#64;login_required decorators to any view functions.  But that doesn't really secure the REST interface at all.  That's where the going gets tough.&lt;/p&gt;
&lt;p&gt;The Django-REST Collection has an 'authentication' attribute that checks passwords.  It has an HttpDigestAuthentication class that handles more-secure password digests.  This looks perfect for web services.  But, it has two problems.&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;We don't have MD5 digests readily available.  Django uses SHA1 digests of password only, not an MD5 digest of username:realm:password.&lt;/li&gt;
&lt;li&gt;We can't easily test using digest authentication with the off-the-shelf Django test Client.  Not only does the test client lack Put and Delete, but it can't handle HTTP Digest authentication, either.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Sigh.  I thought we'd be done in &lt;a class="reference external" href="http://showmedo.com/videos/video?name=2000080&amp;amp;fromSeriesID=200"&gt;20 minutes&lt;/a&gt; .  Turns out, I have to actually do some work.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="adding-md5-digests"&gt;
&lt;h2&gt;Adding MD5 Digests&lt;/h2&gt;
&lt;p&gt;MD5 digests seem to work out best with the 'Profile' extension to the Django authorization application.  The model is delightfully simple, just a single CharField to hold the MD5 hexdigest of username:realm:password.&lt;/p&gt;
&lt;p&gt;One consequence is that we now have two password digests, the default SHA1 in the User model and our Web Services MD5 in the Profile extension.  This means that our page for password resets must have a view that sets both passwords.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="testing-complications"&gt;
&lt;h2&gt;Testing Complications&lt;/h2&gt;
&lt;p&gt;In the long run, we have to provide WS client libraries.  While the application is entirely RESTful, the marketplace expects an API library that they can install.  We have to provide Python, .NET and Java libraries to invoke our service.  This isn't very complex.&lt;/p&gt;
&lt;p&gt;For Python, it would be simplest to leverage the &lt;a class="reference external" href="http://docs.python.org/lib/module-urllib2.html"&gt;urllib2&lt;/a&gt;  package.   We can provide some classes which act as remote procedure call proxies; these classes have methods that invoke our REST services (GET, POST, PUT and DELETE) on various resources or collections.&lt;/p&gt;
&lt;p&gt;Something like the following:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
class MyProxy( object ):
    def __init__( self, host, port, username, password, realm ):
        self.urlBase= &amp;quot;http://%s:%s&amp;quot; % ( host, port )
        # Build Handler to support HTTP Digest Authentication...
        digest_handler = urllib2.HTTPDigestAuthHandler()
        if username is not None:
            digest_handler.add_password(realm, self.urlBase, username, password)
        # Build Handler to support HTTP Basic Authentication...
        basic_handler = urllib2.HTTPBasicAuthHandler()
        if username is not None:
            basic_handler.add_password(realm, self.urlBase, username, password)
        # Build Handler to treat 201 as a normal response, not an exception...
        error_handler= RESTHTTPHandler()
        self.server = urllib2.build_opener(digest_handler,basic_handler,error_handler)
    def request( self, method, uri ):
        assert method in ( &amp;quot;GET&amp;quot;, &amp;quot;POST&amp;quot;, &amp;quot;PUT&amp;quot;, &amp;quot;DELETE&amp;quot; )
        data= urllib.urlencode( argDict )
        theReq= RESTRequest( method, self.urlBase + path, data )
        try:
            response= self.server.open( theReq )
            # fold in attributes that are compatible with Django HttpResponse
            response.status_code = response.code
            response.content= response.read()
            return response
        except:
            ... handle various kinds of IOError, HTTPError exceptions...
    def getSomeResource( self, key ):
        response= self.request( &amp;quot;GET&amp;quot;, &amp;quot;/path/to/resource/%s&amp;quot; % key )
        ... examine response.content, maybe do simplejson decode or xml.etree parse...
&lt;/pre&gt;
&lt;p&gt;The problem is that the Django test client and the urllib2 packages are wildly incompatible.&lt;/p&gt;
&lt;p&gt;Okay, maybe not &lt;em&gt;wildly&lt;/em&gt; , but seriously incompatible.&lt;/p&gt;
&lt;p&gt;First, the Django Client's HttpResopnse includes attributes status_code and content.  The urllib2.addinfourl response uses code and is -- itself -- a file-like object.&lt;/p&gt;
&lt;p&gt;Second, and more important, the Django Client's HttpResponse is a dictionary full of headers.  The urllib2.addinfourl is a file with an info() method that contains the headers.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="choices"&gt;
&lt;h2&gt;Choices&lt;/h2&gt;
&lt;p&gt;We have a tantalizing set of alternatives.&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Make urllib2's response look more like Django's response.  This requires adding a few additional attributes, and a __getitem__ method.  Not too difficult to do.  But only because our unit tests are not very demanding.&lt;/li&gt;
&lt;li&gt;Create a Facade over urllib2.addinfourl and django.http.HttpResponse that is independent of both, and can work with both as implementation classes.  While cool-sounding, and easy to implement in our WS client package, we'd have to do a tiny bit of extra work in our unit tests to create a Facade-based client rather than use the default client.&lt;/li&gt;
&lt;li&gt;Get a proper Python RESTful client.  Like &lt;a class="reference external" href="http://restclient.org/"&gt;RESTClient&lt;/a&gt;  or &lt;a class="reference external" href="http://code.google.com/p/python-rest-client/"&gt;Python-rest-client&lt;/a&gt; .  The approach in &lt;a class="reference external" href="http://www.infectmac.com/2008/08/restful-python.html"&gt;RESTful Python&lt;/a&gt;  -- a decorator -- is another possibility.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The problem with #1 is that the Python client package we distribute will have this odd-looking design that adds a bunch of random-looking features to urllib2.addinfourl.  A lot of explanation (like this Blog posting) doesn't remove the oddness.  The Java and .Net packages will be fine.&lt;/p&gt;
&lt;p&gt;The problem with #2 is that the Python client package will be even more complex than #1, with little recognizable value to anyone for the complexity.&lt;/p&gt;
&lt;p&gt;There's no problem with #3.  Indeed, this might be best in the long run.&lt;/p&gt;
&lt;/div&gt;
</content><category term="Python"></category><category term="#python"></category><category term="unit testing"></category></entry><entry><title>The Schema Evolution Problem</title><link href="https://slott56.github.io/2008_08_06-the_schema_evolution_problem.html" rel="alternate"></link><published>2008-08-06T10:21:00-04:00</published><updated>2008-08-06T10:21:00-04:00</updated><author><name>S.Lott</name></author><id>tag:slott56.github.io,2008-08-06:/2008_08_06-the_schema_evolution_problem.html</id><summary type="html">&lt;p&gt;Fundamentally, we need to provide explicit version identification on a schema.   This is technically easy, but organizationally nearly impossible.&lt;/p&gt;
&lt;p&gt;Technically, we need to use some kind of version control software for our model and the resulting DDL.  We need some meta-meta-data to track schema names and version numbers.  If we …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Fundamentally, we need to provide explicit version identification on a schema.   This is technically easy, but organizationally nearly impossible.&lt;/p&gt;
&lt;p&gt;Technically, we need to use some kind of version control software for our model and the resulting DDL.  We need some meta-meta-data to track schema names and version numbers.  If we like doing too much work, we can introduce a meta-meta-data table with schema name and version numbers.  If we're lazy, there's an even simpler, more reliable approach.&lt;/p&gt;
&lt;p&gt;Organizationally, we need the discipline to track every single schema change and determine the level of compatibility with application software.  Garden-variety ALTER statements (to add columns, or extend the size of a column) won't break software; bumping the minor version number is fine.  Adding new tables or views won't break software.  Renames and drops, however, will break software and require a bump to the major version number.&lt;/p&gt;
&lt;div class="section" id="what-is-a-schema"&gt;
&lt;h2&gt;What is a Schema?&lt;/h2&gt;
&lt;p&gt;First, a schema isn't the &lt;em&gt;entire&lt;/em&gt;  set of metadata in a single database instance.  Even if your data is organized in one massive, flat schema with thousands of tables, you still have many smaller &amp;quot;schema&amp;quot; within that single SQL schema owned by &amp;quot;PROD&amp;quot; or &amp;quot;OPS&amp;quot; or &amp;quot;DBA&amp;quot; or &amp;quot;SYS&amp;quot; or whoever owns your production tables.&lt;/p&gt;
&lt;p&gt;We'll distinguish between the practical, conceptual schema and the often-misused SQL schema.  Sometimes they overlap, but this is rare.&lt;/p&gt;
&lt;p&gt;Your smaller conceptual schemas are the &amp;quot;application-specific&amp;quot; subsets of your overall SQL schema.  If you're smart, your SQL schemas match your conceptual schemas.  If you're lazy, you have a single massive SQL schema and use table name prefixes to try and separate tables into smaller conceptual schemas.&lt;/p&gt;
&lt;p&gt;Here's the bottom-line suggestion. Use SQL schema.  Don't use table prefixes.&lt;/p&gt;
&lt;p&gt;[In a Big IT organization, this can't happen because it would &amp;quot;break everything&amp;quot;.  Everyone depends on there being a single, flat anonymous schema.  This isn't true, as new applications and maintenance to existing applications are an opportunity to restructure the SQL schema to match the actual use of the tables.  Sadly, it only reduces future maintenance costs, so it doesn't have any current-year impact, so no one ever does this.]&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="what-about-the-applications"&gt;
&lt;h2&gt;What About the Applications?&lt;/h2&gt;
&lt;p&gt;The applications exist independent of the data.  Stored procedures (&lt;a class="reference external" href="https://slott56.github.io/2008_08_03-stored_procedures_are_a_configuration_management_nightmare_revised.html"&gt;A Configuration Management Nightmare&lt;/a&gt; ) are in the application model, not the data model, and evolve independently from the data schema.  However, this isn't always understood, and stored procedures are often mis-managed.&lt;/p&gt;
&lt;p&gt;An application could check the schema meta-meta-data to be sure that the application is compatible with the schemas it uses.  It can be a simple query, and an exception gets thrown to indicate that the application can't start and run with the given mix of database schemas.  We know that production programs shouldn't work with the new, upgraded integration test database.  However, we also see this happen; sometimes they crash and we fix them, other times they don't crash, but don't produce right answers, either.  Sigh.&lt;/p&gt;
&lt;p&gt;There's a simpler approach, however, than a query.&lt;/p&gt;
&lt;p&gt;Should the application and schema version numbers track?  Should the application go through version 2.1.2 and 2.1.3 to indicate that it requires schema version 2.1?  Not necessarily.  There is not a tidy 1:1 mapping between software components and database schema objects.  Generally, database schema objects are shared -- widely -- by software components.  Version 2.1 of application X and version 4.2 of application Y may both depend on version 3.x of database schema Z.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="how-to-make-this-work"&gt;
&lt;h2&gt;How To Make This Work&lt;/h2&gt;
&lt;p&gt;Put the version number in the schema name.&lt;/p&gt;
&lt;p&gt;First, don't create a bunch of XYZ_table1, XYZ_table2 names in a single, flat schema.  Create table1 and table2 in schema XYZ.  Use lots of schemas.  That's why they're available to you.&lt;/p&gt;
&lt;p&gt;[Yes, your historical, legacy applications didn't use schemas.  I'm aware that this is new.  Start now.]&lt;/p&gt;
&lt;p&gt;Second, don't simply create a &amp;quot;timeless&amp;quot; XYZ schema, use the major release number as part of the name.  Create an XYZ_2 schema.  This will work for all 2.x versions of the schema.&lt;/p&gt;
&lt;p&gt;When you move to version 3.1, create a new XYZ_3 schema.  &lt;strong&gt;New&lt;/strong&gt;.  Migrate the data from the XYZ_2 schema.  Then, rename XYZ_2 to XYZ_2_OLD, so that any program that improperly uses the old schema will throw an exception and die.  When you need to recover the space, you can drop the XYZ_2_OLD schema, knowing that no program is expected to use it; any program that does use it, needs a fix.&lt;/p&gt;
&lt;p&gt;Wait!  That's potentially a lot of code to touch.  Or, if your a mainframer, that's a lot of programs that need to be rebound to the new SQL.  Yep.  It is.  It's a trivial administrative task.  If you can't recompile or rebind your programs, you have serious quality issues that you &lt;strong&gt;must&lt;/strong&gt;  fix.&lt;/p&gt;
&lt;p&gt;If you can't make simple SQL changes, you have serious flaws in your application software and your overall IT processes.  You &lt;strong&gt;must&lt;/strong&gt;  fix these application design flaws and organizational process flaws.  I'm sorry for pointing this out.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="implementation-steps"&gt;
&lt;h2&gt;Implementation Steps&lt;/h2&gt;
&lt;p&gt;Name your schema.  Allocate your tables to appropriate schema.  More schemas is a better approach than fewer schemas.  There's no performance penalty.  Design and maintenance are simpler.  When you design software, You don't design a single, massive, does-everything application, you write small, focused application programs.  Your database, similarly, should be structured in small, conceptually simple modules.&lt;/p&gt;
&lt;p&gt;For Java programmers, use &lt;a class="reference external" href="http://ibatis.apache.org/"&gt;iBatis&lt;/a&gt;  to extract your SQL from your programs.  The schema changes will be isolated to the iBatis configuration files, mostly.&lt;/p&gt;
&lt;p&gt;For Python programmers, you can use &lt;a class="reference external" href="http://www.sqlalchemy.org/"&gt;SQLAlchemy&lt;/a&gt;  to isolate most of the SQL from your overall application.  Put each schema definition in a separate &amp;quot;models&amp;quot; file.  Include the SQLAlchemy table definitions as well as the Python classes and the mappings.  You can, without too much difficulty, include a few convenience functions that will create or drop-and-create the schema.&lt;/p&gt;
&lt;p&gt;If you're creating Python/Django applications, consider including the schema version number on your Django application name.  Your Django project folder for a given site might include things like someapp_1 and someapp_2.  The older application (someapp_1) has one model, and the newer version (someapp_2) has the expanded, incompatible model.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="change-management"&gt;
&lt;h2&gt;Change Management&lt;/h2&gt;
&lt;p&gt;Rather than mess with an complex, risky in-place conversion, you are &lt;em&gt;adding&lt;/em&gt;  to the database.  You can write a simple batch application to create the someapp_2 data objects from the someapp_1 objects.  Once the data is migrated, you can switch the settings.py and the urls.py files to use someapp_2 instead of someapp_1.  You can easily dry-run this conversion process in an integration test or staging instance of your web site.  If it works there, you can do it again in production.&lt;/p&gt;
&lt;p&gt;The best part about keeping the two schema in parallel for a time is the ability to fall-back to the previous version and try the conversion again after fixing the bugs.  You're never replacing anything; you're simply adding a schema and directing the application programs at the new schema.&lt;/p&gt;
&lt;/div&gt;
</content><category term="Python"></category><category term="#python"></category><category term="database"></category></entry><entry><title>Stored Procedures Are A Configuration Management Nightmare (revised)</title><link href="https://slott56.github.io/2008_08_03-stored_procedures_are_a_configuration_management_nightmare_revised.html" rel="alternate"></link><published>2008-08-03T16:44:00-04:00</published><updated>2008-08-03T16:44:00-04:00</updated><author><name>S.Lott</name></author><id>tag:slott56.github.io,2008-08-03:/2008_08_03-stored_procedures_are_a_configuration_management_nightmare_revised.html</id><summary type="html">&lt;p&gt;I've been asked about the proper location of Stored Procedures more than once.  I've come down very strongly in opposition to triggers and stored procedures.&lt;/p&gt;
&lt;p&gt;First, &lt;a class="reference external" href="https://slott56.github.io/2007_05_27-plsql_and_java_the_benchmark_challenge_revised.html"&gt;PL/SQL is slow&lt;/a&gt; .  Anecdotally, people claim that introducing PL/SQL made an app faster.  I submit that they restructured the application significantly to …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've been asked about the proper location of Stored Procedures more than once.  I've come down very strongly in opposition to triggers and stored procedures.&lt;/p&gt;
&lt;p&gt;First, &lt;a class="reference external" href="https://slott56.github.io/2007_05_27-plsql_and_java_the_benchmark_challenge_revised.html"&gt;PL/SQL is slow&lt;/a&gt; .  Anecdotally, people claim that introducing PL/SQL made an app faster.  I submit that they restructured the application significantly to create small, focused transactions, and that's what created the improvement.  As a practical matter, you need to write focused, PL/SQL-like transaction methods in your Java programs.  While technically possible, you can't casually execute SQL statements willy-nilly.&lt;/p&gt;
&lt;p&gt;Second, it's hard to do configuration management on stored procedures.  Not impossible, but very hard.  The reasons are entirely organizational.&lt;/p&gt;
&lt;p&gt;Recently I received an email that was nearly opaque, but seemed to indicate that the organization couldn't clone production to create another test, and couldn't rationalize the versions of their various stored procedures.   I think they wanted a puff of &lt;strong&gt;Faerie Dust&lt;/strong&gt;™ that would allow stored procedure X to determine if it was being used by package Y or package Z and behave differently in the different contexts.  The request makes no sense -- this is just a version control issue.  Clearly, there are two versions of X, but the emailer claimed there was one version of X and it had to determine it's behavior dynamically.&lt;/p&gt;
&lt;div class="section" id="conflation-the-organizational-root-cause"&gt;
&lt;h2&gt;Conflation - The Organizational Root Cause&lt;/h2&gt;
&lt;p&gt;A stored procedure lives in the database.  Consequently, it's conflated with persistent data and schema definitions and assigned -- for no good reason -- to the DBA's.  These three things -- data, schema and processing -- have little to do with each other.  They emphatically do not belong together.   However, they're almost always conflated into a murky puddle of SQL.&lt;/p&gt;
&lt;p&gt;Let's break these things apart.&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;&lt;strong&gt;Data&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;is the organization's actual data.  Some (but not all) of the business records lives in managed databases.  Some live in desktop application documents (word processing, spreadsheets, unmanaged desktop databases, etc.)  Data is precious, perhaps the most precious thing in the organization.&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;Schema&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;(or metadata) is table, column, view and index definitions.  It's also physical stuff like tablespaces, files, instances, etc.  Some of this is important, some of it is subject to change without notice.  Tablespace configuration parameters rarely matter except as an implementation detail.&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;Processing&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;is triggers, stored procedures and all of the application programs that live outside the database.  Note that there is no crisp distinction between &amp;quot;low-level&amp;quot; and &amp;quot;high-level&amp;quot; processing.  Many DBA's have tried to explain to me that CRUD rules are &amp;quot;low-level&amp;quot;, but then they add some foreign-key relationships, after that they also need to add some many-to-many relationships and the intermediate bridge tables, then they start adding other things that are part of larger and more complex relationships.  Stop!  If you can't find a boundary easily, it doesn't really exist.&lt;/dd&gt;
&lt;/dl&gt;
&lt;/div&gt;
&lt;div class="section" id="version-control"&gt;
&lt;h2&gt;Version Control&lt;/h2&gt;
&lt;p&gt;Data -- typically -- has fairly loose version control.  The RDBMS often has secret sequence numbers (SCN's) that are used internally to manage cache and synchronize physical files.  These transaction sequence numbers are, effectively, a kind of version number for the data.&lt;/p&gt;
&lt;p&gt;Often, we'll have a &amp;quot;last changed date&amp;quot; in a database record.  This is a surrogate version number for the record.  It tells us when the data changed.  Most applications don't record a complete change log for the data, we simply update the change date.  A few applications do create detailed change logs.  In some cases, people try to leverage the database logging facilities to back into a formal change log for the data.&lt;/p&gt;
&lt;p&gt;Schema is rarely under any kind of version control.  Metadata is often the least disciplined part of the enterprise infrastructure.  It's easy (really easy) to have formal version control over metadata.  It's rarely done, however.  For some reason, DBA's don't seem to use version control software.&lt;/p&gt;
&lt;p&gt;Application software, typically, has the best version control.  Many organizations use some formal version control software (CVS, Subversion or some commercial product like MKS, VSS or PVCS.)  This can easily apply version control information to the source code (and even the resulting .class files.)&lt;/p&gt;
&lt;p&gt;[Some organizations can't even put their application software under version control.  This doesn't change the issue of conflating data, schema and application.]&lt;/p&gt;
&lt;p&gt;For no good reason stored procedures are the province of the DBA's (who don't use version control software.)  Consequently, the external application software (in Java, Python or whatever) may have version control information, but the stored procedures never have version control.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="schema-versions"&gt;
&lt;h2&gt;Schema Versions&lt;/h2&gt;
&lt;p&gt;The database schema (the tables, columns, indexes, views and sequence generators) has a version number.  The version number for a schema -- like the version number for software -- defines &amp;quot;compatibility&amp;quot;.&lt;/p&gt;
&lt;p&gt;Schema version 2.1 and 2.2 are &amp;quot;compatible&amp;quot; in some sense.  Schema versions 3.5 and 4.1 are incompatible.&lt;/p&gt;
&lt;p&gt;What defines &amp;quot;compatibility&amp;quot;?  Clearly, &amp;quot;compatible&amp;quot; means &amp;quot;compatible with SQL DML&amp;quot;.  If you've done standard database ALTER statements (adding columns, expanding the sizes of columns) or changing indexes or adding views, you haven't broken any SQL DML.  The old SQL still works with the new schema.  This is a 2.2 to 2.3 kind of change.&lt;/p&gt;
&lt;p&gt;If you've dropped a column or table or view, or you've shortened a column, or changed the type of a column, then you've made a change which may break existing SQL.  When you've make this kind of change, you'll need to bump the major version number.&lt;/p&gt;
&lt;p&gt;You need two things:&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;&lt;strong&gt;Discipline&lt;/strong&gt;.&lt;/dt&gt;
&lt;dd&gt;This doesn't happen by default.&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;Some meta-meta-data&lt;/strong&gt;.&lt;/dt&gt;
&lt;dd&gt;A table that has schema names and version numbers is all you really need.  It's nice to fold in &amp;quot;applicable dates&amp;quot; and &amp;quot;responsible person&amp;quot;, etc., but not essential.   In some cases, you can use database comments for this.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;When you make database changes, you must create a script that (a) makes the change and (b) updates the database schema version table.  That's about it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="what-about-stored-procedures"&gt;
&lt;h2&gt;What About Stored Procedures?&lt;/h2&gt;
&lt;p&gt;Why can't we annotate our stored procedures with version numbers and put them under version control like the rest of the database?&lt;/p&gt;
&lt;p&gt;The question is rhetorical.  Of course we can put stored procedures under version control.  It just requires some discipline.  And -- perhaps -- making stored procedures part of application software's responsibility, and not part of the DBA's job.&lt;/p&gt;
&lt;p&gt;If we take stored procedures away from the DBA's, we need a formal turnover procedure for putting a particular suite of stored procedures into a database.&lt;/p&gt;
&lt;p&gt;Separating the stored procedures from the schema via a formal turnover has some marvelous consequences.&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;You can reconstruct the stored procedures from your source code repository exactly the same way you extract your Python or Java.  Indeed, you can make a complete software package with all of the various language elements.  You can extract all of the procedure creates as a big script and run it any time you need to.&lt;/li&gt;
&lt;li&gt;The database has two distinct parts:  the Data, the Processing.  These two are matched by schema version number.  The DBA's are responsible for the data; the schema versions; the preservation of essential corporate information.  The DBA's are also responsible for running the scripts that upgrade that portion of the application software that happens to live in the database.  The DBA's aren't responsible for stored procedures.&lt;/li&gt;
&lt;li&gt;The migration of a database from development to test is a two-part job.  Move the schema and data from the developers to a test environment.  Separately, run all of the scripts to build the proper software version that matches the schema of the data.&lt;/li&gt;
&lt;li&gt;You have explicit compatibility checks.  Version 2.x of schema and software are being used in production.  Version 3.x of schema and software is in some kind of parallel test prior to conversion.  Version 3.y of schema and software is in some early test; 3.z is in development.&lt;/li&gt;
&lt;li&gt;You can begin to wean yourself away from the nightmare of stored procedure management.  Once you take this out of the DBA's hands, you find that a consistent set of Python (or Java) packages that define the Model layer does everything that stored procedures and triggers do, only more simply and more maintainably.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="what-s-so-hard"&gt;
&lt;h2&gt;What's So Hard?&lt;/h2&gt;
&lt;p&gt;It's very easy to put stored procedures under explicit, clear version control.  With a little care, even a database schema can be put under version control.&lt;/p&gt;
&lt;p&gt;What's so hard is actually making the organizational change.  Ask around.  The DBA's will tell you that they are overworked, because they're &amp;quot;forced&amp;quot; to write all the stored procedures and triggers.  Forced?  By whom?&lt;/p&gt;
&lt;p&gt;Generally, the &amp;quot;organization&amp;quot; seems to mandate that everything SQL -- tables, columns, indexes, views, stored procedures and triggers -- pass through the DBA's.  The distinction between data and processing is somehow lost.  Splitting it up will often anger the manager of the DBA's, who'll make the case that no one else can be trusted to create stored procedures.&lt;/p&gt;
&lt;p&gt;When testing stops because of version control issues, when production fails, it seems like the problem should be addressed.  It's usually obvious that there are serious version control problems between the schema and stored procedures.&lt;/p&gt;
&lt;p&gt;I only know that there's a long-standing, steadfast refusal to split the database into data and processing elements.  The consequence of this is that stored procedures are unmaintainable, testing is nearly impossible, and production problems are rampant.&lt;/p&gt;
&lt;p&gt;Consequently, I suggest that stored procedures and triggers never be used.  Ever.&lt;/p&gt;
&lt;/div&gt;
</content><category term="Python"></category><category term="#python"></category><category term="database"></category></entry><entry><title>Denormalization or "What did you mean by that?"</title><link href="https://slott56.github.io/2008_06_14-denormalization_or_what_did_you_mean_by_that.html" rel="alternate"></link><published>2008-06-14T11:59:00-04:00</published><updated>2008-06-14T11:59:00-04:00</updated><author><name>S.Lott</name></author><id>tag:slott56.github.io,2008-06-14:/2008_06_14-denormalization_or_what_did_you_mean_by_that.html</id><summary type="html">&lt;p&gt;I use the word denormalization heavily, to make a point to a certain class of developers.  Other developers object to the term, since it doesn't have a precise meaning.&lt;/p&gt;
&lt;p&gt;The point I often have to make this:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;3rd Normal Form is for Updates.&lt;/li&gt;
&lt;li&gt;Data Warehousing is about Insert and Select …&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;p&gt;I use the word denormalization heavily, to make a point to a certain class of developers.  Other developers object to the term, since it doesn't have a precise meaning.&lt;/p&gt;
&lt;p&gt;The point I often have to make this:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;3rd Normal Form is for Updates.&lt;/li&gt;
&lt;li&gt;Data Warehousing is about Insert and Select; there are no Updates (to speak of).&lt;/li&gt;
&lt;li&gt;Consequently, the traditional normalization rules (Third Normal Form a/k/a 3NF) doesn't apply to data warehousing.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;My habit is to describe the star-schema (or snowflake schema) as &amp;quot;denormalized&amp;quot;.  This isn't really correct, but it does emphasize my point.  I have to make this point emphatically because we have to get past the Data Cartel's Standard Objection: &lt;strong&gt;New Technology Won't Work&lt;/strong&gt;.  Most DBA's who are new to Data Warehousing and the star schema will exercise their veto authority over new technology, claim that the design is &amp;quot;inefficient&amp;quot; and stop (or delay) the project.&lt;/p&gt;
&lt;div class="section" id="dba-objections"&gt;
&lt;h2&gt;DBA Objections&lt;/h2&gt;
&lt;p&gt;DBA's can object in &lt;a class="reference external" href="https://slott56.github.io/2007_11_29-the_passive_aggressive_programmer_or_why_nothing_gets_done_revised.html"&gt;Passive-Aggressive&lt;/a&gt;  (and &lt;a class="reference external" href="https://slott56.github.io/2008_03_24-the_passive_aggressive_programmer_part_ii.html"&gt;Passive-Aggressive Part II&lt;/a&gt; ) mode -- where they don't have a better solution, they just have &amp;quot;concerns&amp;quot; about the standard DW solution.  Here are some things I've heard.&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;&lt;strong&gt;It isn't normalized&lt;/strong&gt;.  Which is a WTF? kind of point.  It isn't normalized for updates because there aren't any (to speak of).  It's normalized for SELECT SUM(*) GROUP BY, which is the canonical dimensional query.  I call this &amp;quot;denormalization&amp;quot; to make the point; perhaps I should call it star-schema normalization.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;&lt;strong&gt;It doesn't use &amp;quot;natural keys&amp;quot; correctly&lt;/strong&gt;.  I'm pretty sure that natural keys don't actually exist.  Almost everything is either an attribute (which can change) or a surrogate key (which isn't very likely to change).  A changeable attribute isn't really a key, is it?&lt;/p&gt;
&lt;p&gt;When writing ETL programs, we sometimes have a blurry edge when an external application assigns a truly permanent surrogate key.  In these cases, the external surrogate is often something that the organization uses heavily -- as if it was a natural key.  In other cases, they have a surrogate-like key that can (it turns out) change, making it just an attribute.  In the warehouse, it's usually best to simply assign warehouse surrogates and not burn up brain calories trying to make too many distinctions in the source applications.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;&lt;strong&gt;All those joins are inefficient&lt;/strong&gt;.  This can -- in the extreme case -- lead to &lt;strong&gt;The Uni-Table&lt;/strong&gt;.  This is the pre-joined ur-fact table that contains all dimensional attributes and all fact values.  It works, but it repeats all of the dimensional attributes and it doesn't track dimensional change at all.  Yes, I've seen it done.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;&lt;strong&gt;It uses too much storage&lt;/strong&gt;.  This is just silly, but it comes up.  Once, I caught the sysadmins and DBA's in a meeting where they were quibbling about log sizes so that they could micro-manage storage at the 100Gb increment.  &amp;quot;There's four people in this meeting.  At your hourly cost, I could have bought 400Gb at Circuit City.&amp;quot;  And the price of storage continues to plummet.  Nowadays, I think I could buy a terabyte.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;&lt;strong&gt;Fact updates can be inefficient&lt;/strong&gt;.  This is crazy, because changing a fact's measurement value is a single row update; it's fine if you're correcting errors.  Changing a batch of fact's measurements is -- what? -- criminal mischief?  Who changes batches of facts?  Considerer deleting the incorrect ones and reloading correct ones.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Changing the association between a batch of facts and a dimension is even spookier.  The historical fact is what you recorded.  You don't get to change the facts; it's called perjury.  If you're restating your books, you usually have new facts that apply to a historical time period.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="star-schema-normalization"&gt;
&lt;h2&gt;Star Schema Normalization&lt;/h2&gt;
&lt;p&gt;To get past the DBA objections, we need to have several heart-to-heart conversations on star-schema normalization.  Generally, these are painful because DBA's are overworked and sometimes underqualified.  Examples on paper don't help much.  Telling them to read Kimball does nothing.  Loading up realistic sets of data is the only workable approach to showing them that the storage is manageable, the joins won't kill you, surrogate keys work, and the star schema is a &amp;quot;real&amp;quot; thing.&lt;/p&gt;
&lt;p&gt;Once we've aired out an example, we then have to revisit the star schema thing over and over again.  Most DBA's are so habituated to 3NF that they can't get past it to see that a star schema is an alternative normal form.  Except in rare cases, the best we get is grudging tolerance.  [In the rare cases where the DBA's embrace a star schema approach, no one needs me, except to validate the design.]&lt;/p&gt;
&lt;p&gt;The basic 1NF and 2NF rules apply to the star schema normal form as well as transactional normal form.  Arrays are still a bad idea in the relational world.  Foreign attributes (those not functionally dependent on the key) are still a bad idea.  However, 3NF is out the window -- derived data is a helpful thing.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="derived-data-what-about-updates"&gt;
&lt;h2&gt;Derived Data?  What About Updates?&lt;/h2&gt;
&lt;p&gt;DBA standard objection #5 -- updates hurt -- often surfaces when discussing the approach of persisting derived data.  This is a focused &amp;quot;denormalization&amp;quot; that unwinds just 3NF to avoid repeating a calculation.  In the case of a data warehouse (load once, query an infinite number of times) all calculations done at load time are amortized across an infinite number of queries, making them delightfully efficient.&lt;/p&gt;
&lt;p&gt;The &amp;quot;update&amp;quot; issue can't arise.  Let's look at some common dimensions.&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;&lt;strong&gt;Time&lt;/strong&gt;.&lt;/dt&gt;
&lt;dd&gt;You don't change the day of the week for March 8, 1987.  It is, was, and always will be Sunday.&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;Space&lt;/strong&gt;.&lt;/dt&gt;
&lt;dd&gt;Geographical boundaries change.  However, this is the canonical Slowly Changing Dimension (SCD) problem that Kimball covers in detail.  [If you have what Kimball calls a &amp;quot;type 3&amp;quot; SCD, you have the most common example of an update in a data warehouse; the change of status from &amp;quot;current&amp;quot; to &amp;quot;previous&amp;quot;.]&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;Customer&lt;/strong&gt;.&lt;/dt&gt;
&lt;dd&gt;Your customers (either individuals in huge collections or other businesses in small collections) have numerous changes.  However, they often have attributes which can't change as well as attributes which frequently change.  For example, demographics change very slowly (if at all).  Customers often requires more sophisticated &amp;quot;snowflake schema&amp;quot; techniques.  There still aren't any updates, but there are SCD techniques for handling this.&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;Product&lt;/strong&gt;.&lt;/dt&gt;
&lt;dd&gt;Your products, product lines, product families, product groupings, solutions, technologies, platforms, services, etc., are all grouped by marketing in the randomest ways.  These groupings and hierarchies and clusters and affinities are just ways that marketing tries to portray your company; and it changes with every whim and brain-fart.  This is also a basic SCD issue; you simply add the alternative hierarchies and groupings and do alternate joins on the facts.&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;Cost Centers&lt;/strong&gt;.&lt;/dt&gt;
&lt;dd&gt;Your internal cost structure changes.  Sometimes frequently.  This is still SCD.  No updates, just inserts.&lt;/dd&gt;
&lt;/dl&gt;
&lt;/div&gt;
&lt;div class="section" id="recent-example"&gt;
&lt;h2&gt;Recent Example&lt;/h2&gt;
&lt;p&gt;&lt;a class="reference external" href="https://slott56.github.io/2008_06_06-my_query_is_slow_what_to_do_or_dumb_as_a_post_sql_revised.html"&gt;Recently&lt;/a&gt; , I aired out some brain-dead non-solutions to a simple reporting problem where number of rows (500 new rows per hour) might have been the design problem being solved.  The non-solution involved a five ways of avoiding a viable solution.  As follow-up to my suggestions, I was given the following variations on DBA objection 1; each affixing blame somewhere else.&lt;/p&gt;
&lt;p&gt;1.1.  The customer cannot accept a &amp;quot;denormalized&amp;quot; table that pre-computes the values.  [The customer is at fault.]&lt;/p&gt;
&lt;p&gt;1.2.  Since we can't directly use the &amp;quot;denormalized&amp;quot; table in your blog posting, the idea of denormalization is broken, and we can never talk about it in any form whatsoever.  Temporary tables, materialized views and other techniques are off the table, &lt;em&gt;a priori&lt;/em&gt;.  [I'm at fault for not providing the expected solution, which involved some kind of &lt;strong&gt;Faerie Dust&lt;/strong&gt;™ that would make a bad table process quickly.]&lt;/p&gt;
&lt;p&gt;1.3.  The organization can't learn anything new.  Talking about &amp;quot;denormalization&amp;quot; would be new, and is therefore forbidden.  The idea of persistent derived values is off the table, &lt;em&gt;a priori&lt;/em&gt;.  [The organization is at fault.]&lt;/p&gt;
&lt;p&gt;At this point, any suggestion I might have has been trumped by the DBA's opposition to denormalization.  Blame has been assigned everywhere.  I think this is because I used the word &amp;quot;denormalization&amp;quot; incautiously and set myself up for three flavors of DBA objection #1 (&amp;quot;It isn't normalized.&amp;quot;)&lt;/p&gt;
&lt;p&gt;Perhaps, if I'd said &amp;quot;persistent derived values&amp;quot; instead of &amp;quot;denormalization&amp;quot; we might have gotten somewhere.  Ideally, they would have suggested a temporary table or materialized view as an implementation technique.  But, we stalled out at my incautious use of a loaded buzzword.&lt;/p&gt;
&lt;/div&gt;
</content><category term="Python"></category><category term="#python"></category><category term="database"></category></entry><entry><title>Genius Move -- Characteristic Functions</title><link href="https://slott56.github.io/2008_06_07-genius_move_characteristic_functions.html" rel="alternate"></link><published>2008-06-07T13:54:00-04:00</published><updated>2008-06-07T13:54:00-04:00</updated><author><name>S.Lott</name></author><id>tag:slott56.github.io,2008-06-07:/2008_06_07-genius_move_characteristic_functions.html</id><summary type="html">&lt;p&gt;The comment was eaten by Haloscan, but here's the text...&lt;/p&gt;
&lt;p&gt;You need to read Rozhenstein on characteristic functions.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
select
sum(case when a &amp;lt; .5 then 1 else 0 end) 'A'
,sum(case when a &amp;gt;= .5 and a &amp;lt; .75 then 1 else 0 end) 'B'
,sum(case when a &amp;gt;= .75 then …&lt;/pre&gt;</summary><content type="html">&lt;p&gt;The comment was eaten by Haloscan, but here's the text...&lt;/p&gt;
&lt;p&gt;You need to read Rozhenstein on characteristic functions.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
select
sum(case when a &amp;lt; .5 then 1 else 0 end) 'A'
,sum(case when a &amp;gt;= .5 and a &amp;lt; .75 then 1 else 0 end) 'B'
,sum(case when a &amp;gt;= .75 then 1 else 0 end) 'C'
,bar
from foo
group by bar
&lt;/pre&gt;
&lt;p&gt;So, I googled it, and figured out what I'd been missing.&lt;/p&gt;
&lt;div class="section" id="skip-the-math"&gt;
&lt;h2&gt;Skip the Math&lt;/h2&gt;
&lt;p&gt;The Google page on characteristic functions is heavy going.  The issue here is to characterize the frequency distribution of some more-or-less random variable.  This is a real close fit with the formal definition of a characteristic function.&lt;/p&gt;
&lt;p&gt;When should we apply the characteristic function?  Load time or query time?  The comment showed it at query time.  However, we could also do it at load time.&lt;/p&gt;
&lt;p&gt;Here's the genius part.&lt;/p&gt;
&lt;p&gt;If we define it as a separate function, we can defer this decision based on which implementation meets our performance guidelines.&lt;/p&gt;
&lt;p&gt;We have this situation.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
def c1( value ):
    a,b = divmod( int(value*100), 10 )
    if b == 0:
        return &amp;quot;== 0.%d&amp;quot; % ( a, )
    else:
        return &amp;quot;0.%d - 0.%d&amp;quot; % ( a, a+1 )
&lt;/pre&gt;
&lt;p&gt;We can then use this during load or we can use it in a fetch loop.  Quite cool.  Very elegantly separated from other parts of the processing.&lt;/p&gt;
&lt;/div&gt;
</content><category term="Python"></category><category term="#python"></category><category term="database"></category></entry><entry><title>My Query Is Slow -- What To Do? Or Dumb-As-A-Post SQL (Revised)</title><link href="https://slott56.github.io/2008_06_06-my_query_is_slow_what_to_do_or_dumb_as_a_post_sql_revised.html" rel="alternate"></link><published>2008-06-06T22:30:00-04:00</published><updated>2008-06-06T22:30:00-04:00</updated><author><name>S.Lott</name></author><id>tag:slott56.github.io,2008-06-06:/2008_06_06-my_query_is_slow_what_to_do_or_dumb_as_a_post_sql_revised.html</id><summary type="html">&lt;p&gt;First, let me point out that the Data Cartel (&amp;quot;DBA&amp;quot; means Don't Bother Asking) won't release all the information I requested, so some of this is a guess.&lt;/p&gt;
&lt;p&gt;We'll look at a number of dumb-as-a-post SQL techniques.  This is proof -- if any were needed -- that bad SQL is worse than …&lt;/p&gt;</summary><content type="html">&lt;p&gt;First, let me point out that the Data Cartel (&amp;quot;DBA&amp;quot; means Don't Bother Asking) won't release all the information I requested, so some of this is a guess.&lt;/p&gt;
&lt;p&gt;We'll look at a number of dumb-as-a-post SQL techniques.  This is proof -- if any were needed -- that bad SQL is worse than no SQL.&lt;/p&gt;
&lt;p&gt;The table appears to have 2 columns, a date and a floating-point value in the range 0.0 to 1.0.  Rows arrive at the rate of 500 an hour.&lt;/p&gt;
&lt;p&gt;Someone wants a weekly summary (about 90,000 rows) binned into 10 ranges 0.0 to 0.1, 0.1 to 0.2, 0.2 to 0.3, etc.  The algorithm might be slightly more complex (to separate &lt;span class="formula"&gt;&lt;i&gt;n&lt;/i&gt; = 0.1&lt;/span&gt; from &lt;span class="formula"&gt;0.1 &amp;lt; &lt;i&gt;n&lt;/i&gt; ≤ 0.2&lt;/span&gt;.)&lt;/p&gt;
&lt;p&gt;[Again, the DBA steadfastly refuses to provide the use cases, so I'm doing a lot of this with minimal information.  However, I did get a spreadsheet showing an Excel version of the algorithm.  Not PL/SQL, not pure SQL, not Java, but Excel.]&lt;/p&gt;
&lt;div class="section" id="what-s-the-issue"&gt;
&lt;h2&gt;What's the Issue?&lt;/h2&gt;
&lt;p&gt;The issue is that some programmers can't be trusted to find their ass groping with both hands.  I was sent three versions of the obvious SQL query, each more contrived and senseless than the last.&lt;/p&gt;
&lt;p&gt;I was asked -- really -- &amp;quot;What is a more scalable approach to the problem ?&amp;quot;.  &amp;quot;Scalable&amp;quot;? WTF?  Scalable with respect to what?  Rows?  Physical I/O's?  Elapsed Time?  CPU use?  User queries?  Web page hits?  Shots of Tequila?  If I look at the &lt;a class="reference external" href="http://www.zifa.com/"&gt;Zachman Framework&lt;/a&gt;  or the &lt;a class="reference external" href="http://www.sei.cmu.edu/str/taxonomies/view_qm_body.html"&gt;SEI Quality Measures Taxonomy&lt;/a&gt; , I can come up with at least a half-dozen more dimensions of potential &amp;quot;scalability&amp;quot;.&lt;/p&gt;
&lt;p&gt;[Yes, I asked.  No, I didn't get an answer.  &amp;quot;Scalability&amp;quot; appears to mean the same thing as &amp;quot;Better&amp;quot;.]&lt;/p&gt;
&lt;p&gt;I'm assuming that the volume has increased or something, and the old query isn't fast enough.  Or something.  There's a claim that some query is run 83 million times each week; that's 138 times per second, a number I just don't believe.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="fetishize-a-feature"&gt;
&lt;h2&gt;Fetishize a Feature&lt;/h2&gt;
&lt;p&gt;Someone has an Oracle Bulk Bind fetish.  I've listened to this tripe before.  There are probably places where it helps.  I haven't seen any, but I haven't really made a study of the feature.   Apparently, they couldn't get it to work for the required 80,000 rows.  It gets what they call &amp;quot;the standard ORA-04030 error.&amp;quot;&lt;/p&gt;
&lt;p&gt;The sent me a copy of solution one: a big pile of PL/SQL including some BULK COLLECT stuff.  PL/SQL they couldn't get it to work.  I'm not sure what's going on here, but it's clearly the first dumb-as-a-post SQL programming technique:  &lt;strong&gt;Fetishize a Feature&lt;/strong&gt;.  You pick something and stick with it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="drown-it-in-documentation"&gt;
&lt;h2&gt;Drown it in Documentation&lt;/h2&gt;
&lt;p&gt;Here's the best part of solution one.  It didn't work.  And they provided me with extensive documentation -- on the feature they couldn't get to work.  I like that.  So technique two is to quote a lot of documentation -- as if &lt;strong&gt;Drowning It In Documentation&lt;/strong&gt;  somehow make the feature start working.&lt;/p&gt;
&lt;p&gt;I suppose I could try and debug it, but I really don't have the patience.  There are simpler, provably faster techniques.  Why debug something that is highly Oracle-specific, and doesn't seem to work very well?&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="write-more-code"&gt;
&lt;h2&gt;Write More Code&lt;/h2&gt;
&lt;p&gt;Solution two was to purge the bulk-bind syntax from solution one and see if a big pile of PL/SQL will work.  PL/SQL is a demonstrably slow platform.  There are some anecdotal stories of applications that were made faster by replacing external application programs with PL/SQL.  I believe that those stories involve comparing the performance of a Bentley with an Etap 37S.  One's a car, the other's a boat.  PL/SQL is faster when you change your application design to make better use of PL/SQL features.&lt;/p&gt;
&lt;p&gt;In this case, the PL/SQL solution is a huge amount of code for something that is -- as far as I can tell -- a SELECT COUNT(*) GROUP BY operation.  It's hard to be completely sure, since the code is bad, and obscures the intent.&lt;/p&gt;
&lt;p&gt;Rather than summarize and simplify, they &lt;strong&gt;Wrote More Code&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="don-t-do-the-obvious"&gt;
&lt;h2&gt;Don't Do The Obvious&lt;/h2&gt;
&lt;p&gt;Another generally dumb technique is to avoid writing the obvious SQL because -- well -- I don't know why.  I don't have the actual requirements.  However, each example strives to produce one line of output with the frequency table spread out horizontally.  This is fairly hard to do in SQL, and requires lots of copy and paste programming to repeat the CASE expressions over and over again.&lt;/p&gt;
&lt;p&gt;The basic SELECT COUNT(*) GROUP BY produces a number of rows, each of which has a key and a count.  This can be rotated into a horizontal configuration by a reporting program.  For some reason, we're locked into a single form for the report, making it so we can't &lt;strong&gt;Do The Obvious&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="refuse-to-change-the-structure"&gt;
&lt;h2&gt;Refuse to Change the Structure&lt;/h2&gt;
&lt;p&gt;Data structures and algorithms are two complementary sides of the same coin.  You can't fix the algorithm without fixing the data structure, and vice versa.  In this case, the table design was bad, but no one seemed prepared to fix it.&lt;/p&gt;
&lt;p&gt;About a year ago, I had told a member of data cartel to read Ralph Kimball's Data Warehouse Toolkit.  They claimed they read it.  Since they got nothing out of it, I'm not sure what they meant by &amp;quot;read&amp;quot;.  Data warehouse folks know that you have to denormalize for reporting.  A relentless focus on &amp;quot;normalization&amp;quot; -- when dealing with non-updatable reporting-only data -- is simply wrong.&lt;/p&gt;
&lt;p&gt;In this case, the floating point numbers had to be split up into bins.  The calculation must be done at load time, and must be a permanent part of the table.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
TABLE data(
time DATETIME,
value FLOAT );
&lt;/pre&gt;
&lt;p&gt;This isn't really sufficient for reporting.  You need something more like the following:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
TABLE data(
time DATETIME,
week INTEGER,
month INTEGER,
year INTEGER,
value FLOAT,
bin INTEGER );
&lt;/pre&gt;
&lt;p&gt;The various derived values are all trivial to calculate at load time.  Once they're calculated, your query reduces to a trivial SELECT bin, COUNT(*) FROM DATA GROUP BY bin.  It isn't the absolutely fastest way to process the data, but it's a far, far sight faster than on-the-fly CASE expressions or PL/SQL loops.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="the-hubris-of-time-calculations"&gt;
&lt;h2&gt;The Hubris of Time Calculations&lt;/h2&gt;
&lt;p&gt;There's more that's wrong in the various examples I was sent.   Specifically, they use &amp;quot;closed-ended date ranges&amp;quot;.  A serious mistake that is caused by simple hubris.  Time is subtle and complex and easy to get wrong.&lt;/p&gt;
&lt;p&gt;Here's their code.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
time &amp;gt;= TO_DATE( '05/01/2008 00:00:00', 'MM/DD/YYYY HH24:MI:SS') AND
time &amp;lt;= TO_DATE( '05/08/2008 23:59:59', 'MM/DD/YYYY HH24:MI:SS');
&lt;/pre&gt;
&lt;p&gt;It can't -- in general -- work.&lt;/p&gt;
&lt;p&gt;There's a 1-second gap between the two times.  You have use half-open intervals to avoid losing a row that happens to have a timestamp in the gap.  [Don't waste time adding .999's, either, because the decimal value doesn't provide down-to-the-last bit way to encode the internal binary values.]&lt;/p&gt;
&lt;pre class="literal-block"&gt;
time &amp;gt;= TO_DATE('05/01/2008','MM/DD/YYYY')
AND time &amp;lt; TO_DATE('05/08/2008','MM/DD/YY' )
&lt;/pre&gt;
&lt;p&gt;This has NO gap.&lt;/p&gt;
&lt;p&gt;However, this still isn't very good.  As shown in the table definitions above, you need to denormalize the time-stamp into the buckets you actually want to use for selection and grouping.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="real-speed"&gt;
&lt;h2&gt;Real Speed&lt;/h2&gt;
&lt;p&gt;I don't have the table or sample data, so I can't compare my results with their performance numbers.  However, their numbers are sad.&lt;/p&gt;
&lt;p&gt;First, they couldn't get the bulk bind to work, but sent me the code, as if it mattered.&lt;/p&gt;
&lt;p&gt;Second, their massive PL/SQL loop ran for an hour.  Apparently, this is unacceptable, but they sent me the code, as if it mattered.  Which is sad.&lt;/p&gt;
&lt;p&gt;Third, their SQL GROUP-BY with all the CASE expressions ran in 12 minutes.  I don't know if that's too long or uses too much memory or takes too many tequila shots.&lt;/p&gt;
&lt;p&gt;The real SELECT COUNT(*) GROUP BY, with denormalized data, is fast.  On my little 1Gb RAM, 1.7Ghz Dell, running Fedora Core 8 and using SQLite, a basic SELECT COUNT(*) processes 100,000 records in about 3 seconds.&lt;/p&gt;
&lt;p&gt;That's about as fast as this little drip of code.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
import collections
    count= collections.defaultdict(lambda:0)
    for row in q.execute().fetchall():
        b, exact = divmod( int(row[1]*100), 10 )
        band= &amp;quot;==0.%d&amp;quot;%(b,) if exact == 0 else &amp;quot;0.%d-0.%d&amp;quot;%(b,b+1)
        count[band] += 1
    print count
&lt;/pre&gt;
&lt;p&gt;In SQLite, for 100,000 rows, this is the same speed as SQL.  Why?  Because we're not asking the database to do anything much more than fetch rows.&lt;/p&gt;
&lt;p&gt;Interestingly, in Oracle, the &lt;tt class="docutils literal"&gt;SELECT &lt;span class="pre"&gt;COUNT(*)&lt;/span&gt; GROUP BY&lt;/tt&gt; is much, much faster.  Why?  Because Oracle queries involve a context switch, where SQLite does not.  A simple fetch loop in Oracle is relatively slow without using some kind of buffering.&lt;/p&gt;
&lt;p&gt;The database fetch time still dominates what we're doing.  A table design change, and doing all processing at load time will minimizes the query time.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="how-many-bad-things-can-we-do"&gt;
&lt;h2&gt;How Many Bad Things Can We Do?&lt;/h2&gt;
&lt;p&gt;Let's enumerate them:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Fetishize a Feature&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Drown It In Documentation&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Write More Code&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Refuse to Change the Structure&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The Hubris of Time Calculation&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All of these habits get in the way of a simple denormalization that makes the obvious query work at amazing speeds.&lt;/p&gt;
&lt;/div&gt;
</content><category term="Python"></category><category term="#python"></category><category term="database"></category></entry><entry><title>The Django World-View: Model+Admin First; Built-in Transparency and Trustworthiness</title><link href="https://slott56.github.io/2008_03_24-the_django_world_view_modeladmin_first_built_in_transparency_and_trustworthiness.html" rel="alternate"></link><published>2008-03-24T18:24:00-04:00</published><updated>2008-03-24T18:24:00-04:00</updated><author><name>S.Lott</name></author><id>tag:slott56.github.io,2008-03-24:/2008_03_24-the_django_world_view_modeladmin_first_built_in_transparency_and_trustworthiness.html</id><summary type="html">&lt;p&gt;See Michael Hugos &amp;quot;&lt;a class="reference external" href="http://www.computerworld.com/action/article.do?command=viewArticleBasic&amp;amp;articleId=314557"&gt;Think about screens and the data on them to simplify system development&lt;/a&gt; &amp;quot; for some helpful insight on what an &amp;quot;application&amp;quot; really is -- access to data.  Simple transparency is lifted up as a critical value for software.&lt;/p&gt;
&lt;p&gt;I liked the &amp;quot;If you don't believe it could be this …&lt;/p&gt;</summary><content type="html">&lt;p&gt;See Michael Hugos &amp;quot;&lt;a class="reference external" href="http://www.computerworld.com/action/article.do?command=viewArticleBasic&amp;amp;articleId=314557"&gt;Think about screens and the data on them to simplify system development&lt;/a&gt; &amp;quot; for some helpful insight on what an &amp;quot;application&amp;quot; really is -- access to data.  Simple transparency is lifted up as a critical value for software.&lt;/p&gt;
&lt;p&gt;I liked the &amp;quot;If you don't believe it could be this simple, consider the reasons for your response&amp;quot; insight.  I didn't like Hugos' sample response, &amp;quot;complex code that you can brag about&amp;quot;.  I don't think complexity for the sake of complexity is a real problem.&lt;/p&gt;
&lt;p&gt;Complexity can be defined as everything that separates the user from their data.  As Hugos' notes, the data model and the simplest, most direct presentation is the best design.  Everything else is complexity that obscures the real purpose of the software.&lt;/p&gt;
&lt;p&gt;Complexity comes from several sources.  I've blogged about complexity &lt;a class="reference external" href="https://slott56.github.io/2005_09_03-why_are_things_so_complicated_7_deadly_reasons.html"&gt;before&lt;/a&gt; , ever since &lt;a class="reference external" href="http://www.mindspring.com/~mgrand/"&gt;Mark Grand&lt;/a&gt;  gave me the hint that complexity was part of the IT culture.&lt;/p&gt;
&lt;p&gt;Here are seven kinds of complexity that get between a user and their data.&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;strong&gt;&amp;quot;The Conflict Is The Problem&amp;quot;&lt;/strong&gt;. The inherent conflicts in the relationship between developers and buyers or users make the problem appear complex. Often this is because buyers insist on their solution -- irrespective of the actual problem.  Rather than describe the underlying problem, buyers describe a solution based on their favorite technology.  They insist they have to do this because the job of the business analyst is to translate the business problem to technology terms -- usually oriented around a complex non-solution.  After all, when you try to solve a business problem with a spreadsheet, you've created two business problems.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&amp;quot;Fear of Showing Weakness&amp;quot;&lt;/strong&gt;. Simplicity isn't valued.  Some aspect of the problem is (or appears) complex, so we need lots of complex software.  Many &amp;quot;business rules&amp;quot; are transient; an orientation around the decisions a person needs to make is more helpful than over-specifying something that handles 1% of the dollar value of an application.  Rather than simply expose the data (and the business process) to the people, we overdesign &amp;quot;automation&amp;quot; that makes the exceptions and special cases a larger and more complex problem than they deserve to be.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&amp;quot;Quality vs. Quantity of Ideas&amp;quot;&lt;/strong&gt;. It's hard to let go of the first idea, no matter how bad it is.  Someone with deep experience in legacy technology will often be the root cause of complexity.  Just because batch processing was once the vogue doesn't mean it is essential or even necessary.  Many, many things can be handled via an asynchronous message queue rather than an overnight batch process.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&amp;quot;Form vs. Function&amp;quot;&lt;/strong&gt;. If we fail to define the problem in the first place, we don't know what problem we're solving.  We're left applying technology inappropriately, filling in the form of a solution, manufacturing complexity because we're vague on what the actual function should be.  Rather than simply present data, we feel that application logic is &amp;quot;important&amp;quot; and should be part of the system; simple presentation of data isn't appropriate.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&amp;quot;When I Grow Up&amp;quot;&lt;/strong&gt;. If we don't have a mature process for solving problems, we're stuck applying inappropriate technology.  Often we're forced into building something prematurely, and the previous problems all surface: we lock onto the first bad idea, we don't back down from that bad idea, it fills the form of software we think we understand.&lt;/li&gt;
&lt;li&gt;&amp;quot;&lt;strong&gt;If I Had A Hammer&amp;quot;&lt;/strong&gt;. Tied in with the lack of quality ideas or well-defined problems, we make inappropriate use of tools or solution design patterns; we view all fastener problems as nails because we only understand hammers.  We have very, very sophisticated application software development tools; we don't need to write mountains of code when we have sophisticated technology stacks like Linux/Apache/MySQL/Python and Django.&lt;/li&gt;
&lt;li&gt;&amp;quot;&lt;strong&gt;How Hard Can It Be?&amp;quot;&lt;/strong&gt; Failure to assess risks appropriately biases users against a simple solution.  More programming seems -- in some views -- to be less risky.  More automation isn't a solution.  Appropriate controls are more important than volume of software.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Read Thibodeau's &amp;quot;&lt;a class="reference external" href="http://www.computerworld.com/action/article.do?command=viewArticleBasic&amp;amp;articleId=9066618"&gt;D.C.'s tax system won plaudits but couldn't stop alleged insider thefts&lt;/a&gt; &amp;quot;.  Complexity and technology aren't the answer.  Good old-fashioned controls and audits are what matters.  Audits and controls require transparency, not complexity.&lt;/p&gt;
</content><category term="Python"></category><category term="#python"></category><category term="database"></category></entry><entry><title>How Essential Is Unit Testing? Or, How Do We Make It Essential?</title><link href="https://slott56.github.io/2007_12_24-how_essential_is_unit_testing_or_how_do_we_make_it_essential.html" rel="alternate"></link><published>2007-12-24T11:31:00-05:00</published><updated>2007-12-24T11:31:00-05:00</updated><author><name>S.Lott</name></author><id>tag:slott56.github.io,2007-12-24:/2007_12_24-how_essential_is_unit_testing_or_how_do_we_make_it_essential.html</id><summary type="html">&lt;p&gt;See &lt;a class="reference external" href="http://thomas.apestaart.org/log/?p=559"&gt;Present Perfect&lt;/a&gt;  for some thoughts on unit testing.   See some other commentary on the discipline required to write Python programs in &lt;a class="reference external" href="http://panela.blog-city.com/gnome_devs_too_lazy_for_python.htm"&gt;Gnome devs too lazy for python&lt;/a&gt; .  I think I see the disconnect that makes testing appear to be too costly; I think that some basic &amp;quot;meta-quality attributes&amp;quot; are …&lt;/p&gt;</summary><content type="html">&lt;p&gt;See &lt;a class="reference external" href="http://thomas.apestaart.org/log/?p=559"&gt;Present Perfect&lt;/a&gt;  for some thoughts on unit testing.   See some other commentary on the discipline required to write Python programs in &lt;a class="reference external" href="http://panela.blog-city.com/gnome_devs_too_lazy_for_python.htm"&gt;Gnome devs too lazy for python&lt;/a&gt; .  I think I see the disconnect that makes testing appear to be too costly; I think that some basic &amp;quot;meta-quality attributes&amp;quot; are essential to understanding unit testing.&lt;/p&gt;
&lt;p&gt;Here's the original C# vs. Python analysis in &lt;a class="reference external" href="http://joeshaw.org/2007/10/28/496"&gt;Monotonous&lt;/a&gt; .&lt;/p&gt;
&lt;p&gt;Here's the famous quote: &amp;quot;Writing real applications in Python requires a discipline that unfortunately most people (including myself, at that time) are unwilling to adhere to, and this easily leads to buggy and hard to maintain programs. You have to be very diligent about unit tests and code coverage for every line of code, because you can’t rely on the compiler to catch errors for you.&amp;quot;&lt;/p&gt;
&lt;p&gt;I didn't take careful notes at a client meeting where this came up, so I don't have good quotes.  The client balked at the very idea of Test Driven Development.  In a larger presentation on testing (technology, environments, process, etc.) I had lifted up TDD as a direction that would benefit the developers.  The response from the director of development was a series of &amp;quot;how would you do that?&amp;quot; questions.&lt;/p&gt;
&lt;p&gt;These weren't practical &amp;quot;how to&amp;quot; questions.  They were rhetorical &amp;quot;that isn't possible&amp;quot; statements, framed as questions.  In order to portray TDD as impossible the questions quickly devolved into how TDD interacts with requirements gathering and business analysis; I couldn't successfully bracket the questions as part of the fringe of TDD.  I think the disconnect was their certain knowledge that test cases come only from requirements and nowhere else.&lt;/p&gt;
&lt;div class="section" id="it-hurts-when-i-do-that"&gt;
&lt;h2&gt;It Hurts When I Do That&lt;/h2&gt;
&lt;p&gt;TDD is -- certainly -- a pain the neck.  I think I see two complaints.  First, it's a lot of &amp;quot;extra&amp;quot; code.  I'm guessing that there's a &amp;quot;non-deliverable&amp;quot; view of test cases that pervades some people's thinking.  I've been measuring the lines of code in both parts of a project, and the total volume of source is about 50% test cases and 50% operational.&lt;/p&gt;
&lt;p&gt;Many years ago, we made a distinction between &amp;quot;deliverable&amp;quot; and &amp;quot;non-deliverable&amp;quot; software.  We used to carefully segregate any non-deliverable software so that we could wring our hands over how to estimate the cost for it.  Since it wasn't &amp;quot;deliverable,&amp;quot; some managers felt we couldn't charge the customer for it; the logical conclusion was that we should exclude it from our project plans.&lt;/p&gt;
&lt;p&gt;I maintained that &amp;quot;non-deliverable&amp;quot; is still &amp;quot;essential&amp;quot;, so we must include it in our plans.  The &amp;quot;compromise&amp;quot; was to inflate the estimated size of the deliverable to include a pro-rated version of the non-deliverable code.  The claim was that non-deliverable software was half the cost of deliverable software.  It had less documentation and less testing or some such.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="i-can-t-cope-with-that"&gt;
&lt;h2&gt;I Can't Cope With That&lt;/h2&gt;
&lt;p&gt;The second complaint seems to be that programmers can't be trusted.  Because they can't be trusted, we must have full definitions of all deliverables, complete up-front design, rigorous schedules for code creation, and a fungible, compressible schedule for testing.&lt;/p&gt;
&lt;p&gt;We can't engage in an agile test-driven process for a number of reasons.  First, and foremost, programmers are the root cause of scope creep.  We all know that programmers will &amp;quot;gold-plate&amp;quot; the simplest thing; they'll spend years polishing and improving something of limited business value.  [Why did we let them get started on something of limited value?  Why aren't we willing to invest in making it work correctly every time?]&lt;/p&gt;
&lt;p&gt;We can't trust programmers to do just enough design because they are lazy slobs and won't ever get anything to work.  If we try to let them fire at half-cock, they'll never get anything useful accomplished. After all, we -- as managers -- have a vision of something trivially simple.  The programmers keep introducing some technology nuance that makes a simple thing horribly complex and difficult.  [Who -- specifically -- told us that introducing new technology will be simpler?  Or did we just make that part up?]&lt;/p&gt;
&lt;p&gt;We can't trust programmers to evolve code, design and test hand-in-hand.  If we did, there'd be scope creep and they'd just play with the technology.  Worse, of course, they'd miss the schedule.&lt;/p&gt;
&lt;p&gt;We certainly can't trust programmers and end-users to collaborate.  If we did, they would change the focus of the project, and the schedule might be missed.  As managers, we don't fully understand the business value proposition; we don't completely get the technology, but we do understand the schedule.  Since we really, truly, deeply understand the calendar, that is the one thing we can manage to.  [Why is schedule more important than delivered features?]&lt;/p&gt;
&lt;p&gt;Above all, we can't trust programmers to create test cases.  Only end-users can create tests, and those tests must be married to the requirements.  There's no reason to elaborate the tests to match the design, or elaborate the tests to match the details embodied in the code.  Tests based on design or programming amount to letting a programmer do their own tests; programmers are untrustworthy; therefore this can't work.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="the-tdd-alternatives"&gt;
&lt;h2&gt;The TDD Alternatives&lt;/h2&gt;
&lt;p&gt;I think there's just one disconnect underlying this.  This disconnect manifests itself as two alternatives to TDD.  The static language folks seem to like the idea that compiler type-checking is an alternative to testing.  I suppose -- to a limited extent -- this is true.  Rather than write a unit test to examine proper integration among classes or modules, we can trust the compiler.&lt;/p&gt;
&lt;p&gt;Everyone knows -- or should know -- that the compiler is easily fooled.  When using externally developed JAR files, we can easily compile against one version, and try to execute against a different version.  All the compile-time type-checking in the world can't cope with mis-configuration.  Eventually, we need Python-style dynamic testing.&lt;/p&gt;
&lt;p&gt;When we can't trust our programmers, we have a number of clever alternatives to TDD.  The primary approach is to define a process that imposes a waterfall approach to developing unit test cases in parallel with the code.  When asked &amp;quot;How does TDD interact with requirements gathering?&amp;quot; no answer I could give was acceptable.  What they wanted me to say was &amp;quot;Oh crap, you're right, I'm such an idiot.  Test cases are only based on requirements, never design or programming.&amp;quot;  They wanted me to agree that programmers can't be allowed write their own test cases.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="the-disconnect"&gt;
&lt;h2&gt;The Disconnect&lt;/h2&gt;
&lt;p&gt;I think both viewpoints stem from looking at testing as &amp;quot;final&amp;quot;, &amp;quot;end-user&amp;quot; or &amp;quot;acceptance&amp;quot; testing.  If testing is only for acceptance, then we should have other ways to test that the programming is correct and the design really works.  The compiler should -- somehow -- validate our basic programming via static type analysis.  The design, similarly, should be checked via some static analysis.  That leaves testing to focus on the requirements and nothing else.&lt;/p&gt;
&lt;p&gt;Additionally, we can't trust one person to interpret the requirements as test cases and as code.  We must apply a second pair of eyeballs to the requirements to create the acceptance-oriented test cases.&lt;/p&gt;
&lt;p&gt;It appears to me that TDD is dismissed as worthless because people don't see a need to test their designs or programming.  Either they hope that static type analysis will do this, or they simply dismiss this testing as worthless.&lt;/p&gt;
&lt;p&gt;It's hard to create a value proposition for testing the design and programming.  It requires emphasizing a sense of distrust.  And the level of distrust is already fairly high.  After all, unit testing requires a level of discipline that programmers are unwilling to adhere to.  The idea of adding testing at the design and code level only gets into complex philosophical discussions about &amp;quot;the role of requirements&amp;quot;.&lt;/p&gt;
&lt;p&gt;It's hard to break testing free from &amp;quot;End-User Acceptance.&amp;quot;  However, if we can portray testing as essential, it then becomes deliverable.  Indeed, it becomes essential to establishing confidence in the software.  It also becomes part of the documentation, since each API is demonstrated by at least a test case (in some cases, a whole test suite.)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="meta-quality"&gt;
&lt;h2&gt;Meta-Quality&lt;/h2&gt;
&lt;p&gt;The logical conclusion is a set of meta-quality attributes.  Software quality attributes can be based on the SEI Quality Measures Taxonomy &lt;a class="reference external" href="http://www.sei.cmu.edu/str/taxonomies/view_qm.html"&gt;http://www.sei.cmu.edu/str/taxonomies/view_qm.html&lt;/a&gt;.  This taxonomy includes need satisfaction, resource use, maintainability, adaptability and cost factors.&lt;/p&gt;
&lt;p&gt;Meta-quality includes the quality attributes of the test cases.  There are probably a number of quality attributes regarding things like 'traceability to requirements&amp;quot;, &amp;quot;class coverage&amp;quot; and &amp;quot;method coverage&amp;quot; that determine how useful and complete the test cases are.  Looking at &amp;quot;traceability&amp;quot;, we examine how the test cases apply to end-user acceptance.&lt;/p&gt;
&lt;p&gt;I look at &amp;quot;class coverage&amp;quot; as  a way to to look at the design.  This includes classical &amp;quot;class-in-isolation&amp;quot; unit tests, as well as module- (or &amp;quot;component&amp;quot; or &amp;quot;package&amp;quot;) -level unit tests that examine a collection of classes to be sure that they interact properly.  This makes limited use of mock objects, since this is looking at integration of classes and modules.&lt;/p&gt;
&lt;p&gt;The &amp;quot;method coverage&amp;quot; is how we look at the programming.  This includes appropriate test cases to exercise each method more-or-less in isolation.  This level of testing makes heavy use of mock objects to be sure that the code in each method is actually correct.&lt;/p&gt;
&lt;p&gt;I think that these meta-quality attributes of the test case code is as important as the quality attributes of the &amp;quot;operational&amp;quot; code.&lt;/p&gt;
&lt;/div&gt;
</content><category term="Python"></category><category term="#python"></category><category term="unit testing"></category></entry><entry><title>User Interface Testing</title><link href="https://slott56.github.io/2007_08_14-user_interface_testing.html" rel="alternate"></link><published>2007-08-14T10:34:00-04:00</published><updated>2007-08-14T10:34:00-04:00</updated><author><name>S.Lott</name></author><id>tag:slott56.github.io,2007-08-14:/2007_08_14-user_interface_testing.html</id><summary type="html">&lt;p&gt;The question seemed simple, which testing framework is the simplest?  The situation is complex.  There's a web application, there are developers and there are testers.  The developers develop, and the testers test.  So far, not so complex.&lt;/p&gt;
&lt;p&gt;Here's the complexity.  The testers are pretty focused on manual point-and-click testing.  They …&lt;/p&gt;</summary><content type="html">&lt;p&gt;The question seemed simple, which testing framework is the simplest?  The situation is complex.  There's a web application, there are developers and there are testers.  The developers develop, and the testers test.  So far, not so complex.&lt;/p&gt;
&lt;p&gt;Here's the complexity.  The testers are pretty focused on manual point-and-click testing.  They didn't like &lt;a class="reference external" href="http://httpunit.sourceforge.net/"&gt;HttpUnit&lt;/a&gt; , declaring it too complex.&lt;/p&gt;
&lt;div class="section" id="what-s-simpler-than-httpunit"&gt;
&lt;h2&gt;What's simpler than HttpUnit?&lt;/h2&gt;
&lt;p&gt;At first blush, my answer was to look at &lt;a class="reference external" href="http://www.openqa.org/selenium/"&gt;Selenium&lt;/a&gt; .  This is a widely-used, easily automated toolset for browser and UI testing.  But further conversation showed that this is the wrong approach.&lt;/p&gt;
&lt;p&gt;They aren't deeply interested in the kind of cross-browser testing that Selenium does well.  They're more interested in the essential functionality testing that HttpUnit does.  They need to know that the application works with the given target browser.  Articles like &amp;quot;&lt;a class="reference external" href="http://magpiebrain.com/blog/2007/01/28/selenium-rocks-and-you-dont-need-it/"&gt;Selenium rocks - and you don't need it&lt;/a&gt; &amp;quot; help to clarify this distinction between Selenium and HttpUnit&lt;/p&gt;
&lt;p&gt;My next answer was to look at &lt;a class="reference external" href="http://twill.idyll.org/"&gt;Twill&lt;/a&gt; .  Articles like the Advogato &amp;quot;&lt;a class="reference external" href="http://www.advogato.org/article/874.html"&gt;Introduction&lt;/a&gt; &amp;quot; are very compelling.&lt;/p&gt;
&lt;p&gt;It turns out, though, the real problem isn't &amp;quot;complexity&amp;quot; &lt;em&gt;per se&lt;/em&gt; .  The real problem is that the testers aren't interested in writing sophisticated test scripts.  They know the application, they know what they want to see, and they don't feel that programming is the best use of their time.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="unit-testing-101"&gt;
&lt;h2&gt;Unit Testing 101&lt;/h2&gt;
&lt;p&gt;This wasn't my idea, I'm just relaying the insight I got from the conversation.  I was busy shilling shamelessly for Twill when the real solution surfaced.&lt;/p&gt;
&lt;p&gt;The smart answer isn't to give the testers more tools.  The testers (as currently managed) don't see a need for tools.  The smart answer is to have the developers made officially responsible for unit tests, in HttpUnit (or Twill).  The developers need to put the unit tests into the source tree along with everything else.  They need to run the unit tests themselves.&lt;/p&gt;
&lt;p&gt;The official &amp;quot;testers&amp;quot; are now freed from the &amp;quot;test everything&amp;quot; requirement.  Instead, they can now do &amp;quot;guerilla testing&amp;quot; as well as review the unit test logs.&lt;/p&gt;
&lt;p&gt;At some point in time -- and at a higher level in the organization -- the testers need to be encouraged to use powerful scripting and unit testing tools as force multipliers.  They can claim that HttpUnit is too complex, but that's because they're looking at the wrong thing.&lt;/p&gt;
&lt;p&gt;They need to see that they can only point and click so fast.  A tool like Twill or HttpUnit can point and click a whole lost faster.  Until they're rewarded for speed, they don't have any incentive to master a tool.  Until they're given the incentive, every tool will be labeled as &amp;quot;too complex&amp;quot;.&lt;/p&gt;
&lt;/div&gt;
</content><category term="Python"></category><category term="#python"></category><category term="unit testing"></category></entry><entry><title>Another Dimensional Model Implementation</title><link href="https://slott56.github.io/2007_05_26-another_dimensional_model_implementation.html" rel="alternate"></link><published>2007-05-26T01:14:00-04:00</published><updated>2007-05-26T01:14:00-04:00</updated><author><name>S.Lott</name></author><id>tag:slott56.github.io,2007-05-26:/2007_05_26-another_dimensional_model_implementation.html</id><summary type="html">&lt;p&gt;The &lt;a class="reference external" href="http://sourceforge.net/projects/cubulus/"&gt;Cubulus&lt;/a&gt;  project and &lt;a class="reference external" href="http://alxtoth.webfactional.com/"&gt;Alexandru Toth&lt;/a&gt; 's page describe an &amp;quot;OLAP Aggregation Engine&amp;quot;.  It is very nice to see advanced work done on the dimensional model.&lt;/p&gt;
&lt;p&gt;The cited research dates from 1999 (V. Markl, F. Ramsak, R. Bayer, &amp;quot;Improving OLAP Performance by Multidimensional Hierarchical Clustering&amp;quot;, &lt;em&gt;Proceedings of the Intl. Database …&lt;/em&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;The &lt;a class="reference external" href="http://sourceforge.net/projects/cubulus/"&gt;Cubulus&lt;/a&gt;  project and &lt;a class="reference external" href="http://alxtoth.webfactional.com/"&gt;Alexandru Toth&lt;/a&gt; 's page describe an &amp;quot;OLAP Aggregation Engine&amp;quot;.  It is very nice to see advanced work done on the dimensional model.&lt;/p&gt;
&lt;p&gt;The cited research dates from 1999 (V. Markl, F. Ramsak, R. Bayer, &amp;quot;Improving OLAP Performance by Multidimensional Hierarchical Clustering&amp;quot;, &lt;em&gt;Proceedings of the Intl. Database Engineering and Applications Symposium&lt;/em&gt; , pp. 165-177, 1999.)  I'm suspicious that it predates the &amp;quot;bit-mapped index&amp;quot;.&lt;/p&gt;
&lt;p&gt;It may be that this technique helps a lot with an RDBMS that doesn't support the star schema via bit-mapped indexes.  It may be that this technique only helps a little with a more modern RDBMS.&lt;/p&gt;
&lt;p&gt;However, the idea of a nice, tidy Python application that helps manipulate the dimensional model is a great thing.&lt;/p&gt;
</content><category term="Python"></category><category term="#python"></category><category term="database"></category></entry><entry><title>Just for a moment, I though I'd found something SQLAlchemy doesn't do perfectly.</title><link href="https://slott56.github.io/2007_05_18-just_for_a_moment_i_though_id_found_something_sqlalchemy_doesnt_do_perfectly.html" rel="alternate"></link><published>2007-05-18T17:40:00-04:00</published><updated>2007-05-18T17:40:00-04:00</updated><author><name>S.Lott</name></author><id>tag:slott56.github.io,2007-05-18:/2007_05_18-just_for_a_moment_i_though_id_found_something_sqlalchemy_doesnt_do_perfectly.html</id><summary type="html">&lt;p&gt;After having written a number of application-specific object-relational mappers, I have been on the prowl for an elegant, enduring solution.  I had started to come to grips with &lt;a class="reference external" href="http://www.djangoproject.com/"&gt;Django&lt;/a&gt; , and like much of the approach.  Django has a tiny infrastructure feature (the settings.py file) which made it unpleasant to …&lt;/p&gt;</summary><content type="html">&lt;p&gt;After having written a number of application-specific object-relational mappers, I have been on the prowl for an elegant, enduring solution.  I had started to come to grips with &lt;a class="reference external" href="http://www.djangoproject.com/"&gt;Django&lt;/a&gt; , and like much of the approach.  Django has a tiny infrastructure feature (the settings.py file) which made it unpleasant to separate the ORM from the rest of the framework.  (Not impossible, just fleetingly unpleasant.)&lt;/p&gt;
&lt;p&gt;My first look at SQLAlchemy made it look over the top.  However, after the PyCon 2007 presentation, I realized that the layers were cleanly separated, and I could use the ORM without messing about in the SQL-in-Python-Notation layer.&lt;/p&gt;
&lt;p&gt;Then, I figured out (&amp;quot;&lt;a class="reference external" href="../C465799452/E20070322201220/index.html"&gt;PL/SQL vs. Java, Which One is Really Faster?&lt;/a&gt; &amp;quot;) that stored procedures were slow.  Given that PL/SQL is slow, what else in the RDBMS world is slow?  How much SQL is too much SQL, when speed matters?  That answer is forthcoming -- I'm still fussing around with experiments.&lt;/p&gt;
&lt;div class="section" id="problem-child"&gt;
&lt;h2&gt;Problem Child&lt;/h2&gt;
&lt;p&gt;The central issue started out as the all-too-common situation of &lt;strong&gt;Disjoint Subentities&lt;/strong&gt;.  This is where a single table has distinct classes of entities.  The usual symptoms of this are indicators or NULL columns.  Often, both are used.  Sometimes, the indicator is omitted, and the pattern of NULLs has to be used to discriminate among the entity classes.&lt;/p&gt;
&lt;p&gt;In this specific experiment, a single table has two subentities, each with different granularity.  One subentity has to be summed to match the grain of the other.  This gives us a union of two kinds of SQL queries: detailed and summary.&lt;/p&gt;
&lt;p&gt;The detailed query, in SQLAlchemy, looks like this:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
qrySingle= select(
    [stuff.c.groupName,stuff.c.amount,literal(1)],
    and_(stuff.c.status=='unmatched',
        stuff.c.subtype=='single'))
&lt;/pre&gt;
&lt;p&gt;In SQL, this is&lt;/p&gt;
&lt;pre class="literal-block"&gt;
SELECT &amp;quot;stuff&amp;quot;.&amp;quot;groupName&amp;quot;, &amp;quot;stuff&amp;quot;.amount, ?
FROM &amp;quot;stuff&amp;quot; WHERE &amp;quot;stuff&amp;quot;.status = ? AND &amp;quot;stuff&amp;quot;.subtype = ?
&lt;/pre&gt;
&lt;p&gt;This is precisely the SQL that would be coded &amp;quot;by hand&amp;quot;.  The literals (1, 'unmatched' and 'single') are bound into the SQL at run-time.&lt;/p&gt;
&lt;p&gt;The summary query looks like this in SQLAlchemy.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
qryMulti= select(
     [stuff.c.groupName,func.sum(stuff.c.amount),literal(2)],
     and_(stuff.c.status=='unmatched',
             stuff.c.subtype=='multi'),
     group_by=[stuff.c.groupName])
&lt;/pre&gt;
&lt;p&gt;And produces the following SQL.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
SELECT &amp;quot;stuff&amp;quot;.&amp;quot;groupName&amp;quot;, sum(&amp;quot;stuff&amp;quot;.amount), ?
FROM &amp;quot;stuff&amp;quot;
WHERE &amp;quot;stuff&amp;quot;.status = ? AND &amp;quot;stuff&amp;quot;.subtype = ?
GROUP BY &amp;quot;stuff&amp;quot;.&amp;quot;groupName&amp;quot;
&lt;/pre&gt;
&lt;p&gt;This is all very pleasant.  You can see that the literals (2, 'unmatched', 'multi') are bound in at run-time.  This technique often leads to a speed-up because the SQL statement can be reused by the RDBMS.  When coding by hand, this is easily overlooked.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="real-world"&gt;
&lt;h2&gt;Real World&lt;/h2&gt;
&lt;p&gt;In the &amp;quot;real world&amp;quot;, that is, the world of my clients, this kind of query is distressingly common.  And doing simulations and architectural recommendations is often made complex by having to cope with these kind of table designs.&lt;/p&gt;
&lt;p&gt;To work with this table, I needed a union, and (for a brief time) SQLAlchemy couldn't generate the correct SQL.&lt;/p&gt;
&lt;p&gt;Here's my union in SQLAlchemy.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
invQry= union( qrySingle, qryMulti )
&lt;/pre&gt;
&lt;p&gt;Here's the SQL which was generated.  Note that the GROUP-BY vanished.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
SELECT &amp;quot;stuff&amp;quot;.&amp;quot;groupName&amp;quot;, &amp;quot;stuff&amp;quot;.amount, ?
FROM &amp;quot;stuff&amp;quot;
WHERE &amp;quot;stuff&amp;quot;.status = ? AND &amp;quot;stuff&amp;quot;.subtype = ?
UNION SELECT &amp;quot;stuff&amp;quot;.&amp;quot;groupName&amp;quot;, sum(&amp;quot;stuff&amp;quot;.amount), ?
FROM &amp;quot;stuff&amp;quot;
WHERE &amp;quot;stuff&amp;quot;.status = ? AND &amp;quot;stuff&amp;quot;.subtype = ?
&lt;/pre&gt;
&lt;p&gt;Very disappointing.  However, it's since been fixed.  And the amazing speed of that fix is more reason to love SQLAlchemy and the folks who support it.  Many thanks!&lt;/p&gt;
&lt;p&gt;Now we can continue investigating which is faster: &amp;quot;Pure SQL&amp;quot; (i.e., complex stored procedures) or some programming language which uses SQL as necessary for persistence.&lt;/p&gt;
&lt;/div&gt;
</content><category term="Python"></category><category term="#python"></category><category term="database"></category></entry><entry><title>Dejavu and Python-based Dimensional Analysis</title><link href="https://slott56.github.io/2007_03_13-dejavu_and_python_based_dimensional_analysis.html" rel="alternate"></link><published>2007-03-13T10:14:00-04:00</published><updated>2007-03-13T10:14:00-04:00</updated><author><name>S.Lott</name></author><id>tag:slott56.github.io,2007-03-13:/2007_03_13-dejavu_and_python_based_dimensional_analysis.html</id><summary type="html">&lt;p&gt;Actually, the code looks like a clever expansion
on my example, in &lt;a class="reference external" href="https://slott56.github.io/2007_02_26-pycon_2007_revised.html"&gt;PyCon 2007
(Revised)&lt;/a&gt; .&lt;/p&gt;
&lt;p&gt;&amp;quot;But wait,&amp;quot; you
say.  &amp;quot;Creating a pivot table in
Python?&amp;quot;&lt;/p&gt;
&lt;p&gt;Of course.  Spreadsheets can
create pivot tables from dimensionally normalized data.  However, getting the
data in this form is often challenging and if there is …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Actually, the code looks like a clever expansion
on my example, in &lt;a class="reference external" href="https://slott56.github.io/2007_02_26-pycon_2007_revised.html"&gt;PyCon 2007
(Revised)&lt;/a&gt; .&lt;/p&gt;
&lt;p&gt;&amp;quot;But wait,&amp;quot; you
say.  &amp;quot;Creating a pivot table in
Python?&amp;quot;&lt;/p&gt;
&lt;p&gt;Of course.  Spreadsheets can
create pivot tables from dimensionally normalized data.  However, getting the
data in this form is often challenging and if there is any manual operation at
all, the data quality is immediately
suspect.&lt;/p&gt;
&lt;p&gt;To have perfect transparency
-- with no possibility of manual transformations -- you need a simple
application program which reliably, auditably, and testably produces the correct
data.  Further, you want to reduce the manual operations to formatting and
presentation.  The ideal solution is to produce the data in the required pivot
table so that it can be loaded into a spreadsheet for display
only.&lt;/p&gt;
&lt;p&gt;With an object-relational mapper,
you can write a tidy query to fetch raw data, and compute a aggregate along two
dimensions.  You then assemble result columns on one dimension and rows on the
other dimension.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Elegant -- But Dirty -- Pool.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The Elegant
Thing that makes this work pleasantly and simply in Python is being able to use
a tuple as the key to a mapping.  I can't say enough good things about this
simple, elegant piece of Pythonic programming.  You can easily handle complex,
multi-column keys in each dimension of the pivot table, by simply creating a
tuple of key values, and using a pair of tuples to locate the appropriate cell
in a mapping.&lt;/p&gt;
&lt;p&gt;Things like dimensional
conformance often create a gnarly algorithm in Java or -- shudder -- COBOL.  In
Python, it's a tuple that you can use to locate the dimension value in a
dictionary.  It works for everything except the Customer dimension, which in
some applications is too huge to retain in a simple in-memory
mapping.&lt;/p&gt;
&lt;p&gt;The graceful elegance of
&lt;strong&gt;Python's Mapping Indexed By A Tuple™&lt;/strong&gt;  (MXT) can really prevent a lot of
brain-cramping bugs.&lt;/p&gt;
</content><category term="Python"></category><category term="#python"></category><category term="database"></category></entry><entry><title>What a Data Warehouse Can Never Do</title><link href="https://slott56.github.io/2007_01_12-what_a_data_warehouse_can_never_do.html" rel="alternate"></link><published>2007-01-12T14:40:00-05:00</published><updated>2007-01-12T14:40:00-05:00</updated><author><name>S.Lott</name></author><id>tag:slott56.github.io,2007-01-12:/2007_01_12-what_a_data_warehouse_can_never_do.html</id><summary type="html">&lt;p&gt;In one form, the question is &amp;quot;How do we handle
the [X] transaction in the warehouse?&amp;quot;  Another form of the question is &amp;quot;What do
we do when [Y] changes?&amp;quot;   The third form is less clear, but essentially the
same: &amp;quot;How do we maintain [Z] in the
warehouse?&amp;quot;&lt;/p&gt;
&lt;p&gt;All of these …&lt;/p&gt;</summary><content type="html">&lt;p&gt;In one form, the question is &amp;quot;How do we handle
the [X] transaction in the warehouse?&amp;quot;  Another form of the question is &amp;quot;What do
we do when [Y] changes?&amp;quot;   The third form is less clear, but essentially the
same: &amp;quot;How do we maintain [Z] in the
warehouse?&amp;quot;&lt;/p&gt;
&lt;p&gt;All of these are questions
that superficially cover change management, but we're not really talking about
Kimball's &lt;strong&gt;Slowly Changing Dimension&lt;/strong&gt;  (SCD) design pattern.  It turns out,
we're talking about something more subtle and
confusing.&lt;/p&gt;
&lt;div class="section" id="system-of-record"&gt;
&lt;h2&gt;System of Record&lt;/h2&gt;
&lt;p&gt;The real questions are &lt;strong&gt;System of Record&lt;/strong&gt;  (SoR) questions.  In short, each
question is a version of &amp;quot;Where's the authoritative copy, and how do I keep it
current?&amp;quot;&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;The [X] transaction is, at least in
theory, part of a source application, a System of Record.  It is extracted from
SoR, transformed, and loaded into the warehouse.  The [X] transaction does not
change when the warehouse is implemented.  Unless, of course, there is no
SoR.&lt;/li&gt;
&lt;li&gt;The changes to [Y], similarly, should be
made in the SoR.  This is almost the same question as the &amp;quot;[X] transaction&amp;quot;
question, but it's asked about a piece of data, not a named business process.
The distinction reveals much about the processes which the warehouse must
support.&lt;/li&gt;
&lt;li&gt;The maintenance of [Z], clearly, should
be made in the SoR.  This is similar to the &amp;quot;changes to [Y]&amp;quot; question, but shows
a different point of view on what data is and why it
exists.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We'll look at these questions in a bit of depth.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="transactions-in-the-warehouse"&gt;
&lt;h2&gt;Transactions in the Warehouse&lt;/h2&gt;
&lt;p&gt;When someone asks
about the &amp;quot;[X] transaction,&amp;quot; they're often summarizing a business process.  In
general, every business process is either informal, or formalized.  Informal
transactions are done manually using desktop tools: email, spreadsheet, word
processing, etc.  No piece of software captures, manages and enforces the
transaction.&lt;/p&gt;
&lt;p&gt;Formal transactions have
three general patterns for their SoR: one SoR, many SoR's and a badly-chosen
SoR.  When there's one SoR, life is good.  The transaction happens in some
system (SAP, Oracle, QuickBooks, Aptiva, etc.)  It propagates through the
organization through ordinary Enterprise Application Integration (EAI)
techniques.  It winds up in the warehouse through ordinary
Extract-Transform-Load (ETL) processing.&lt;/p&gt;
&lt;p&gt;When there are multiple
SoR's, we have some challenges.  Sometimes, the relationship is &lt;em&gt;horizontal&lt;/em&gt;:
two peer business units have separate sources for similar data.  One unit has
SAP, the other has Aptiva.  This means that there may be common data which must
be conformed into a warehouse dimension.  So far, so good.&lt;/p&gt;
&lt;p&gt;Sometimes the relationship between SoR's is &lt;em&gt;vertical&lt;/em&gt;:
the parent company uses SAP, the subsidiary uses Great Plains.   This means that
there may be contradictions between the views of the common data.  When data is
moved up from the subsidiary, it may be aggregated: business entities are
elided, and the data is difficult (or impossible) to
conform.&lt;/p&gt;
&lt;p&gt;Sometimes the relationship between SoR's is &lt;em&gt;psychotic&lt;/em&gt;.
This often leads to a badly-chosen SoR.  A single organization can have the same
data in two applications and neither can be trusted to be the SoR.  They may
have customer data in Siebel and JDE, and the data is different, and can only be
reconciled manually.  Sigh.  No amount of Data Warehouse ETL can sort this out.
The organization must pick something as the SoR, and revise their business
processes to reflect that.&lt;/p&gt;
&lt;p&gt;In summary,
there are no transactions in the warehouse.  Transactions happen in the SoR, and
the results of those transactions are applied to the warehouse.  You must pick
an SoR.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="change-in-the-warehouse"&gt;
&lt;h2&gt;Change in the Warehouse&lt;/h2&gt;
&lt;p&gt;Sometimes, there is no System of Record.  There are two common cases: the data is maintained manually,
and the data is maintained through a cryptic transaction buried in the legacy
reporting application.  When data is maintained manually, we have a rather
difficult &lt;strong&gt;Master Data Management&lt;/strong&gt;  (MDM) issue because we don't have
an official SoR.  We're often in a bad position, here, because we're forced to
stop data warehouse development work to put a SoR in place.  This extra work can
be hard to justify; managers say &amp;quot;we never needed a system for that before, why now?&amp;quot;&lt;/p&gt;
&lt;p&gt;The answer is simple, but
unpleasant.  &amp;quot;It never worked before, either.&amp;quot;  People put in data warehouses
because their legacy reporting tools are incorrect or inconsistent.  One root
cause of errors is lack of a public, well-understood truth because of manual or
informal changes.&lt;/p&gt;
&lt;p&gt;The cryptic
transaction is the worst thing to ferret out.  Let's say we have two
applications, B and C, which each do parts of a business function.  Further, each
has it's little quirks, and we periodically must reconcile B and C's results
against each other.  How do we do this reconciliation when the two applications
are largely disjoint except where they have to be
reconciled?&lt;/p&gt;
&lt;p&gt;The usual solution is to
merge the data into a kind of data warehouse.  However, when there are
reconciliation problems, we hate to make a change to B or C, and re-run the
complete ETL cycle.  Instead we make the change directly in the warehouse.  Who
wants to duplicate this change in B or C?  No one, so we back-propagate the
change from the warehouse into the SoR's.  In effect, we've made the warehouse
the SoR.&lt;/p&gt;
&lt;p&gt;In summary, change in the
warehouse is limited to a historical snapshot of change in the SoR.  Change
happens in the SoR, and the results of the changes are applied to the warehouse.
You must pick an SoR.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="maintenance-in-the-warehouse"&gt;
&lt;h2&gt;Maintenance in the Warehouse&lt;/h2&gt;
&lt;p&gt;The question of
maintaining data in the warehouse usually stems from a warehouse design which
involves something more complex than simple facts and dimensions.  Generally, a
bridge table (often for a hierarchy) becomes a source of confusion.  Most
business entities (dates, accounts, products, documents, etc.) are pretty clear
in the source applications.  The facts are usually
obvious.&lt;/p&gt;
&lt;p&gt;It's the reporting
relationships that get confusing.  Something like product family can be a very
difficult thing to handle.  Something like a bill of materials (BoM) or
Organization Hierarchy (OH) can be even more
complex.&lt;/p&gt;
&lt;p&gt;In the product family case,
the reporting is an organization fiction.  It doesn't tie back to anything
except how managers chunk information.  In this case, the reporting hierarchy is
entirely a feature of the warehouse itself.  This is the pure Master Data
Management problem, where business entities are grouped in the warehouse
exclusively for the user's
convenience.&lt;/p&gt;
&lt;p&gt;In the BoM or OH case,
however, the reporting hierarchy does have an independent existence.  In the
case of the BoM, it ties to engineering or product configuration.  In the case
of OH, it ties to some project structure or accounting structure.  However,
these hierarchical structures don't often exist in the same simple form that
they do in the warehouse bridge table.  And this leads to confusion on how we
maintain the bridge table.&lt;/p&gt;
&lt;p&gt;In summary,
maintenance in the warehouse is limited to loading a historical snapshot of the
relationships in the SoR.  Maintenance happens in the SoR, and the results of
the maintenance are applied to the warehouse.  You must depend on an SoR.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="bridge-tables-maintenance"&gt;
&lt;h2&gt;Bridge Tables Maintenance&lt;/h2&gt;
&lt;p&gt;There are several
varieties of Bridge Tables.  We'll address hierarchy, since it seems to lead to
the most confusion.  We'll touch on minidimension and outrigger tables, also,
since the same design pattern applies to those.&lt;/p&gt;
&lt;p&gt;The essential worry about
hierarchies stems from the fact that a hierarchy bridge table can have many more
rows than the  dimension it bridges.  Generally, it's an &lt;span class="formula"&gt;&lt;i&gt;n&lt;/i&gt;log(&lt;i&gt;n&lt;/i&gt;)&lt;/span&gt;
kind of multiplication, where &lt;span class="formula"&gt;log(&lt;i&gt;n&lt;/i&gt;)&lt;/span&gt; is an estimate of the depth of the hierarchy.&lt;/p&gt;
&lt;p&gt;As a practical matter,
moving one child to another parent is a single row change in the original data.
However, the expansion in the bridge table means that &lt;span class="formula"&gt;2&lt;i&gt;d&lt;/i&gt;&lt;/span&gt; rows will change, where &lt;span class="formula"&gt;&lt;i&gt;d&lt;/i&gt;&lt;/span&gt; is
the depth of the node in the hierarchy.  For some reason, this is intimidating.&lt;/p&gt;
&lt;p&gt;There are two solutions:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Reload the entire bridge table with each
source change.  This is easy to implement but slow.  If you use SCD change
tracking, you'll have lots of nearly identical rows that are labeled with change
dates because they were associated with a source node change.&lt;/li&gt;
&lt;li&gt;Recompute just the changed parentage,
updating only those rows of the bridge table.  This is not significantly more
complex.  First, write a &amp;quot;find-all-parents&amp;quot; function, and apply this across
every element of the source data to populate the bridge initially.  Then, you
can use the &amp;quot;find-all-parents&amp;quot; function to compute just the relevant bridge
table changes when a source node changes.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A similar pattern is appropriate for
minidimensions and outriggers, which are based on subsets of a dimension.  The
lazy approach is to rebuild these each time the dimension changes.  A slightly
more efficient approach is to derive just the changed rows from the changes in
the dimension.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="bottom-line"&gt;
&lt;h2&gt;Bottom Line&lt;/h2&gt;
&lt;p&gt;Change doesn't happen in the warehouse.  Change happens in the SoR.
The warehouse merely captures the effect of that change.&lt;/p&gt;
&lt;/div&gt;
</content><category term="Python"></category><category term="#python"></category><category term="database"></category></entry><entry><title>Refactoring and Unit Testing</title><link href="https://slott56.github.io/2006_10_11-refactoring_and_unit_testing.html" rel="alternate"></link><published>2006-10-11T00:19:00-04:00</published><updated>2006-10-11T00:19:00-04:00</updated><author><name>S.Lott</name></author><id>tag:slott56.github.io,2006-10-11:/2006_10_11-refactoring_and_unit_testing.html</id><summary type="html">&lt;p&gt;I do a fair amount of manual refactoring.  I've
used WebSphere Studio (Eclipse) to do some automated refactoring, so I have some
experience in using IDE's which exploit Java's static type-checking.&lt;/p&gt;
&lt;p&gt;However, the question of
type checking in a dynamic language is interesting.  I don't use a sophisticated
IDE for …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I do a fair amount of manual refactoring.  I've
used WebSphere Studio (Eclipse) to do some automated refactoring, so I have some
experience in using IDE's which exploit Java's static type-checking.&lt;/p&gt;
&lt;p&gt;However, the question of
type checking in a dynamic language is interesting.  I don't use a sophisticated
IDE for Python development.  So, I have limited experience using an IDE to do
refactoring in a dynamic language.&lt;/p&gt;
&lt;p&gt;However, JB notes&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;quot;I'm having
some heartburn about hierarchical type
systems as a way of determining 1)
conformability and 2) managing commitments of
semantically equivalent behavior.&lt;/p&gt;
&lt;p&gt;...&lt;/p&gt;
&lt;p&gt;Seems a constraining way to do it, to me, not
that I have a better alternative at the
moment.&amp;quot;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="section" id="duck-typing"&gt;
&lt;h2&gt;Duck Typing&lt;/h2&gt;
&lt;p&gt;Since Python relies on
&lt;a class="reference external" href="http://en.wikipedia.org/wiki/Duck_typing"&gt;Duck
Typing&lt;/a&gt; , refactoring takes on an interesting new dimension.  We aren't
constrained to simply shuffle methods up and down the class hierarchy.  We are
now able to -- well -- put a method just about anywhere.&lt;/p&gt;
&lt;p&gt;Further, since Python doesn't have a
simple, single-inheritance model, the &amp;quot;hierarchical&amp;quot; type system doesn't
completely apply.&lt;/p&gt;
&lt;p&gt;For these reasons,
refactoring in Python is one potentially complex problem.&lt;/p&gt;
&lt;p&gt;From what I understand of
Ruby, you can override a class method without creating a subclass, essentially
redefining a base class in some obscure way.  This gives me the willies because
it makes refactoring a problem without any sensible boundaries.  Maybe I'm
misunderstanding Ruby, and have this wrong.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="essential-use-cases"&gt;
&lt;h2&gt;Essential Use Cases&lt;/h2&gt;
&lt;p&gt;The principal refactoring
use case involves moving a common method up the inheritance hierarchy.  As a
practical matter, this does happen once in a while.&lt;/p&gt;
&lt;p&gt;An additional text-book
refactoring use case arises when we're adding or removing whole methods in the
subclass hierarchy.&lt;/p&gt;
&lt;p&gt;The fringe use case is a variation on the theme of &lt;tt class="docutils literal"&gt;SubClass1.methodA&lt;/tt&gt;
looking a lot like &lt;tt class="docutils literal"&gt;Subclass2.methodA&lt;/tt&gt;,
but they're not the same.  There are two interesting cases.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;SC1.mA()&lt;/tt&gt; is a superset of &lt;tt class="docutils literal"&gt;SC2.mA()&lt;/tt&gt;.
All of &lt;tt class="docutils literal"&gt;SC2.mA()&lt;/tt&gt; &lt;cite&gt;gets refactored up, and ``SC1.mA()`&lt;/cite&gt;
overrides it to add features.&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;SC1.mA()&lt;/tt&gt; overlaps with &lt;tt class="docutils literal"&gt;SC2.mA()&lt;/tt&gt;.
Some common functionality has to get extracted, moved up the hierarchy;
&lt;tt class="docutils literal"&gt;SC1.mA()&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;SC2.mA()&lt;/tt&gt; are rebuilt around this common kernel.&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;SC1.mA()&lt;/tt&gt; has no usable relationship with &lt;tt class="docutils literal"&gt;SC2.mA()&lt;/tt&gt;.
What now?  In some cases, a complete change in design may be called for.  The mere
presence of this situation is diagnostic of the designer having missed
something.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="beyond-the-fringe"&gt;
&lt;h2&gt;Beyond the Fringe&lt;/h2&gt;
&lt;p&gt;Outside the fringe of
ordinary refactoring are the &lt;strong&gt;New Design Pattern&lt;/strong&gt;™ situations.  Mostly, these are
&lt;strong&gt;Strategy&lt;/strong&gt; situations, where what looks -- initially -- like a variant method grows into a
different approach as we learn more about the
solution.&lt;/p&gt;
&lt;p&gt;Consider a pair of ordinary
Entity classes that look like different entities because of different behavior.
However, they have the same attributes, and almost identical methods.  The only
difference is one algorithm.  This can be done through inheritance, but
sometimes that variant algorithm is only the tip of the iceberg, and there is
more variability just below the
surface.&lt;/p&gt;
&lt;p&gt;At this point, we realize we need a
&lt;strong&gt;Strategy&lt;/strong&gt; hierarchy to contain the variant algorithms, not a hierarchy of ordinary
Entities.  How does refactoring work here, where we're moving the functionality
out of a class hierarchy into a different class hierarchy?  Is this even
refactoring, or is it the more general case of redesign?&lt;/p&gt;
&lt;p&gt;It doesn't feel like
refactoring because  we aren't shuffling methods up and down the class
hierarchy.  In Python, the Duck Typing means we don't actually need a proper
hierarchy for the &lt;strong&gt;Strategy&lt;/strong&gt; class definitions.  Consequently, we're free to make significant structural
changes that I don't think an IDE can ever help with.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="across-the-spectrum"&gt;
&lt;h2&gt;Across the Spectrum&lt;/h2&gt;
&lt;p&gt;One potential problem
with this is captured in the comment that &amp;quot;[the compiler] can’t help but
see your code as a pile of text&amp;quot;.  By extension, then, the IDE can't do anything
more than treat source as text, losing precious semantic information.&lt;/p&gt;
&lt;p&gt;However, when doing a fundamental
restructuring (from class methods to Strategy hierarchy), the source code
information available to the compiler (or the IDE) isn't of much value until
you've finished.  Nothing helps you when you're in the middle of this.  Until
the semantic information exists, no IDE can help you manage and maintain the
semantic information.&lt;/p&gt;
&lt;p&gt;There are parts of design (and redesign) that are hard.  I think anyone would agree that the
earliest phases of noodling around about a problem are done without benefit of
an IDE or formal semantics.  When the design is merely conceptual, tools can't
help.&lt;/p&gt;
&lt;p&gt;I think refactoring includes a very broad spectrum.  At one end, things are essentially mechanical; at the
other end things, are completely conceptual.  This isn't really a problem that
needs a solution; it doesn't need tools.  It's part of the game of moving from a
good idea to software.  Some parts of the good idea don't have formal semantics.
Eventually, when formal semantics exist, tools can be
applied.&lt;/p&gt;
&lt;p&gt;In the case of Python, I suspect that IDE support for refactoring could only be feeble at best.  The
mechanical end of the spectrum is so easy that tools aren't required.   At the
conceptual end of the spectrum, tools don't help in the first place.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="the-middle-ground"&gt;
&lt;h2&gt;The Middle Ground&lt;/h2&gt;
&lt;p&gt;One might argue that simple, mechanical refactoring can be aided by the presence of static type
declarations.  However, my experience is that this covers only the most mundane
of the refactoring use cases.  In Python, we just move the method around.&lt;/p&gt;
&lt;p&gt;In Python, there's a double whammy:
checking types can't be done because the language traditionally lacked type
declarations.  Further -- and more important -- type checking doesn't need to be
done because the language is dynamic.  It can't be done, and even if it could,
it didn't matter anyway.&lt;/p&gt;
&lt;p&gt;This is overly
simplistic, however.  There is some type checking which can be done in Python.
The &lt;a class="reference external" href="http://epydoc.sourceforge.net/"&gt;epydoc&lt;/a&gt;  package does considerable analysis of
source as part of writing documentation.  It spots unused arguments, and can
spot certain kinds of obvious mismatches in number of arguments vs. parameters.&lt;/p&gt;
&lt;p&gt;When we look at JB's point on
committing to specific semantics, we see something even more profound.  It goes
way beyond what even Java is capable of checking or
automating.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="the-formal-specification"&gt;
&lt;h2&gt;The Formal Specification&lt;/h2&gt;
&lt;p&gt;JB is asking for a
level beyond syntax, beyond type matching and off into &amp;quot;intent&amp;quot;.  JB appears to
be looking for formal assertions of preconditions and postconditions that he can
use to determine how to redesign methods to make them refactorable, and then how
to refactor the changed design.&lt;/p&gt;
&lt;p&gt;JB's formality would be a nice thing to capture.  If every statement had a proper
precondition and postcondition, then we could prove almost anything about our
software except whether or not the loops actually terminated.  (That can't be
formally proven in a system with the same expressive power as software, it
requires more sophisticated logical tools.)&lt;/p&gt;
&lt;p&gt;Since Java and Python have
added additional markers (annotations and decorators) JB's assertions could be
captured, to an extent.  You'd have to implement a simple &amp;quot;for all&amp;quot; and &amp;quot;there
exists&amp;quot; predicate, but Python has a nice reduce that can be paired with a lambda
that allows you to write a &amp;quot;for all&amp;quot;; from this you can built a &amp;quot;there exists&amp;quot;.&lt;/p&gt;
&lt;p&gt;I'm not sure how helpful formal assertions would be.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="pragmatic-refactoring"&gt;
&lt;h2&gt;Pragmatic Refactoring&lt;/h2&gt;
&lt;p&gt;When working in the
center of the refactoring use cases, IDE aids are helpful.  When working at the
fringe, they're just visual noise.  Indeed, when redesigning something, I have
to be sure not to look at any of the &amp;quot;helpful&amp;quot; messages from Eclipse because
it's checking for errors using obsolete type information.  When I've broken the
whole thing down into a workbench full of parts, the semantic checks aren't even
meaningful.  Once I get it put back together again, automated checking can be
handy to assure a complete job.&lt;/p&gt;
&lt;p&gt;In Python, breaking the whole thing down as part of a redesign is so much simpler.
We don't have the artifice of &amp;quot;interface&amp;quot; to keep to a single inheritance model
with static type checking across multiple aspects of a class.  We just move the
methods around.  We have multiple inheritance, and we don't need formal
interface declarations.&lt;/p&gt;
&lt;p&gt;Indeed, it's
far, far easier to produce a working design in Python, and use that as a formal
specification for a Java program.  I can tweak and tinker, optimizing
performance and simplifying without the rigid formality of Java.  Adding proper
class hierarchies and turning multiple inheritance into single+interface
inheritance is typically a pretty easy transformation.  Since I knew I was
aiming at Java in the first place, I avoided Pythonisms that don't translate.&lt;/p&gt;
&lt;p&gt;While it's true that we
don't need Java's formality in Python, much of that formality is helpful.  I
find it easier to work with a proper inheritance hierarchy, one that has
explicit Not Implemented exceptions to mark the place-holders.  I like to have a
tidy interface definition so that I can document the interface.  This additional
material makes refactoring slightly more complex, but could help an automated
tool do some useful method matching among classes.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="the-final-test"&gt;
&lt;h2&gt;The Final Test&lt;/h2&gt;
&lt;p&gt;Without appropriate unit
tests, refactoring is impossible.  Even in Java, with a swanky IDE that checks
everything, you still have potential problems which are uncheckable.  In
particular, a mis-named subclass method cannot be detected except by &amp;quot;near-miss&amp;quot;
fuzzy-matching rules that will almost always work and will have false-positives.
Only unit testing can locate this situation.&lt;/p&gt;
&lt;p&gt;Unit testing absolutely is a
stand-in for things the compiler can't check.  You can portray the heavy use of
unit testing as a negative (&amp;quot;the compiler can't be trusted&amp;quot;) or as a pragmatic
approach to verifying the things you can't formally state.  All of the
assertions in the world won't find a spelling mistake.&lt;/p&gt;
&lt;p&gt;Worse, your formal
declarations (post-condition assertions or type definitions) could just as
easily be wrong.  A tidy formal proof with a wrong piece of logic will derive an
incorrect program.  A misspelled class name may compile, but still fail a suite
of tests.&lt;/p&gt;
&lt;p&gt;Since the IDE can't register intent very well, it isn't a complete solution.
In the case of redesign, it isn't even very helpful.&lt;/p&gt;
&lt;/div&gt;
</content><category term="Python"></category><category term="#python"></category><category term="unit testing"></category></entry><entry><title>Python OODB (Revised)</title><link href="https://slott56.github.io/2006_06_20-python_oodb_revised.html" rel="alternate"></link><published>2006-06-20T10:35:00-04:00</published><updated>2006-06-20T10:35:00-04:00</updated><author><name>S.Lott</name></author><id>tag:slott56.github.io,2006-06-20:/2006_06_20-python_oodb_revised.html</id><summary type="html">&lt;p&gt;Simple object persistence (i.e., serialization to
a file system) is what pickle, marshal and shelve
do.&lt;/p&gt;
&lt;p&gt;However, here's the next thing of
some interest OODB's.&lt;/p&gt;
&lt;p&gt;Zope's &lt;a class="reference external" href="http://www.zope.org/Wikis/ZODB/FrontPage"&gt;ZODB&lt;/a&gt; .  The original OODB for Python, the
backbone of Zope.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://buzhug.sourceforge.net/"&gt;buzhug&lt;/a&gt; :
&amp;quot;a fast, pure-Python database engine, using a syntax that Python programmers
should …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Simple object persistence (i.e., serialization to
a file system) is what pickle, marshal and shelve
do.&lt;/p&gt;
&lt;p&gt;However, here's the next thing of
some interest OODB's.&lt;/p&gt;
&lt;p&gt;Zope's &lt;a class="reference external" href="http://www.zope.org/Wikis/ZODB/FrontPage"&gt;ZODB&lt;/a&gt; .  The original OODB for Python, the
backbone of Zope.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://buzhug.sourceforge.net/"&gt;buzhug&lt;/a&gt; :
&amp;quot;a fast, pure-Python database engine, using a syntax that Python programmers
should find very intuitive.&amp;quot;&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://pypersyst.org/"&gt;PyPerSyst&lt;/a&gt;  &amp;quot;fast,
reliable, and flexible object persistence with a small footprint, suitable for
embedding in other Python
applications.&amp;quot;&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://couchdb.infogami.com/"&gt;CouchDB&lt;/a&gt;  &amp;quot;A
stand-alone document store, [which] most closely resembles the Lotus
Notes/Domino storage engine.&amp;quot;&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://www.objectivity.com/blogs/insider/expert_opinion/languages/python/"&gt;ObjectivityDB/Python&lt;/a&gt;  &amp;quot;a high performance and
robust Object-Oriented Database Management System [ODBMS].&amp;quot;&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://divmod.org/trac/wiki/DivmodAxiom"&gt;Axiom&lt;/a&gt;  &amp;quot;Axiom is an object database, or
alternatively, an object-relational mapper.&amp;quot;  The pleasant thing is that you
don't really care which.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://www.mems-exchange.org/software/durus/"&gt;Durus&lt;/a&gt;  &amp;quot;a persistent object system for
applications written in the Python programming
language.&amp;quot;&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://www.itamarst.org/software/cog/"&gt;http://www.itamarst.org/software/cog/&lt;/a&gt;
(not &lt;a class="reference external" href="http://wiki.cogkit.org/index.php/Main_Page"&gt;CoG&lt;/a&gt; , the Commodity Grid) is the Checkpointed
Object Graph, which provides &amp;quot;semi-transparent persistence for large sets of
interrelated Python objects.&amp;quot;&lt;/p&gt;
</content><category term="Python"></category><category term="#python"></category><category term="database"></category></entry><entry><title>Doctest beyond Python</title><link href="https://slott56.github.io/2006_04_17-doctest_beyond_python.html" rel="alternate"></link><published>2006-04-17T14:53:00-04:00</published><updated>2006-04-17T14:53:00-04:00</updated><author><name>S.Lott</name></author><id>tag:slott56.github.io,2006-04-17:/2006_04_17-doctest_beyond_python.html</id><summary type="html">&lt;p&gt;This is something that elevates Doctest into the
realm of Pattern.  Perhaps even above
that.&lt;/p&gt;
&lt;p&gt;The idea is so elegant: the
document is the test, and the test procedure is the
document.&lt;/p&gt;
&lt;p&gt;There's a &lt;a class="reference external" href="http://en.wikipedia.org/wiki/Don't_repeat_yourself"&gt;DRY&lt;/a&gt;  clarity to the whole thing that is rather
exciting.  It is an elegant application of …&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is something that elevates Doctest into the
realm of Pattern.  Perhaps even above
that.&lt;/p&gt;
&lt;p&gt;The idea is so elegant: the
document is the test, and the test procedure is the
document.&lt;/p&gt;
&lt;p&gt;There's a &lt;a class="reference external" href="http://en.wikipedia.org/wiki/Don't_repeat_yourself"&gt;DRY&lt;/a&gt;  clarity to the whole thing that is rather
exciting.  It is an elegant application of basic &lt;a class="reference external" href="http://en.wikipedia.org/wiki/Literate_programming"&gt;Literate Programming&lt;/a&gt;
principles.&lt;/p&gt;
&lt;p&gt;The best part is that it is
difficult to do in other languages.  Ruby and Perl have the necessary
interactive execution modes.  But in Java, it would be a nightmare to define all
the required overheads to have a standardized exercise framework that paralleled
the Python interactive execution
mode.&lt;/p&gt;
&lt;p&gt;This makes the &amp;quot;Doctest&amp;quot; pattern
a key value proposition for any new language or environment.  If you can
implement the Doctest pattern, you have something that creates value by binding
testing and documentation into one tidy package.  If you can't implement the
Doctest pattern, perhaps you should rethink your implementation because you
can't easily compete against Python.&lt;/p&gt;
</content><category term="Python"></category><category term="#python"></category><category term="unit testing"></category></entry><entry><title>Python Object-Relational Mapping (Revised)</title><link href="https://slott56.github.io/2006_04_13-python_object_relational_mapping_revised.html" rel="alternate"></link><published>2006-04-13T02:37:00-04:00</published><updated>2006-04-13T02:37:00-04:00</updated><author><name>S.Lott</name></author><id>tag:slott56.github.io,2006-04-13:/2006_04_13-python_object_relational_mapping_revised.html</id><summary type="html">&lt;p&gt;Ian Bicking: A Blog &lt;a class="reference external" href="http://blog.ianbicking.org/"&gt;http://blog.ianbicking.org/&lt;/a&gt;,
provided some info on Py3K and Python Introspection &lt;a class="reference external" href="http://blog.ianbicking.org/introspecting-expressions-in-py3k.html"&gt;http://blog.ianbicking.org/introspecting-expressions-in-py3k.html&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For
me, the interesting part was his summary of Object-Relational Mapping.  Mr.
Bicking identifies two broad approaches: lambda introspection and operator
overloading.&lt;/p&gt;
&lt;div class="section" id="lambda-introspection"&gt;
&lt;h2&gt;Lambda Introspection&lt;/h2&gt;
&lt;p&gt;&lt;a class="reference external" href="http://projects.amor.org/dejavu"&gt;Dejavu&lt;/a&gt;
It primarily uses …&lt;/p&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;Ian Bicking: A Blog &lt;a class="reference external" href="http://blog.ianbicking.org/"&gt;http://blog.ianbicking.org/&lt;/a&gt;,
provided some info on Py3K and Python Introspection &lt;a class="reference external" href="http://blog.ianbicking.org/introspecting-expressions-in-py3k.html"&gt;http://blog.ianbicking.org/introspecting-expressions-in-py3k.html&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For
me, the interesting part was his summary of Object-Relational Mapping.  Mr.
Bicking identifies two broad approaches: lambda introspection and operator
overloading.&lt;/p&gt;
&lt;div class="section" id="lambda-introspection"&gt;
&lt;h2&gt;Lambda Introspection&lt;/h2&gt;
&lt;p&gt;&lt;a class="reference external" href="http://projects.amor.org/dejavu"&gt;Dejavu&lt;/a&gt;
It primarily uses a generic &lt;a class="reference external" href="http://www.martinfowler.com/eaaCatalog/dataMapper.html"&gt;Data Mapper&lt;/a&gt;  architecture.  It is more of an OODB
backed by a relational store.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://subway.python-hosting.com/wiki/SQLComp"&gt;SQLComp&lt;/a&gt;  The make_query method examines a lambda
containing a list comprehension to create SQL.  This is only queries, and isn't
a complete ORM.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="operator-overloading"&gt;
&lt;h2&gt;Operator Overloading&lt;/h2&gt;
&lt;p&gt;&lt;a class="reference external" href="http://sqlobject.org/"&gt;SQLObject&lt;/a&gt;  This is
a very complete ORM, cast in the some mold as
Django.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://sqlalchemy.org/"&gt;SQLAlchemy&lt;/a&gt; This provides a Pythonic definition
of SQL metadata and a mapping from the SQL metadata to Python class definitions.
This is a very, very rich approach, allowing you to straddle the SQL and Object
worlds explicitly.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://pyorq.sourceforge.net/"&gt;PyORQ&lt;/a&gt;   This
is an older ORM with a few data types but a very &amp;quot;naked&amp;quot; use of overloaded
operators to perform queries.  Unlike the lambda overloading, the class provides
operators that are set operations for
queries.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="non-introspective-approaches"&gt;
&lt;h2&gt;Non-Introspective Approaches&lt;/h2&gt;
&lt;p&gt;&lt;a class="reference external" href="http://www.djangoproject.com/"&gt;Django&lt;/a&gt; , for example, encodes attributes and
operators as keyword parameters to methods.  It doesn't look inside the Python
code, but parses the keywords.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://skunkweb.sourceforge.net/"&gt;PyDO2&lt;/a&gt;
encodes the query explicitly, using functions that mirror SQL operators or
tuples that contain string names for the
functions.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://www.qlime.org/"&gt;QLime&lt;/a&gt;   is an ORM with functional notation,
similar to PyDO2.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://www.tux4web.de/computer/software/orm/"&gt;ORM&lt;/a&gt;  (the Object-Relational Membrane) mostly
captures SQL metadata in Python.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://projects.almad.net/dbclass"&gt;DBClass&lt;/a&gt;
is focused on an easy way to hack around with SQL queries (to get data from
procedures and so on).&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://divmod.org/trac/wiki/DivmodAxiom"&gt;Axiom&lt;/a&gt;  is an object database, or alternatively,
an object-relational mapper.  It depends on &lt;a class="reference external" href="http://divmod.org/trac/wiki/DivmodEpsilon"&gt;Epsilon&lt;/a&gt; .&lt;/p&gt;
&lt;p&gt;The
Python wiki page on &lt;a class="reference external" href="http://wiki.python.org/moin/HigherLevelDatabaseProgramming"&gt;Higher Level Database Programming&lt;/a&gt;   has
additional notes and products that are high
level.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="garden-variety-relational-access"&gt;
&lt;h2&gt;Garden-Variety Relational Access&lt;/h2&gt;
&lt;p&gt;All of these modules
provide the standard &lt;a class="reference external" href="http://www.python.org/dev/peps/pep-0249/"&gt;DB-API&lt;/a&gt;  (PEP 249) interface to a SQL database.&lt;/p&gt;
&lt;p&gt;The most visible access layer product
is &lt;a class="reference external" href="http://www.egenix.com/files/python/eGenix-mx-Extensions.html"&gt;mx.ODBC&lt;/a&gt;  for bare ODBC connectivity.  This has
the advantage of wide portability, and the disadvantage of the narrow ODBC
interface.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://pdo.neurokode.com/"&gt;PDO&lt;/a&gt;  wraps a
variety of other access methods into a single, combined package.  I'm not
precisely sure why it adds another interface layer, but it appears to simply do
away with Cursor objects.  However, it does provide a nice list of DB-API 2.0
modules for direct SQL access.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://sourceforge.net/projects/mysql-python"&gt;MySQLdb&lt;/a&gt;  for
MySQL&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://initd.org/tracker/pysqlite"&gt;PySQLite&lt;/a&gt;  and &lt;a class="reference external" href="http://www.rogerbinns.com/apsw.html"&gt;APSW&lt;/a&gt;
are for the ultra-lightweight SQLite
RDBMS.&lt;/p&gt;
&lt;p&gt;The &lt;a class="reference external" href="http://python.projects.postgresql.org/"&gt;PostgresPy&lt;/a&gt;   project will address many PostgreSQL
topics.  &lt;a class="reference external" href="http://www.pygresql.org/"&gt;PyGreSql&lt;/a&gt;  (aka pgdb), &lt;a class="reference external" href="http://www.initd.org/projects/psycopg1"&gt;psycopg&lt;/a&gt; , &lt;a class="reference external" href="http://www.zope.org/Members/tm/PoPy"&gt;PoPy&lt;/a&gt; ,
&lt;a class="reference external" href="http://barryp.org/software/bpgsql"&gt;bpgsql&lt;/a&gt; .&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://kinterbasdb.sourceforge.net/"&gt;kinterbasdb&lt;/a&gt;  Firebird and Borland's
Interbase&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://sourceforge.net/projects/pydb2/"&gt;pyDB2&lt;/a&gt;
DB/2&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://www.cxtools.net/default.aspx?nav=cxorlb%22%20target=%22NewWindow"&gt;cx_Oracle&lt;/a&gt;
Oracle&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://adodbapi.sourceforge.net/"&gt;adodbapi&lt;/a&gt;
Python access to the MS Windows ADO
interface&lt;/p&gt;
&lt;p&gt;The Python wiki page on &lt;a class="reference external" href="http://wiki.python.org/moin/DatabaseInterfaces"&gt;Database Interfaces&lt;/a&gt;  also has a list of these
product-specific access
modules.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="recommendations"&gt;
&lt;h2&gt;Recommendations&lt;/h2&gt;
&lt;p&gt;Rule 1.  Do development with SQLite.  Why? Eschew Features.  Focus on RDBMS for
relational store, focus on Python for processing.  Stored Procedures and
Triggers are a product-specific mine-field.  Once the model passes unit tests,
move to another RDBMS that supports concurrent
users.&lt;/p&gt;
&lt;p&gt;Rule 2.  For OLTP, use an
OR-Mapping and stay away from naked SQL.  However (and this is a big however)
you will likely be supporting ad-hoc reporting through SQL-based report writers.
There are two extemes.  At one end is Deja-Vu, which may be too far from the
underlying SQL.   The other end begins with SQLAlchemy, which may expose too
much SQL; ORM and DBClass may be too light on object
features.&lt;/p&gt;
&lt;p&gt;Rule 3.  For OLAP, you have
two kinds of applications.  Some parts (like dimension conformance) can use an
OR-Mapping because they are OLAP-like.  For some loading, aggregation and
extraction, use direct SQL drivers for the chosen product.  For the large-volume
fact-oriented loads, use the vendor-supplied bulk loader.  Portability is not
your concern.&lt;/p&gt;
&lt;/div&gt;
</content><category term="Python"></category><category term="#python"></category><category term="database"></category></entry><entry><title>Agile Testing Goodies from PyCon 2006</title><link href="https://slott56.github.io/2006_02_27-agile_testing_goodies_from_pycon_2006.html" rel="alternate"></link><published>2006-02-27T11:26:00-05:00</published><updated>2006-02-27T11:26:00-05:00</updated><author><name>S.Lott</name></author><id>tag:slott56.github.io,2006-02-27:/2006_02_27-agile_testing_goodies_from_pycon_2006.html</id><summary type="html">&lt;p&gt;A number of testing frameworks were used.  The
Agile Testing tutorial provides a path through the toolsets, showing what you
can do, and how you should do it.&lt;/p&gt;
&lt;p&gt;Unit
Testing:  [&lt;a class="reference external" href="http://somethingaboutorange.com/mrl/projects/nose/"&gt;Nose&lt;/a&gt; ], &amp;lt;{filename}/blog/2005/11/2005_11_09-compare_and_contrast_round_3_revised.rst&amp;gt;&lt;/p&gt;
&lt;p&gt;Acceptance
Testing:  [&lt;a class="reference external" href="http://fitnesse.org/FrontPage"&gt;FitNesse&lt;/a&gt; ]&lt;/p&gt;
&lt;p&gt;Regression
Testing:  [&lt;a class="reference external" href="http://texttest.carmen.se/index.html"&gt;TextTest&lt;/a&gt; ]&lt;/p&gt;
&lt;p&gt;Functional
Testing:  [&lt;a class="reference external" href="http://www.idyll.org/~t/www-tools/twill/"&gt;twill&lt;/a&gt; ].  A thorough analysis is …&lt;/p&gt;</summary><content type="html">&lt;p&gt;A number of testing frameworks were used.  The
Agile Testing tutorial provides a path through the toolsets, showing what you
can do, and how you should do it.&lt;/p&gt;
&lt;p&gt;Unit
Testing:  [&lt;a class="reference external" href="http://somethingaboutorange.com/mrl/projects/nose/"&gt;Nose&lt;/a&gt; ], &amp;lt;{filename}/blog/2005/11/2005_11_09-compare_and_contrast_round_3_revised.rst&amp;gt;&lt;/p&gt;
&lt;p&gt;Acceptance
Testing:  [&lt;a class="reference external" href="http://fitnesse.org/FrontPage"&gt;FitNesse&lt;/a&gt; ]&lt;/p&gt;
&lt;p&gt;Regression
Testing:  [&lt;a class="reference external" href="http://texttest.carmen.se/index.html"&gt;TextTest&lt;/a&gt; ]&lt;/p&gt;
&lt;p&gt;Functional
Testing:  [&lt;a class="reference external" href="http://www.idyll.org/~t/www-tools/twill/"&gt;twill&lt;/a&gt; ].  A thorough analysis is at &lt;a class="reference external" href="http://www.advogato.org/article/874.html"&gt;http://www.advogato.org/article/874.html&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Ajax
Interaction Testing:  [&lt;a class="reference external" href="http://www.openqa.org/selenium/"&gt;Selenium&lt;/a&gt; ] and PAMIE &lt;a class="reference external" href="http://pamie.sourceforge.net/"&gt;http://pamie.sourceforge.net/&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Literate
Testing:  [&lt;a class="reference external" href="http://www.python.org/doc/lib/module-doctest.html"&gt;doctest&lt;/a&gt; ] and epydoc &lt;a class="reference external" href="http://epydoc.sourceforge.net/"&gt;http://epydoc.sourceforge.net/&lt;/a&gt;.&lt;/p&gt;
</content><category term="Python"></category><category term="#python"></category><category term="unit testing"></category></entry><entry><title>testresources</title><link href="https://slott56.github.io/2005_12_26-testresources.html" rel="alternate"></link><published>2005-12-26T13:57:00-05:00</published><updated>2005-12-26T13:57:00-05:00</updated><author><name>S.Lott</name></author><id>tag:slott56.github.io,2005-12-26:/2005_12_26-testresources.html</id><summary type="html">&lt;p&gt;&lt;tt class="docutils literal"&gt;testresources&lt;/tt&gt; &lt;a class="reference external" href="http://www.robertcollins.net/unittest/testresources/"&gt;http://www.robertcollins.net/unittest/testresources/&lt;/a&gt;
purpose appears to be to manage the resources used by a test suite.&lt;/p&gt;
&lt;p&gt;Adding this resource management
context extends the &lt;strong&gt;Test Suite&lt;/strong&gt;  to optimize tests around the resources.
This can reshuffle the TestCases to minimize SetUp's.  This can be useful in
contexts where …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;tt class="docutils literal"&gt;testresources&lt;/tt&gt; &lt;a class="reference external" href="http://www.robertcollins.net/unittest/testresources/"&gt;http://www.robertcollins.net/unittest/testresources/&lt;/a&gt;
purpose appears to be to manage the resources used by a test suite.&lt;/p&gt;
&lt;p&gt;Adding this resource management
context extends the &lt;strong&gt;Test Suite&lt;/strong&gt;  to optimize tests around the resources.
This can reshuffle the TestCases to minimize SetUp's.  This can be useful in
contexts where the &lt;strong&gt;Fixture&lt;/strong&gt; includes &lt;strong&gt;Singletons&lt;/strong&gt; or expensive resources.&lt;/p&gt;
&lt;p&gt;While interesting, this package bends one of the common definitions of Unit Testing.
If there is a complex resource dependency, the &lt;strong&gt;Fixture&lt;/strong&gt;
being tested isn't really isolated.  This pushes beyond isolated unit testing
with &lt;strong&gt;Mock&lt;/strong&gt; objects into integration testing with real objects and real
interfaces.&lt;/p&gt;
&lt;p&gt;One can make the case that
&amp;quot;unit&amp;quot; is intentionally vague; the Beck definitions refer to a &lt;strong&gt;Fixture&lt;/strong&gt;
as the design pattern.  This could be a class, module or package, depending on
your willingness to abstract.  I agree that &amp;quot;unit&amp;quot; does not necessarily mean
class.  However, I do think that &amp;quot;unit&amp;quot; means isolated from other
components.&lt;/p&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;testresources&lt;/tt&gt; seems
specifically designed for integration test, not unit test.  I think it is
miscategorized, and belongs to an unidentified species of products: integration
testing frameworks.&lt;/p&gt;
</content><category term="Python"></category><category term="#python"></category><category term="unit testing"></category></entry><entry><title>SubUnit</title><link href="https://slott56.github.io/2005_12_20-subunit.html" rel="alternate"></link><published>2005-12-20T18:36:00-05:00</published><updated>2005-12-20T18:36:00-05:00</updated><author><name>S.Lott</name></author><id>tag:slott56.github.io,2005-12-20:/2005_12_20-subunit.html</id><summary type="html">&lt;p&gt;SubUnit's &lt;a class="reference external" href="http://www.robertcollins.net/unittest/subunit/"&gt;http://www.robertcollins.net/unittest/subunit/&lt;/a&gt; purpose appears to be to manage testing
via subprocesses.&lt;/p&gt;
&lt;p&gt;Consequently, it can run external tests not in Python, it can fork a subprocess to manage the Fixture
in an isolated process.&lt;/p&gt;
&lt;p&gt;Adding this subprocess execution context extends the &lt;strong&gt;Test Runner&lt;/strong&gt;  implementation of the …&lt;/p&gt;</summary><content type="html">&lt;p&gt;SubUnit's &lt;a class="reference external" href="http://www.robertcollins.net/unittest/subunit/"&gt;http://www.robertcollins.net/unittest/subunit/&lt;/a&gt; purpose appears to be to manage testing
via subprocesses.&lt;/p&gt;
&lt;p&gt;Consequently, it can run external tests not in Python, it can fork a subprocess to manage the Fixture
in an isolated process.&lt;/p&gt;
&lt;p&gt;Adding this subprocess execution context extends the &lt;strong&gt;Test Runner&lt;/strong&gt;  implementation of the built-in
&lt;tt class="docutils literal"&gt;unittest&lt;/tt&gt; module.  This can be useful in contexts where the Fixture includes &lt;strong&gt;Singletons&lt;/strong&gt;
or connection pools or other per-process design features.&lt;/p&gt;
</content><category term="Python"></category><category term="#python"></category><category term="unit testing"></category></entry><entry><title>Twisted Trial</title><link href="https://slott56.github.io/2005_12_15-twisted_trial.html" rel="alternate"></link><published>2005-12-15T17:10:00-05:00</published><updated>2005-12-15T17:10:00-05:00</updated><author><name>S.Lott</name></author><id>tag:slott56.github.io,2005-12-15:/2005_12_15-twisted_trial.html</id><summary type="html">&lt;p&gt;Trial is not really a stand-alone unit test
framework.  It is an extension to unittest focused on the testing needs for the
Twisted framework.&lt;/p&gt;
&lt;p&gt;The Trial how-to
&lt;a class="reference external" href="http://twistedmatrix.com/projects/core/documentation/howto/testing.html"&gt;http://twistedmatrix.com/projects/core/documentation/howto/testing.html&lt;/a&gt; has some information.  More valuable,
perhaps are the API documents &lt;a class="reference external" href="http://twistedmatrix.com/documents/current/api/twisted.trial.html"&gt;http://twistedmatrix.com/documents …&lt;/a&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;Trial is not really a stand-alone unit test
framework.  It is an extension to unittest focused on the testing needs for the
Twisted framework.&lt;/p&gt;
&lt;p&gt;The Trial how-to
&lt;a class="reference external" href="http://twistedmatrix.com/projects/core/documentation/howto/testing.html"&gt;http://twistedmatrix.com/projects/core/documentation/howto/testing.html&lt;/a&gt; has some information.  More valuable,
perhaps are the API documents &lt;a class="reference external" href="http://twistedmatrix.com/documents/current/api/twisted.trial.html"&gt;http://twistedmatrix.com/documents/current/api/twisted.trial.html&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Because of the asynchronous nature of
Twisted, the Fixture pattern has a rather complex relationship with the Twisted
Reactor.  Also, since Twisted is a framework, not a single application,
components are optional, and the TestSuite pattern is implemented with
considerably more flexibility.&lt;/p&gt;
</content><category term="Python"></category><category term="#python"></category><category term="unit testing"></category></entry><entry><title>More Frameworks! (rev. 3)</title><link href="https://slott56.github.io/2005_12_13-more_frameworks_rev_3.html" rel="alternate"></link><published>2005-12-13T18:40:00-05:00</published><updated>2005-12-13T18:40:00-05:00</updated><author><name>S.Lott</name></author><id>tag:slott56.github.io,2005-12-13:/2005_12_13-more_frameworks_rev_3.html</id><summary type="html">&lt;p&gt;A wiki page on Python testing tools &lt;a class="reference external" href="http://pycheesecake.org/wiki/PythonTestingToolsTaxonomy"&gt;http://pycheesecake.org/wiki/PythonTestingToolsTaxonomy&lt;/a&gt; identifies a number of additional unit
testing tools.  The wiki page provides a handy summary.  I'll examine these in
light of the Beck Unit Test design patterns to provide a little more detail on
what they really do …&lt;/p&gt;</summary><content type="html">&lt;p&gt;A wiki page on Python testing tools &lt;a class="reference external" href="http://pycheesecake.org/wiki/PythonTestingToolsTaxonomy"&gt;http://pycheesecake.org/wiki/PythonTestingToolsTaxonomy&lt;/a&gt; identifies a number of additional unit
testing tools.  The wiki page provides a handy summary.  I'll examine these in
light of the Beck Unit Test design patterns to provide a little more detail on
what they really do.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Twisted Trial&lt;/li&gt;
&lt;li&gt;SubUnit&lt;/li&gt;
&lt;li&gt;Testresources&lt;/li&gt;
&lt;li&gt;PyUnitPerf&lt;/li&gt;
&lt;li&gt;PeckCheck&lt;/li&gt;
&lt;li&gt;PythonMock&lt;/li&gt;
&lt;li&gt;pMock&lt;/li&gt;
&lt;/ul&gt;
</content><category term="Python"></category><category term="#python"></category><category term="unit testing"></category></entry><entry><title>Compare and Contrast (round 3, revised)</title><link href="https://slott56.github.io/2005_11_09-compare_and_contrast_round_3_revised.html" rel="alternate"></link><published>2005-11-09T19:38:00-05:00</published><updated>2005-11-09T19:38:00-05:00</updated><author><name>S.Lott</name></author><id>tag:slott56.github.io,2005-11-09:/2005_11_09-compare_and_contrast_round_3_revised.html</id><summary type="html">&lt;p&gt;The object-oriented unit testing framework began
as Smalltalk's Beck Test framework &lt;a class="reference external" href="http://www.xprogramming.com/testfram.htm"&gt;http://www.xprogramming.com/testfram.htm&lt;/a&gt;.  It evolved to the JUnit &lt;a class="reference external" href="http://www.junit.org/index.htm"&gt;http://www.junit.org/index.htm&lt;/a&gt;&amp;gt;`_ `  &amp;lt;&lt;a class="reference external" href="http://www.junit.org/index.htm%22%20target=%22NewWindow"&gt;http://www.junit.org/index.htm%22%20target=%22NewWindow&lt;/a&gt;
framework for Java.  Beck defined four repeated patterns of unit testing
software …&lt;/p&gt;</summary><content type="html">&lt;p&gt;The object-oriented unit testing framework began
as Smalltalk's Beck Test framework &lt;a class="reference external" href="http://www.xprogramming.com/testfram.htm"&gt;http://www.xprogramming.com/testfram.htm&lt;/a&gt;.  It evolved to the JUnit &lt;a class="reference external" href="http://www.junit.org/index.htm"&gt;http://www.junit.org/index.htm&lt;/a&gt;&amp;gt;`_ `  &amp;lt;&lt;a class="reference external" href="http://www.junit.org/index.htm%22%20target=%22NewWindow"&gt;http://www.junit.org/index.htm%22%20target=%22NewWindow&lt;/a&gt;
framework for Java.  Beck defined four repeated patterns of unit testing
software, covered in a previous posting &amp;lt;{filename}/blog/2005/11/2005_11_05-compare_and_contrast_round_1.rst&amp;gt;.&lt;/p&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;Nose&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;TestOOB&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;test.py&lt;/tt&gt;
(and &lt;tt class="docutils literal"&gt;TestGears&lt;/tt&gt;) are significant revisions to the
&lt;strong&gt;Test Suite&lt;/strong&gt;  and &lt;strong&gt;Test Runner&lt;/strong&gt;  parts of the unit test patterns.
Additionally, these tools make efforts to implement the &lt;strong&gt;Diagnostics&lt;/strong&gt; pattern, also.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;Fixture&lt;/strong&gt;
is implied by the context in which the tests are discovered.  Nose can locate
package, module and function tests; it uses TestCase class definitions, also.
TestOOB and test.py sit more squarely on unittest, with the resulting focus on
module-level testing.&lt;/p&gt;
&lt;p&gt;In &lt;tt class="docutils literal"&gt;TestOOB&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;test.py&lt;/tt&gt;, the &lt;strong&gt;TestCase&lt;/strong&gt;
class plus a flexible regular expressions or glob expression defines the test
cases.  test.py looks for packages of tests, using the path name of the package,
as well as the module name.  In &lt;tt class="docutils literal"&gt;Nose&lt;/tt&gt;, the &lt;strong&gt;TestCase&lt;/strong&gt;
class can be used for compatibility, but this is not required; Nose will match a
regular expression to locate tests.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;Results Check&lt;/strong&gt;  in &lt;tt class="docutils literal"&gt;nose&lt;/tt&gt; can be done via the existing
&lt;tt class="docutils literal"&gt;assert&lt;/tt&gt; statement.  &lt;tt class="docutils literal"&gt;Nose&lt;/tt&gt;, pleasantly handles the &amp;quot;test which throws an exception&amp;quot;
case: a test function that exits normally is a &amp;quot;pass&amp;quot;.  An &lt;tt class="docutils literal"&gt;AssertionError&lt;/tt&gt;
exception is a test failure; any other exception is an error.  Since &lt;tt class="docutils literal"&gt;TestOOB&lt;/tt&gt; and
&lt;tt class="docutils literal"&gt;test.py&lt;/tt&gt; sit on &lt;tt class="docutils literal"&gt;unittest&lt;/tt&gt;, they
depend on the complex set of assert methods, and the &lt;tt class="docutils literal"&gt;fail()&lt;/tt&gt; method.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;Test Suite&lt;/strong&gt;  is implied by the collection of &lt;tt class="docutils literal"&gt;TestCase&lt;/tt&gt;
instances with the expected name forms in &lt;tt class="docutils literal"&gt;TestOOB&lt;/tt&gt;.  In &lt;tt class="docutils literal"&gt;Nose&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;test.py&lt;/tt&gt;, it is
the collection of modules, functions and methods with names that have the
expected forms.  Both cases make powerful use of Python introspection to track
down the tests.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;Test Runner&lt;/strong&gt;  in nose can be a stand-alone &lt;tt class="docutils literal"&gt;nosetests&lt;/tt&gt;
program, or you can &lt;tt class="docutils literal"&gt;import nose; nose.main()&lt;/tt&gt;.
In the case of &lt;tt class="docutils literal"&gt;TestOOB&lt;/tt&gt;, we have a &lt;tt class="docutils literal"&gt;testoob&lt;/tt&gt;
program, or we can &lt;cite&gt;import testoob; testoob.main()`&lt;/cite&gt;.
&lt;tt class="docutils literal"&gt;Nose&lt;/tt&gt; has an interesting
integration with Python &lt;tt class="docutils literal"&gt;distutils/setuptools&lt;/tt&gt;.  It adds a new &amp;quot;test&amp;quot; verb to
&lt;tt class="docutils literal"&gt;setup.py&lt;/tt&gt;.  The &lt;tt class="docutils literal"&gt;test.py&lt;/tt&gt; main program has a large number of options to fine-tune
which tests are run&lt;/p&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;Nose&lt;/tt&gt; supports the &lt;strong&gt;Diagnostics&lt;/strong&gt;
with output capture and a simple flag for producing additional details.
&lt;tt class="docutils literal"&gt;TestOOB&lt;/tt&gt;, in certain environments, will produce color output; it produces an XML
test report as well as HTML test reports.  &lt;tt class="docutils literal"&gt;TestOOB&lt;/tt&gt; can launch the Python
debugger as well as log failing assertions in detail.  &lt;tt class="docutils literal"&gt;test.py&lt;/tt&gt; can run
&lt;tt class="docutils literal"&gt;pychecker&lt;/tt&gt;, do tracing and refcount checking as part of the diagnostics.&lt;/p&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;TestOOB&lt;/tt&gt; has some additional features for repeating and controlling the timing of the tests.
While this is not sufficient to prove that an application lacks the kind of race
condition that makes it behave poorly; it can help to provide some confidence
for load testing.  Similarly, &lt;tt class="docutils literal"&gt;test.py&lt;/tt&gt; includes features for looping tests to
look for memory leaks and race conditions.&lt;/p&gt;
</content><category term="Python"></category><category term="#python"></category><category term="unit testing"></category></entry><entry><title>Compare and Contrast (round 2)</title><link href="https://slott56.github.io/2005_11_07-compare_and_contrast_round_2.html" rel="alternate"></link><published>2005-11-07T17:50:00-05:00</published><updated>2005-11-07T17:50:00-05:00</updated><author><name>S.Lott</name></author><id>tag:slott56.github.io,2005-11-07:/2005_11_07-compare_and_contrast_round_2.html</id><summary type="html">&lt;p&gt;The object-oriented unit testing framework began
as Smalltalk's Beck Test framework &lt;a class="reference external" href="http://www.xprogramming.com/testfram.htm%22%20target=%22NewWindow"&gt;http://www.xprogramming.com/testfram.htm%22%20target=%22NewWindow&lt;/a&gt;.
It evolved to the JUnit &lt;a class="reference external" href="http://www.junit.org/index.htm%22%20target=%22NewWindow"&gt;http://www.junit.org/index.htm%22%20target=%22NewWindow&lt;/a&gt;
framework for Java.  Beck defined four repeated patterns of unit testing
software, covered in a previous …&lt;/p&gt;</summary><content type="html">&lt;p&gt;The object-oriented unit testing framework began
as Smalltalk's Beck Test framework &lt;a class="reference external" href="http://www.xprogramming.com/testfram.htm%22%20target=%22NewWindow"&gt;http://www.xprogramming.com/testfram.htm%22%20target=%22NewWindow&lt;/a&gt;.
It evolved to the JUnit &lt;a class="reference external" href="http://www.junit.org/index.htm%22%20target=%22NewWindow"&gt;http://www.junit.org/index.htm%22%20target=%22NewWindow&lt;/a&gt;
framework for Java.  Beck defined four repeated patterns of unit testing
software, covered in a previous posting &amp;lt;{filename}/blog/2005/11/2005_11_05-compare_and_contrast_round_1.rst&amp;gt;.&lt;/p&gt;
&lt;p&gt;An additional pattern that py.test introduces is the &lt;strong&gt;Diagnostics&lt;/strong&gt;
pattern.  This is a useful traceback or cached output.  To make it useful, it is
presented only for failing tests, and elides repetition in the event of
recursions that lead to stack overflows.&lt;/p&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;py.test&lt;/tt&gt; seems to deliver most of the Beck-defined features.&lt;/p&gt;
&lt;p&gt;The Fixture is created by offering a
number of setup/teardown functions, either at the module level (for a module or
class) or within a class.&lt;/p&gt;
&lt;p&gt;The Test Case is a module, class or function with an appropriate name.  Either
&lt;tt class="docutils literal"&gt;test_&lt;/tt&gt; or &lt;tt class="docutils literal"&gt;Test_&lt;/tt&gt; as a
prefix is sufficient to define a test case.&lt;/p&gt;
&lt;p&gt;The Results Check uses ordinary
asserts and a special
&lt;tt class="docutils literal"&gt;py.test.raises()&lt;/tt&gt;
function to cover all the bases.  Personally, I prefer the JUnit approach to
catching the expected exception and calling the
&lt;tt class="docutils literal"&gt;fail()&lt;/tt&gt; method for everything else.&lt;/p&gt;
&lt;p&gt;The Suite is
developed by implication through Python's powerful introspection: everything
that looks like a test -- at the package, module and class level -- is a
candidate.  A regular expression can pick names, plus other global conditions
can be examined to further refine the test protocols.&lt;/p&gt;
&lt;p&gt;The Runner is a stand-alone &lt;tt class="docutils literal"&gt;py.test&lt;/tt&gt; program
that locates the tests, executes them and produces a log.  Further, it produces
Diagnostics focused on the failing tests.&lt;/p&gt;
</content><category term="Python"></category><category term="#python"></category><category term="unit testing"></category></entry><entry><title>Compare and Contrast (round 1)</title><link href="https://slott56.github.io/2005_11_05-compare_and_contrast_round_1.html" rel="alternate"></link><published>2005-11-05T20:21:00-05:00</published><updated>2005-11-05T20:21:00-05:00</updated><author><name>S.Lott</name></author><id>tag:slott56.github.io,2005-11-05:/2005_11_05-compare_and_contrast_round_1.html</id><summary type="html">&lt;div class="section" id="some-basis-for-comparison"&gt;
&lt;h2&gt;Some Basis for Comparison&lt;/h2&gt;
&lt;p&gt;The object-oriented unit
testing framework began as Smalltalk's Beck Test framework &lt;a class="reference external" href="http://www.xprogramming.com/testfram.htm"&gt;http://www.xprogramming.com/testfram.htm&lt;/a&gt;.  It evolved to the JUnit &lt;a class="reference external" href="http://www.junit.org/index.htm"&gt;http://www.junit.org/index.htm&lt;/a&gt;
framework for Java.  Beck defined four repeated patterns of unit testing
software:&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;Fixture&lt;/strong&gt;.
The thing we are …&lt;/p&gt;&lt;/div&gt;</summary><content type="html">&lt;div class="section" id="some-basis-for-comparison"&gt;
&lt;h2&gt;Some Basis for Comparison&lt;/h2&gt;
&lt;p&gt;The object-oriented unit
testing framework began as Smalltalk's Beck Test framework &lt;a class="reference external" href="http://www.xprogramming.com/testfram.htm"&gt;http://www.xprogramming.com/testfram.htm&lt;/a&gt;.  It evolved to the JUnit &lt;a class="reference external" href="http://www.junit.org/index.htm"&gt;http://www.junit.org/index.htm&lt;/a&gt;
framework for Java.  Beck defined four repeated patterns of unit testing
software:&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;Fixture&lt;/strong&gt;.
The thing we are testing; a class or possibly a set of instances of a given
class, or possibly something even larger.  If we are testing more than one class
at a time, we aren't really &amp;quot;unit&amp;quot; testing.  So the fixture often includes stubs
for missing classes.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;Test Case&lt;/strong&gt;.  A predictable reaction of the fixture.
This should either work or fail.  It can, of course also raise one of those
egregious, unchecked-for errors that indicate fairly serious problems in a
preliminary piece of software.  Or, it may indicate something that was badly
damaged during maintenance and is now raising errors instead of simply failing
the regression test suite.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;Results Check&lt;/strong&gt;.  A specific assertion about the fixture's results.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;Test Suite&lt;/strong&gt;. A collection of TestCases.&lt;/p&gt;
&lt;p&gt;JUnit and unittest add a
&lt;strong&gt;Test Runner&lt;/strong&gt;  pattern, also.  This the top-level
component that uses a Test Suite to create test results by executing each Test
Case, assuring that each Results Check worked.  The Test Runner can also assure
that any Fixture Setup and Teardown is done
correctly.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="legacy-frameworks"&gt;
&lt;h2&gt;Legacy Frameworks&lt;/h2&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;unittest&lt;/tt&gt; delivers all
the Beck-defined features.  It should, it is the indirect descendant of the
original framework.  Having JUnit as an ancestor, however, leads to some clunky
non-Pythonic features.  In particular, Python features that Java lacks are
ignored, including modules and free-standing
functions.&lt;/p&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;doctest&lt;/tt&gt; has an odd fit with
the Beck framework.  The fixture isn't well defined; since doctest has a
module-centric view, a shallow copy of the module globals are given to each
test, making the module globals the fixture.  Each Case and Results Check is
encoded in a docstring, usually by a cut and paste from an interactive testing
session.  The test suite is implied by the module
structure.&lt;/p&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;unittest&lt;/tt&gt; isn't terribly
Pythonic.  Doctest is module-focused, not class focused, and doesn't treat the
notion of fixture very well.&lt;/p&gt;
&lt;p&gt;IMO, module-based testing is a more useful level of unit testing.  Individual
classes, while important, rarely make sense in a vacuum.  All of the test
harness and stub classes required to test just one class seems like too much
unproductive work.  When the architecture changes, I may have to change a class
definition as well as the test harness classes that stand in for this class in
the unit testing framework.&lt;/p&gt;
&lt;p&gt;Next Up,
&lt;tt class="docutils literal"&gt;py.test&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;nose&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;testgears&lt;/tt&gt;.  Later, &lt;tt class="docutils literal"&gt;TestOOB&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;Sancho&lt;/tt&gt;.&lt;/p&gt;
&lt;/div&gt;
</content><category term="Python"></category><category term="#python"></category><category term="unit testing"></category></entry><entry><title>Python Unit Testing Frameworks (v3)</title><link href="https://slott56.github.io/2005_11_02-python_unit_testing_frameworks_v3.html" rel="alternate"></link><published>2005-11-02T00:12:00-05:00</published><updated>2005-11-02T00:12:00-05:00</updated><author><name>S.Lott</name></author><id>tag:slott56.github.io,2005-11-02:/2005_11_02-python_unit_testing_frameworks_v3.html</id><summary type="html">&lt;p&gt;Ned Batchelder : Blog [&lt;a class="reference external" href="http://www.nedbatchelder.com/blog/index.html"&gt;http://www.nedbatchelder.com/blog/index.html&lt;/a&gt; ] identifies no less than 6 unit testing
frameworks for Python [&lt;a class="reference external" href="http://www.nedbatchelder.com/blog/200510.html#e20051025T070731"&gt;http://www.nedbatchelder.com/blog/200510.html#e20051025T070731&lt;/a&gt; ] and [&lt;a class="reference external" href="http://www.nedbatchelder.com/blog/200411.html#e20041120T185622"&gt;http://www.nedbatchelder.com/blog/200411.html#e20041120T185622&lt;/a&gt; ].&lt;/p&gt;
&lt;p&gt;TestGears
[&lt;a class="reference external" href="http://www.turbogears.com/testgears/"&gt;http://www.turbogears.com/testgears/&lt;/a&gt; ] is part of the TurboGears web
uber-framework …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Ned Batchelder : Blog [&lt;a class="reference external" href="http://www.nedbatchelder.com/blog/index.html"&gt;http://www.nedbatchelder.com/blog/index.html&lt;/a&gt; ] identifies no less than 6 unit testing
frameworks for Python [&lt;a class="reference external" href="http://www.nedbatchelder.com/blog/200510.html#e20051025T070731"&gt;http://www.nedbatchelder.com/blog/200510.html#e20051025T070731&lt;/a&gt; ] and [&lt;a class="reference external" href="http://www.nedbatchelder.com/blog/200411.html#e20041120T185622"&gt;http://www.nedbatchelder.com/blog/200411.html#e20041120T185622&lt;/a&gt; ].&lt;/p&gt;
&lt;p&gt;TestGears
[&lt;a class="reference external" href="http://www.turbogears.com/testgears/"&gt;http://www.turbogears.com/testgears/&lt;/a&gt; ] is part of the TurboGears web
uber-framework. It provides automatic discovery of test functions, simplifies
suite development, and makes it easy to run tests zero configuration.  Kevin
Dangoor [&lt;a class="reference external" href="http://www.blueskyonmars.com/"&gt;http://www.blueskyonmars.com/&lt;/a&gt; ] says he will deprecate this in favor of
Nose.  David Warnock [&lt;a class="reference external" href="http://42.blogs.warnock.me.uk/2005/10/turbogears_cont.html"&gt;http://42.blogs.warnock.me.uk/2005/10/turbogears_cont.html&lt;/a&gt; ] says something
similar.&lt;/p&gt;
&lt;p&gt;TestOOB [&lt;a class="reference external" href="http://testoob.sourceforge.net/"&gt;http://testoob.sourceforge.net/&lt;/a&gt; ]
(Testing Out Of [the] Box) provides for new styles of output (HTML and color
terminal), debugger launching, verbose asserts, parallel execution, and
command-line utility testing&lt;/p&gt;
&lt;p&gt;nose [&lt;a class="reference external" href="http://somethingaboutorange.com/mrl/projects/nose/"&gt;http://somethingaboutorange.com/mrl/projects/nose/&lt;/a&gt; ] provides an alternate test discovery and
execution engine for unittest&lt;/p&gt;
&lt;p&gt;unittest [&lt;a class="reference external" href="http://docs.python.org/lib/module-unittest.html"&gt;http://docs.python.org/lib/module-unittest.html&lt;/a&gt; ], formerly known as PyUnit [&lt;a class="reference external" href="http://pyunit.sourceforge.net/"&gt;http://pyunit.sourceforge.net/&lt;/a&gt; ]
(Thanks for the heads up, Tony [&lt;a class="reference external" href="http://www.haloscan.com/comments/slott/E20051105152154/#29209"&gt;http://www.haloscan.com/comments/slott/E20051105152154/#29209&lt;/a&gt; ])&lt;/p&gt;
&lt;p&gt;doctest
[&lt;a class="reference external" href="http://docs.python.org/lib/module-doctest.html"&gt;http://docs.python.org/lib/module-doctest.html&lt;/a&gt; ]&lt;/p&gt;
&lt;p&gt;py.test [&lt;a class="reference external" href="http://codespeak.net/py/current/doc/test.html"&gt;http://codespeak.net/py/current/doc/test.html&lt;/a&gt; ]&lt;/p&gt;
&lt;p&gt;Michal
Watkins [&lt;a class="reference external" href="http://mikewatkins.net/"&gt;http://mikewatkins.net/&lt;/a&gt; ] adds  Sancho, a unit testing framework
[&lt;a class="reference external" href="http://www.mems-exchange.org/software/sancho/"&gt;http://www.mems-exchange.org/software/sancho/&lt;/a&gt; ].&lt;/p&gt;
&lt;p&gt;Also,
ZOPE has test.py [&lt;a class="reference external" href="http://zopewiki.org/HowToRunZopeUnitTests"&gt;http://zopewiki.org/HowToRunZopeUnitTests&lt;/a&gt; ].  There is a derivative product, also, the
SchoolTool Test Runner [&lt;a class="reference external" href="http://svn.nuxeo.org/trac/pub/file/CalCore/trunk/test.py"&gt;http://svn.nuxeo.org/trac/pub/file/CalCore/trunk/test.py&lt;/a&gt; ].&lt;/p&gt;
&lt;p&gt;Jeremy
Hylton's blog has some notes [&lt;a class="reference external" href="http://www.python.org/~jeremy/weblog/031014.html"&gt;http://www.python.org/~jeremy/weblog/031014.html&lt;/a&gt; ] on unit testing, describing
test.py.&lt;/p&gt;
&lt;p&gt;Ian Bicking also has a list of
complaints about the basic unittest interface [&lt;a class="reference external" href="http://blog.colorstudy.com/ianb/weblog/2003/10/10.html#P11"&gt;http://blog.colorstudy.com/ianb/weblog/2003/10/10.html#P11&lt;/a&gt; ], many of which are answered by the
add-ons.&lt;/p&gt;
</content><category term="Python"></category><category term="#python"></category><category term="unit testing"></category></entry></feed>